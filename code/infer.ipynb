{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import sys\n",
    "from infer_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_reload = [\"infer_functions\"]\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "    __import__(module_name)\n",
    "    module = sys.modules[module_name]\n",
    "    globals().update({name: getattr(module, name) for name in dir(module) if not name.startswith('_')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catting AAPL.csv\n",
      "Catting AMZN.csv\n",
      "Catting LLY.csv\n",
      "Catting MSFT.csv\n",
      "Catting NVDA.csv\n",
      "Catting TSLA.csv\n"
     ]
    }
   ],
   "source": [
    "tensor_dataset = create_tensor_dataset(\"static\", 4, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1300, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1300, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1300, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1360, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1360, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1360, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1360, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1360, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1360, dtype=torch.float64))\n",
      "((tensor([[ 1.2210,  0.5435, 14.1786,  4.3501],\n",
      "        [ 0.8461,  0.0850,  8.3076,  3.3166],\n",
      "        [ 1.8592,  9.8285,  1.1807,  0.1624],\n",
      "        [ 5.8709,  1.6466,  0.7817, 13.4769],\n",
      "        [ 4.1467,  0.9799,  0.1090,  7.9394],\n",
      "        [ 3.7399,  1.8592,  9.3302,  1.0426],\n",
      "        [ 0.1160,  5.5375,  1.4010,  0.8101],\n",
      "        [10.7563,  3.1795,  0.6423,  0.0979],\n",
      "        [ 5.5810,  2.9437,  1.3449,  7.5768],\n",
      "        [ 0.9569,  0.0000,  5.1753,  1.0377],\n",
      "        [ 0.6079,  9.6039,  3.4001,  0.6616],\n",
      "        [ 0.0818,  3.8718,  2.0255,  0.7869],\n",
      "        [ 6.2037,  0.7700,  0.0000,  5.7321]], dtype=torch.float64), tensor([0., 1., 4.], dtype=torch.float64)), tensor(29.1360, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "for i, thing in list(enumerate(tensor_dataset))[:10]:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SlidingWindowDataset(Dataset):\n",
    "#     def __init__(self, dataset, sequence_length):\n",
    "#         self.dataset = dataset\n",
    "#         self.sequence_length = sequence_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset) - self.sequence_length\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "\n",
    "\n",
    "# class SlidingWindowDatasetTEST(Dataset):\n",
    "#     def __init__(self, dataset, sequence_length):\n",
    "#         self.dataset = dataset\n",
    "#         self.sequence_length = sequence_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset) - self.sequence_length\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.dataset[idx:idx+self.sequence_length]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 400\n",
    "HIDDEN_SIZE = 200\n",
    "EMBED_SIZE = 30\n",
    "LAYERS = 8\n",
    "SEQUENCE_LENGTH = 20\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# train_tensor = train_tensor.to(device)\n",
    "# train_label_tensor = train_label_tensor.to(device)\n",
    "# test_tensor = test_tensor.to(device)\n",
    "# validate_tensor = validate_tensor.to(device)\n",
    "# validate_label_tensor = validate_label_tensor.to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_tensor, train_label_tensor)\n",
    "train_dataset = SlidingWindowDataset(train_dataset,SEQUENCE_LENGTH)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_tensor)\n",
    "###problem here###\n",
    "test_dataset = SlidingWindowDatasetTEST(test_dataset,SEQUENCE_LENGTH)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "validate_dataset = torch.utils.data.TensorDataset(validate_tensor,validate_label_tensor)\n",
    "validate_dataset = SlidingWindowDataset(validate_dataset,SEQUENCE_LENGTH)\n",
    "validate_dataloader = torch.utils.data.DataLoader(validate_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "class LSTMSales(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, batch_size, layers):\n",
    "        super(LSTMSales, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.layers_num = layers\n",
    "\n",
    "        #Embedding layers\n",
    "        self.store_number = nn.Embedding(54,embedding_dim)\n",
    "        self.family = nn.Embedding(33,embedding_dim)\n",
    "        self.store_type = nn.Embedding(5,embedding_dim)\n",
    "        self.cluster = nn.Embedding(17,embedding_dim)\n",
    "        self.holiday = nn.Embedding(5,embedding_dim)\n",
    "        \n",
    "        #input is all the embedding vectors plus all the other variables\n",
    "        self.lstm = nn.LSTM(120, hidden_dim, num_layers=layers, batch_first=True) \n",
    "        self.hidden = (torch.zeros(layers,batch_size,hidden_dim),torch.zeros(layers,batch_size,hidden_dim))\n",
    "        \n",
    "        #normalize outputs\n",
    "        #self.bn1 = nn.BatchNorm1d(out_features)\n",
    "\n",
    "        self.hidden2sales = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, batch_tensor):\n",
    "        #Trying to predict the log of (the sales + 1) \n",
    "        # store_number =self.store_number(batch_tensor[:,:,0].long())\n",
    "        # family = self.family(batch_tensor[:,:,1].long())\n",
    "        # store_type = self.store_type(batch_tensor[:,:,3].long())\n",
    "        # cluster = self.cluster(batch_tensor[:,:,4].long())\n",
    "        # holiday = self.holiday(batch_tensor[:,:,7].long())\n",
    "        # batch_tensor = batch_tensor[:,:,[2,5,6,8,9,10]]\n",
    "        # input = torch.cat([batch_tensor,store_number,family,store_type,cluster,holiday],dim=2)\n",
    "        lstm_out, self.hidden = self.lstm(batch_tensor)\n",
    "        last_timestep_output = lstm_out[:, -1, :]\n",
    "        sales = self.hidden2sales(last_timestep_output)\n",
    "        sales =sales\n",
    "        return sales\n",
    "    \n",
    "    def hidden_reset(self):\n",
    "        #reset the hidden and cell state after each epoch\n",
    "        self.hidden = (torch.zeros(self.layers_num,self.batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,self.batch_size,self.hidden_dim))\n",
    "    def batch_reset(self,batch_size):\n",
    "        self.hidden = (torch.zeros(self.layers_num,batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,batch_size,self.hidden_dim))\n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
