{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from infer_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_reload = [\"infer_functions\"]\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "    __import__(module_name)\n",
    "    module = sys.modules[module_name]\n",
    "    globals().update({name: getattr(module, name) for name in dir(module) if not name.startswith('_')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_tensor_dataset = create_tensor_dataset(\"static\", 4, limit=100, categories= 0, averages=True)\n",
    "dynamic_tensor_dataset = create_tensor_dataset(\"dynamic\", 4, limit=100, categories= 0, averages=True, use_profile=True, use_multiples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catting AAPL.csv\n",
      "Catting ABT.csv\n",
      "Catting AEP.csv\n",
      "Catting AMD.csv\n",
      "Catting AMGN.csv\n",
      "Catting AMZN.csv\n",
      "Catting APH.csv\n",
      "Catting BA.csv\n",
      "Catting BKR.csv\n",
      "Catting BMY.csv\n",
      "Catting BSX.csv\n",
      "Catting CDW.csv\n",
      "Catting CI.csv\n",
      "Catting CL.csv\n",
      "Catting COP.csv\n",
      "Catting COR.csv\n",
      "Catting CPNG.csv\n",
      "Catting CSGP.csv\n",
      "Catting CTSH.csv\n",
      "Catting CVS.csv\n",
      "Catting DHR.csv\n",
      "Catting ECL.csv\n",
      "Catting ED.csv\n",
      "Catting EFX.csv\n",
      "Catting EL.csv\n",
      "Catting ET.csv\n",
      "Catting FAST.csv\n",
      "Catting FIS.csv\n",
      "Catting GILD.csv\n",
      "Catting HES.csv\n",
      "Catting HSY.csv\n",
      "Catting IBM.csv\n",
      "Catting INTC.csv\n",
      "Catting IR.csv\n",
      "Catting KDP.csv\n",
      "Catting KLAC.csv\n",
      "Catting KMB.csv\n",
      "Catting KMI.csv\n",
      "Catting KO.csv\n",
      "Catting LHX.csv\n",
      "Catting LIN.csv\n",
      "Catting LRCX.csv\n",
      "Catting LYB.csv\n",
      "Catting MA.csv\n",
      "Catting MCK.csv\n",
      "Catting MCO.csv\n",
      "Catting MLM.csv\n",
      "Catting MMM.csv\n",
      "Catting MPC.csv\n",
      "Catting MSFT.csv\n",
      "Catting MSI.csv\n",
      "Catting NEM.csv\n",
      "Catting NOC.csv\n",
      "Catting NSC.csv\n",
      "Catting NUE.csv\n",
      "Catting OKE.csv\n",
      "Catting ON.csv\n",
      "Catting ORLY.csv\n",
      "Catting OTIS.csv\n",
      "Catting PFE.csv\n",
      "Catting PG.csv\n",
      "Catting PH.csv\n",
      "Catting PM.csv\n",
      "Catting PWR.csv\n",
      "Catting QCOM.csv\n",
      "Catting RTX.csv\n",
      "Catting SBUX.csv\n",
      "Catting SCCO.csv\n",
      "Catting SHW.csv\n",
      "Catting SPGI.csv\n",
      "Catting SYK.csv\n",
      "Catting SYY.csv\n",
      "Catting TDG.csv\n",
      "Catting TEL.csv\n",
      "Catting TMO.csv\n",
      "Catting TSLA.csv\n",
      "Catting TXN.csv\n",
      "Catting URI.csv\n",
      "Catting WM.csv\n",
      "Catting XYL.csv\n",
      "Catting ZTS.csv\n",
      "tensor(False) tensor(False) tensor(False)\n"
     ]
    }
   ],
   "source": [
    "with open(r\"..\\other_pickle\\measures.json\", \"r\") as file:\n",
    "    measures = json.load(file)\n",
    "combined_tensor_dataset = create_tensor_dataset(\"together\", 5, measures, limit =800, categories= 0, verbose=True, averages=False, use_profile=True, use_multiples=False, ghost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in combined_tensor_dataset:\n",
    "    print(inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "with open(r\"..\\other_pickle\\measures.json\", \"r\") as file:\n",
    "    measures = json.load(file)\n",
    "\n",
    "static_size = len(measures[\"static\"])\n",
    "dynamic_size = len(measures[\"dynamic\"])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "STATIC_BATCH_SIZE = 20\n",
    "DYNAMIC_BATCH_SIZE = 5\n",
    "COMBINED_BATCH_SIZE = 32\n",
    "\n",
    "# static_train_dataloader = torch.utils.data.DataLoader(static_tensor_dataset, batch_size=STATIC_BATCH_SIZE, shuffle=True)\n",
    "# dynamic_train_dataloader = torch.utils.data.DataLoader(dynamic_tensor_dataset, batch_size=DYNAMIC_BATCH_SIZE, shuffle=False)\n",
    "# combined_train_dataloader = torch.utils.data.DataLoader(combined_tensor_dataset, batch_size=COMBINED_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "LAYERS = 8\n",
    "\n",
    "class StaticLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, batch_size, layers, input, categories=0):\n",
    "        super(StaticLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.layers_num = layers\n",
    "        \n",
    "        #input is all the embedding vectors plus all the other variables\n",
    "        self.lstm = nn.LSTM(input, hidden_dim, num_layers=layers, batch_first=True) \n",
    "        self.hidden = (torch.zeros(layers,batch_size,hidden_dim),torch.zeros(layers,batch_size,hidden_dim))\n",
    "        \n",
    "        #Squeeeze them into 1 dimension\n",
    "        if categories > 0:\n",
    "            self.hidden2label = nn.Linear(hidden_dim, categories)\n",
    "        else:\n",
    "            self.hidden2label = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, batch_tensor):\n",
    "        lstm_out, self.hidden = self.lstm(batch_tensor)\n",
    "        last_timestep_output = lstm_out[:, -1, :]\n",
    "        sales = self.hidden2label(last_timestep_output)\n",
    "        return sales\n",
    "    \n",
    "    def hidden_reset(self):\n",
    "        #reset the hidden and cell state after each epoch\n",
    "        self.hidden = (torch.zeros(self.layers_num,self.batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,self.batch_size,self.hidden_dim))\n",
    "    def batch_reset(self,batch_size):\n",
    "        self.hidden = (torch.zeros(self.layers_num,batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,batch_size,self.hidden_dim))\n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "static_model = StaticLSTM(HIDDEN_SIZE, STATIC_BATCH_SIZE, LAYERS, static_size, categories=6)\n",
    "static_model = static_model.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split_tensor_dataset(static_tensor_dataset)\n",
    "grid_search(StaticLSTM, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.L1Loss()\n",
    "loss_scores = [float('inf')]\n",
    "learning_rate = 0.01\n",
    "epochs = 2\n",
    "static_model = static_model.to(device)\n",
    "optimizer = optim.Adam(static_model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    static_model.hidden_reset()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(static_train_dataloader):\n",
    "        (input, worthless_input), label = batch\n",
    "        if input.shape[0] != STATIC_BATCH_SIZE:\n",
    "            static_model.batch_reset(input.shape[0])\n",
    "            print(\"Reset triggered due to batch size mismatch\")\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = static_model(input).squeeze()\n",
    "        \n",
    "        # Ensure output and label shapes are compatible for the loss function\n",
    "        if output.shape != label.shape:\n",
    "            print(f\"Output shape: {output.shape}, Label shape: {label.shape}\")\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 49:\n",
    "            print(f\"Batch {i+1}, Loss: {epoch_loss / (i+1)}\")\n",
    "    \n",
    "    average_epoch_loss = epoch_loss / len(static_train_dataloader)\n",
    "    print(f\"Average loss for epoch {epoch+1}: {average_epoch_loss}\")\n",
    "    \n",
    "    if average_epoch_loss < loss_scores[-1]:\n",
    "        torch.save(static_model.state_dict(), \"../other_pickle/Static_Model.pth\")\n",
    "        print(\"Model saved\")\n",
    "    loss_scores.append(average_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_model.load_state_dict(torch.load(\"../other_pickle/Static_Model.pth\"))\n",
    "static_model.eval()\n",
    "for i, batch in list(enumerate(static_train_dataloader))[:10]:\n",
    "    (input, worthless_input), label = batch\n",
    "    output = static_model(input).squeeze()\n",
    "    # loss = loss_function(output, label)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_reload = [\"infer_functions\"]\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "    __import__(module_name)\n",
    "    module = sys.modules[module_name]\n",
    "    globals().update({name: getattr(module, name) for name in dir(module) if not name.startswith('_')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-13 00:30:45,479] A new study created in memory with name: no-name-e34ca1de-900c-4d97-9128-2ef98a39edd0\n",
      "[I 2024-06-13 00:32:03,103] Trial 0 finished with value: 0.10038082953418623 and parameters: {'hidden_dim': 437, 'layers': 4, 'batch_size': 16, 'lr': 0.003038154129716284, 'epochs': 2}. Best is trial 0 with value: 0.10038082953418623.\n",
      "[I 2024-06-13 00:32:05,642] Trial 1 finished with value: 0.10009098962899576 and parameters: {'hidden_dim': 165, 'layers': 2, 'batch_size': 64, 'lr': 0.00740147025891154, 'epochs': 1}. Best is trial 1 with value: 0.10009098962899576.\n",
      "[I 2024-06-13 00:32:19,027] Trial 2 finished with value: 0.5972372979827296 and parameters: {'hidden_dim': 331, 'layers': 2, 'batch_size': 16, 'lr': 0.009466467695336572, 'epochs': 1}. Best is trial 1 with value: 0.10009098962899576.\n",
      "[I 2024-06-13 00:33:34,037] Trial 3 finished with value: 0.20244354824980024 and parameters: {'hidden_dim': 328, 'layers': 4, 'batch_size': 16, 'lr': 0.007598251470058156, 'epochs': 3}. Best is trial 1 with value: 0.10009098962899576.\n",
      "[I 2024-06-13 00:33:47,606] Trial 4 finished with value: 0.11244786788586701 and parameters: {'hidden_dim': 324, 'layers': 4, 'batch_size': 64, 'lr': 0.006656967446449591, 'epochs': 1}. Best is trial 1 with value: 0.10009098962899576.\n",
      "[I 2024-06-13 00:34:08,201] Trial 5 finished with value: 0.17311995911862704 and parameters: {'hidden_dim': 267, 'layers': 4, 'batch_size': 16, 'lr': 0.0014153255897160892, 'epochs': 1}. Best is trial 1 with value: 0.10009098962899576.\n",
      "[I 2024-06-13 00:34:16,231] Trial 6 finished with value: 0.0963741911125318 and parameters: {'hidden_dim': 163, 'layers': 2, 'batch_size': 64, 'lr': 0.007554072845705796, 'epochs': 3}. Best is trial 6 with value: 0.0963741911125318.\n",
      "[I 2024-06-13 00:34:36,359] Trial 7 finished with value: 0.13462883259464126 and parameters: {'hidden_dim': 203, 'layers': 3, 'batch_size': 16, 'lr': 0.005985982512284994, 'epochs': 2}. Best is trial 6 with value: 0.0963741911125318.\n",
      "[I 2024-06-13 00:34:52,389] Trial 8 finished with value: 0.11244041210086576 and parameters: {'hidden_dim': 208, 'layers': 3, 'batch_size': 48, 'lr': 0.003700128902912334, 'epochs': 3}. Best is trial 6 with value: 0.0963741911125318.\n",
      "[I 2024-06-13 00:35:25,152] Trial 9 finished with value: 0.09587821616399922 and parameters: {'hidden_dim': 277, 'layers': 4, 'batch_size': 16, 'lr': 0.008790942024600675, 'epochs': 1}. Best is trial 9 with value: 0.09587821616399922.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = split_tensor_dataset(combined_tensor_dataset)\n",
    "best_parameters = grid_search(DynamicLSTM, x_train, y_train, n_trials=10, categories=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_dim': 288, 'layers': 3, 'batch_size': 32, 'lr': 0.0014625720043832183, 'epochs': 2}\n"
     ]
    }
   ],
   "source": [
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Batch 10, Loss: 0.7624322595160065\n",
      "Batch 20, Loss: 0.386967732861853\n",
      "Batch 30, Loss: 0.2613999674617259\n",
      "Batch 40, Loss: 0.1975048067858554\n",
      "Batch 50, Loss: 0.1597081456687775\n",
      "Batch 60, Loss: 0.13536079461954834\n",
      "Batch 70, Loss: 0.11740619922441936\n",
      "Batch 80, Loss: 0.1038365854815854\n",
      "Batch 90, Loss: 0.09343729232504773\n",
      "Batch 100, Loss: 0.08504591803135755\n",
      "Batch 110, Loss: 0.07825082887840876\n",
      "Batch 120, Loss: 0.07402816352052223\n",
      "Reset triggered due to batch size mismatch\n",
      "Average loss for epoch 1: 0.07182994614602504\n",
      "Model saved\n",
      "Epoch 2/1\n",
      "Batch 10, Loss: 0.014380470689310521\n",
      "Batch 20, Loss: 0.011746353080158343\n",
      "Batch 30, Loss: 0.010758333578077409\n",
      "Batch 40, Loss: 0.009818680875900012\n",
      "Batch 50, Loss: 0.009923647432612622\n",
      "Batch 60, Loss: 0.01098262778718081\n",
      "Batch 70, Loss: 0.011287995123552563\n",
      "Batch 80, Loss: 0.011420591634955174\n",
      "Batch 90, Loss: 0.011205457416902365\n",
      "Batch 100, Loss: 0.010976625398587904\n",
      "Batch 110, Loss: 0.010882718150887172\n",
      "Batch 120, Loss: 0.012331125424967263\n",
      "Reset triggered due to batch size mismatch\n",
      "Average loss for epoch 2: 0.012108937684938393\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# loss_function = nn.CrossEntropyLoss()\n",
    "combined_train_dataloader = DataLoader(combined_tensor_dataset, batch_size=best_parameters[\"batch_size\"], shuffle=False)\n",
    "loss_function = nn.HuberLoss(delta=1.0)\n",
    "loss_scores = [float('inf')]\n",
    "learning_rate = best_parameters[\"lr\"]\n",
    "combined_model = DynamicLSTM(best_parameters[\"hidden_dim\"], best_parameters[\"batch_size\"], best_parameters[\"layers\"], input=input_size)\n",
    "combined_model = combined_model.to(device).double()\n",
    "optimizer = optim.Adam(combined_model.parameters(), lr=learning_rate)\n",
    "#best_parameters[\"epochs\"]\n",
    "for epoch in range(2):\n",
    "    print(f\"Epoch {epoch+1}/{best_parameters['epochs']}\")\n",
    "    combined_model.hidden_reset()\n",
    "    combined_model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(combined_train_dataloader):\n",
    "        (input, worthless_input), label = batch\n",
    "        if input.shape[0] != best_parameters[\"batch_size\"]:\n",
    "            combined_model.batch_reset(input.shape[0])\n",
    "            print(\"Reset triggered due to batch size mismatch\")\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = combined_model(input).squeeze()\n",
    "        \n",
    "        # Ensure output and label shapes are compatible for the loss function\n",
    "        if output.shape != label.shape:\n",
    "            print(f\"Output shape: {output.shape}, Label shape: {label.shape}\")\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Batch {i+1}, Loss: {epoch_loss / (i+1)}\")\n",
    "    \n",
    "    average_epoch_loss = epoch_loss / len(combined_train_dataloader)\n",
    "    print(f\"Average loss for epoch {epoch+1}: {average_epoch_loss}\")\n",
    "    \n",
    "    if average_epoch_loss < loss_scores[-1]:\n",
    "        torch.save(combined_model.state_dict(), \"../other_pickle/Combined_Model.pth\")\n",
    "        print(\"Model saved\")\n",
    "    loss_scores.append(average_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9290, 1.1534, 1.0416, 1.2103, 1.0436, 1.0669, 1.0928, 0.9987, 1.0997,\n",
      "        1.1640, 0.7270, 1.1895, 1.0377, 1.1402, 1.2970, 0.9154],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.3575, 1.2703, 1.1188, 0.9746, 1.0865, 1.0709, 1.1736, 0.9679, 0.8655,\n",
      "        1.0319, 0.9190, 1.1729, 1.1673, 0.9426, 0.8711, 0.9764],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0874, 0.9179, 1.0392, 0.9915, 1.0692, 1.0836, 1.0692, 0.9821, 1.1044,\n",
      "        0.9663, 1.0983, 1.0145, 1.0293, 1.0636, 1.0434, 1.0552],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8632, 1.0098, 0.9554, 0.9732, 1.0403, 0.9483, 1.1221, 1.0869, 1.1044,\n",
      "        1.0818, 1.0436, 1.0389, 1.1127, 1.0120, 1.1092, 1.0715],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9905, 1.0481, 0.9490, 1.1292, 1.1478, 1.0356, 1.0879, 0.9608, 1.0638,\n",
      "        1.0855, 0.8914, 0.9178, 0.9302, 1.0781, 0.9373, 1.0438],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0915, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0915, 1.0915, 1.0915, 1.0915, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.4179, 1.0813, 1.0656, 1.0601, 0.8274, 0.7643, 1.0332, 0.8267, 0.8400,\n",
      "        1.2933, 1.1490, 1.8193, 1.3202, 1.6032, 1.2501, 1.4826],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.7293, 0.7143, 1.3231, 1.1949, 1.0632, 0.9734, 1.1377, 1.0693, 1.0873,\n",
      "        1.1487, 1.0255, 1.1567, 1.0066, 1.1167, 1.0231, 0.9930],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1786, 1.1437, 1.0013, 0.9857, 0.9395, 1.0561, 0.9657, 1.0327, 1.0584,\n",
      "        0.9070, 1.1102, 1.0153, 1.0763, 0.9805, 0.9842, 1.0615],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0730, 0.9647, 0.9652, 0.9637, 1.1095, 1.1836, 0.8933, 1.1341, 1.0108,\n",
      "        0.9604, 1.0525, 0.9901, 0.8814, 1.0398, 1.0811, 1.0174],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9826, 1.1137, 0.8959, 0.9447, 1.0580, 1.2474, 0.8712, 0.9686, 0.9725,\n",
      "        0.9660, 1.2328, 1.1776, 1.2030, 1.1745, 0.9320, 1.2243],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1064, 0.9713, 1.1253, 1.2211, 1.1545, 1.0913, 0.8365, 1.1300, 1.0668,\n",
      "        0.9310, 1.0409, 1.1008, 1.3836, 1.1339, 1.0050, 0.9969],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0851, 0.9747, 0.9798, 0.9242, 0.7500, 1.0319, 0.7652, 1.1092, 1.2773,\n",
      "        1.0313, 1.0134, 1.0216, 1.0284, 0.8964, 1.1867, 0.9741],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0009, 1.1217, 0.7523, 1.2230, 1.1258, 1.1861, 0.9973, 0.8599, 1.1625,\n",
      "        1.0180, 0.9769, 0.9820, 1.0572, 1.1362, 1.2009, 1.1389],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1660, 0.9253, 1.0262, 0.9711, 1.0425, 1.1525, 0.9462, 0.9513, 1.0134,\n",
      "        0.9298, 1.0171, 1.0209, 1.1812, 1.1347, 1.1327, 1.2521],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0915, 1.0914, 1.0915, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.2080, 1.0958, 1.0394, 1.0435, 0.9248, 1.1468, 0.9301, 1.0278, 0.9086,\n",
      "        0.4924, 1.0852, 0.9215, 1.6146, 1.0438, 0.9623, 1.0007],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1965, 1.1306, 1.0278, 1.1354, 0.9828, 0.9352, 1.0590, 1.1699, 1.0807,\n",
      "        1.0316, 0.9194, 1.0799, 0.9858, 1.1122, 0.7452, 1.0433],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9708, 1.0043, 1.1372, 0.9881, 0.9880, 0.9009, 1.0748, 0.8492, 0.9535,\n",
      "        0.9561, 1.1058, 1.2470, 0.8985, 1.0332, 1.0219, 1.0393],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0062, 1.0608, 0.9075, 1.0199, 1.1827, 1.0335, 0.9450, 1.0379, 0.9289,\n",
      "        0.9312, 0.7460, 0.9181, 1.0909, 0.9472, 0.9888, 1.0838],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0915, 1.0915, 1.0914, 1.0915, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0915, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.2549, 1.2514, 1.2321, 1.0524, 1.0761, 0.9706, 0.9489, 1.1185, 1.2844,\n",
      "        1.0114, 0.9499, 1.0753, 1.0389, 1.2332, 1.0081, 0.9501],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1167, 1.1120, 1.0439, 0.9101, 1.0621, 1.1731, 1.1357, 0.9597, 1.0716,\n",
      "        1.0916, 0.9824, 1.0841, 0.7644, 1.0693, 1.0727, 0.9145],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1100, 1.0943, 1.0162, 0.9630, 1.0334, 0.8713, 1.0655, 1.1344, 1.0754,\n",
      "        1.0677, 0.9246, 1.1262, 1.0093, 0.9643, 1.0265, 1.2772],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8733, 1.0579, 0.9254, 1.2128, 1.1476, 0.9843, 0.8706, 1.0907, 1.0855,\n",
      "        1.0806, 1.0970, 0.9513, 0.9530, 1.0364, 1.0133, 1.0822],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0374, 1.0062, 1.0021, 1.0912, 1.0034, 1.0337, 1.0661, 1.0016, 1.0546,\n",
      "        0.9563, 1.0601, 1.0026, 0.9633, 0.9663, 1.0169, 1.0660],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0413, 0.9990, 0.9122, 1.1057, 1.0139, 0.9755, 1.0281, 0.9366, 0.9272,\n",
      "        1.0149, 0.9396, 1.0975, 1.0736, 0.9774, 0.9747, 0.9914],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0683, 1.0631, 1.0695, 0.9395, 1.0492, 0.9291, 1.0774, 0.9373, 1.0156,\n",
      "        0.9419, 1.0517, 0.9629, 1.0249, 0.4234, 0.5547, 1.1970],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0915, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0915],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8116, 1.2357, 1.2647, 1.1045, 1.1244, 1.1605, 1.2958, 0.9657, 1.1730,\n",
      "        1.0401, 0.8730, 1.0289, 0.5104, 1.0840, 0.9725, 1.1120],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0915, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1481, 1.0508, 0.9314, 0.9844, 1.0128, 1.0040, 1.0184, 1.1199, 1.1761,\n",
      "        1.0864, 1.1051, 1.1300, 1.0052, 0.8791, 1.0771, 1.0617],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8729, 1.1522, 0.9665, 0.9695, 1.0244, 0.8765, 0.9918, 1.0977, 0.9843,\n",
      "        1.0338, 0.9922, 1.1529, 0.9785, 1.0466, 1.1343, 1.0114],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0915, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0915, 1.0915, 1.0915, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0412, 1.0675, 1.1867, 0.9366, 0.9913, 1.1575, 0.9679, 1.1607, 0.9869,\n",
      "        1.0446, 0.9516, 0.9199, 1.1189, 0.4702, 1.2181, 1.2922],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0915,\n",
      "        1.0915, 1.0915, 1.0915, 1.0915, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0817, 1.0237, 0.8382, 0.9757, 1.1795, 1.1030, 0.8702, 1.3258, 1.1932,\n",
      "        1.0505, 1.0448, 0.9943, 1.1517, 0.8875, 0.9640, 1.0153],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8280, 0.9817, 1.1251, 1.0119, 1.0755, 0.9406, 1.1564, 1.0318, 1.0240,\n",
      "        1.0449, 1.1191, 1.0708, 1.0008, 1.1669, 1.0689, 1.0430],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0579, 1.1770, 1.0708, 1.0312, 0.9519, 0.9513, 1.0606, 0.9453, 0.9279,\n",
      "        0.8947, 0.9928, 0.9954, 0.9906, 0.9601, 0.8669, 1.0331],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1419, 0.8901, 1.1617, 0.8124, 1.0770, 0.9204, 1.1975, 1.0487, 1.1204,\n",
      "        1.0242, 1.1857, 1.0228, 0.9070, 1.0287, 0.9660, 0.8122],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0585, 1.1433, 1.1134, 1.0067, 0.8466, 1.0964, 1.1202, 0.9499, 1.0592,\n",
      "        1.0411, 1.0783, 1.0965, 1.1109, 1.0136, 1.0363, 1.0090],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0173, 1.0332, 1.0982, 1.0402, 1.0110, 1.0446, 0.9834, 1.2473, 1.0914,\n",
      "        1.0013, 1.0970, 0.9350, 1.2432, 1.1990, 1.0636, 1.0062],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1691, 1.1641, 0.9842, 0.9063, 0.9255, 1.0333, 0.9939, 1.0819, 0.9413,\n",
      "        1.0655, 1.0872, 0.9861, 1.0900, 1.1277, 1.0544, 1.0326],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0203, 1.0369, 0.9263, 1.0906, 0.9944, 0.9995, 0.9783, 0.9932, 1.0751,\n",
      "        0.9996, 0.9986, 1.0530, 1.0587, 1.0319, 1.0224, 1.0309],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0765, 0.9800, 1.1763, 1.1032, 1.0056, 0.9723, 0.8972, 1.1877, 0.9853,\n",
      "        1.0813, 0.9946, 0.9847, 1.0345, 1.0129, 0.7843, 0.9056],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9642, 0.9761, 1.0937, 1.1182, 0.4326, 0.9649, 0.9609, 0.9755, 1.0039,\n",
      "        1.0263, 1.0362, 1.1368, 0.9235, 1.0047, 1.0782, 1.0448],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0915, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0445, 0.9722, 0.9204, 0.8944, 0.7656, 1.2066, 1.1387, 1.0542, 1.0152,\n",
      "        0.8981, 1.2978, 0.9460, 1.0865, 0.9888, 1.0083, 1.1062],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0584, 0.9213, 1.0652, 1.0895, 0.9812, 0.9519, 0.8944, 1.0890, 1.1794,\n",
      "        1.1355, 0.9930, 0.9454, 0.9590, 1.2378, 1.1104, 1.0694],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0590, 0.8161, 1.1473, 1.1421, 1.1641, 1.1524, 0.7353, 0.5139, 0.6702,\n",
      "        0.9863, 0.8096, 1.0977, 0.9406, 0.9094, 0.9806, 0.5164],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1040, 0.8001, 1.1243, 1.2199, 1.3006, 0.9157, 0.9207, 1.2294, 0.9717,\n",
      "        1.1746, 1.0310, 0.8750, 1.0412, 1.1954, 1.0000, 0.9691],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0753, 0.9719, 1.1929, 0.9733, 1.0451, 1.1026, 0.9111, 1.2873, 1.0579,\n",
      "        1.0800, 1.0098, 1.0674, 1.0251, 1.1261, 0.9285, 0.8934],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9485, 1.0210, 1.0807, 1.0792, 0.9856, 0.8988, 1.0557, 1.1233, 1.0236,\n",
      "        1.0307, 1.0227, 1.1087, 1.0634, 0.9647, 1.0747, 1.1263],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0582, 1.0628, 0.8870, 1.1056, 1.2685, 1.1286, 1.1770, 1.1796, 0.9862,\n",
      "        1.1465, 1.2406, 0.9501, 1.0118, 1.1484, 0.8912, 0.9521],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9389, 0.9083, 0.9188, 0.9454, 0.9262, 0.9755, 1.1528, 1.0131, 1.0414,\n",
      "        1.1629, 0.9416, 0.7921, 0.9876, 0.9139, 0.8503, 0.8487],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0915,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1235, 1.0843, 0.8889, 1.1756, 0.8081, 0.9042, 1.0001, 1.1030, 1.0675,\n",
      "        1.2419, 1.0206, 1.1418, 1.0102, 1.0481, 1.0377, 1.0390],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9698, 1.1158, 0.9561, 1.0733, 0.9463, 0.9384, 0.9883, 1.0391, 0.9807,\n",
      "        0.9950, 0.8582, 1.0197, 1.0240, 0.8802, 0.9182, 1.0902],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0139, 1.0736, 1.0272, 0.8854, 0.9662, 1.0671, 0.9751, 0.9360, 1.0018,\n",
      "        0.8332, 1.1710, 0.9943, 1.0066, 0.9716, 0.8533, 1.0527],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9932, 1.0275, 1.0599, 1.0878, 0.9562, 0.9853, 0.9965, 1.0632, 0.9160,\n",
      "        1.1331, 0.8974, 1.0504, 0.4806, 1.0806, 1.1133, 0.9930],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9848, 0.9713, 1.1057, 1.1742, 1.1284, 1.0230, 0.8903, 1.0210, 1.1414,\n",
      "        0.8830, 1.0760, 1.1622, 0.9280, 1.0614, 0.8586, 1.1650],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.2190, 1.2422, 1.0919, 0.9818, 1.0904, 1.1213, 0.8208, 0.9076, 1.0651,\n",
      "        1.1511, 1.0408, 1.1394, 0.9271, 0.7804, 0.2553, 1.1043],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0538, 1.0543, 0.9491, 1.0450, 0.8805, 1.1397, 0.9939, 1.0952, 1.0976,\n",
      "        1.2743, 1.0535, 1.0360, 0.9675, 1.1260, 1.1889, 1.0258],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0422, 1.0573, 1.0240, 0.9832, 0.9320, 0.9171, 1.2962, 0.9895, 1.3240,\n",
      "        1.1087, 0.8449, 1.3124, 1.0194, 1.3785, 1.1789, 0.9853],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0995, 1.1875, 0.8414, 0.9604, 0.9575, 1.2318, 0.9740, 1.2254, 1.0107,\n",
      "        0.8926, 1.0771, 1.0082, 1.0704, 1.1120, 1.0129, 1.0100],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9616, 1.0684, 1.0400, 0.9074, 1.0070, 0.9841, 1.0085, 1.0414, 0.9036,\n",
      "        1.0457, 0.9041, 1.1341, 0.9810, 1.0238, 0.9037, 0.4390],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9142, 0.7834, 0.9831, 0.9620, 0.8645, 1.1024, 1.0224, 0.9283, 1.2009,\n",
      "        1.0469, 0.9821, 1.0246, 0.7158, 1.0129, 0.8474, 1.1218],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9470, 1.0123, 1.0439, 1.0393, 0.9714, 1.1067, 1.0515, 1.0219, 0.8492,\n",
      "        0.9800, 1.0818, 1.0451, 1.0052, 1.0532, 0.9903, 1.0749],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0626, 1.0020, 0.9344, 1.0708, 0.9866, 0.9880, 0.7651, 0.9092, 0.8304,\n",
      "        1.1904, 0.9394, 1.1896, 0.9249, 1.1196, 1.1647, 1.1592],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0654, 1.0276, 0.9027, 1.0490, 1.0900, 1.0257, 0.9480, 0.9217, 1.0622,\n",
      "        1.1026, 1.1297, 1.0697, 1.0114, 1.1717, 1.1008, 1.1069],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9355, 0.8492, 1.1755, 1.1760, 1.0793, 0.9920, 0.9001, 0.9590, 0.9929,\n",
      "        1.0565, 1.0765, 1.1022, 1.0316, 0.9450, 1.1590, 0.9357],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9689, 0.9198, 0.9554, 0.9662, 1.0923, 0.8489, 1.2303, 1.0961, 1.0729,\n",
      "        1.0727, 1.0589, 1.0523, 1.0792, 0.9329, 0.9530, 0.9550],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1653, 1.0712, 1.0608, 0.4543, 0.9163, 1.1230, 1.1209, 1.0845, 1.0413,\n",
      "        1.0222, 1.2401, 1.0905, 0.9477, 1.0658, 0.8574, 1.0952],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0446, 1.0723, 1.1241, 1.1340, 1.1896, 1.0950, 1.0720, 1.1362, 1.1152,\n",
      "        1.0428, 0.7639, 1.1339, 1.1120, 0.8750, 0.9642, 1.0077],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9081, 1.0245, 1.1156, 1.0021, 0.9404, 1.1621, 1.1485, 0.9557, 1.0424,\n",
      "        0.9227, 0.8314, 1.0306, 0.9620, 1.0160, 1.0678, 0.5873],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.2384, 1.1080, 1.2348, 1.1591, 0.9830, 0.9205, 0.9781, 1.1089, 0.8925,\n",
      "        0.8572, 1.0939, 1.0645, 0.9881, 0.9467, 1.0276, 1.1053],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8562, 1.1614, 1.0478, 1.1148, 1.0491, 0.9634, 1.0717, 1.0176, 0.8352,\n",
      "        0.9598, 0.8799, 1.1517, 0.8902, 0.8628, 1.0129, 1.1205],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9225, 1.0546, 0.9218, 0.9522, 0.9387, 0.9071, 1.1756, 1.1184, 1.0879,\n",
      "        1.0476, 1.1039, 1.0727, 1.0183, 1.0705, 0.8788, 1.2370],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0857, 1.0778, 1.1394, 0.9263, 1.2406, 1.1352, 0.9947, 0.9041, 0.8443,\n",
      "        1.1389, 1.1121, 0.8789, 1.1174, 1.1363, 1.0615, 1.0249],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9453, 1.0368, 1.2298, 1.0373, 0.9650, 0.9052, 1.2439, 1.0674, 1.0724,\n",
      "        0.8510, 1.1640, 1.1982, 0.9470, 1.2417, 0.9632, 1.0457],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9121, 1.0599, 0.9381, 1.0904, 0.8250, 0.9586, 1.1435, 1.1225, 1.1648,\n",
      "        1.0304, 0.7089, 1.0855, 1.1331, 1.2079, 1.1898, 1.0383],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0291, 1.1549, 0.8911, 0.8485, 1.0363, 1.0579, 1.0026, 1.2606, 0.8669,\n",
      "        1.1179, 0.9254, 0.9051, 1.0328, 0.9351, 1.0721, 0.8234],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9565, 1.0664, 1.0170, 1.0850, 0.7683, 0.9864, 0.8656, 1.1139, 1.0099,\n",
      "        0.4653, 1.3452, 0.8352, 1.3759, 1.2833, 1.0877, 1.0444],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0789, 1.2430, 1.0875, 1.1310, 1.1455, 1.0867, 0.9202, 1.1747, 1.0916,\n",
      "        0.9344, 1.1402, 1.1366, 1.0313, 1.1482, 1.0119, 1.2388],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0572, 1.0438, 1.1028, 1.1088, 1.1122, 1.0802, 0.9061, 0.8911, 0.9322,\n",
      "        0.9916, 1.1557, 1.2046, 0.9731, 1.0259, 0.9505, 1.0809],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0764, 0.9483, 1.0592, 1.1126, 1.1107, 0.9243, 1.0379, 1.1054, 0.9460,\n",
      "        1.1868, 1.1707, 1.0257, 0.9798, 0.8908, 0.9390, 1.1457],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0734, 1.0875, 1.1621, 1.1114, 1.0647, 0.8981, 0.9378, 1.0910, 1.1071,\n",
      "        1.1344, 1.0571, 0.9545, 0.9324, 0.9891, 1.1772, 0.9709],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0915, 1.0914, 1.0915, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8318, 0.9251, 1.1268, 0.8362, 0.8558, 0.7841, 0.9294, 0.8397, 1.0270,\n",
      "        1.0154, 0.9543, 0.8598, 1.1476, 1.1356, 1.0014, 1.0413],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1679, 1.0414, 1.0509, 1.0422, 0.9039, 0.9770, 0.9899, 0.8932, 1.0448,\n",
      "        1.1577, 1.0602, 0.9819, 0.8912, 1.1988, 1.0472, 0.9099],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0990, 0.7857, 1.1577, 0.9645, 1.0439, 1.1200, 1.0273, 0.9900, 1.0997,\n",
      "        1.0574, 0.9762, 0.9930, 1.0613, 0.9140, 0.9700, 0.9638],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8916, 0.9583, 1.1931, 1.0953, 0.9484, 1.1727, 0.9917, 1.0579, 1.0386,\n",
      "        0.4270, 1.0285, 0.8395, 1.4560, 1.2522, 1.0909, 1.0674],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.7867, 0.9228, 1.1398, 1.1228, 1.0008, 0.9018, 1.1103, 1.1645, 0.9621,\n",
      "        0.9762, 1.1312, 1.2136, 0.9681, 0.8509, 0.9514, 0.9828],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0019, 1.2329, 1.1152, 1.1631, 1.0045, 1.2252, 1.1833, 1.1268, 0.9666,\n",
      "        0.7716, 0.9590, 1.2486, 0.9000, 0.9635, 1.2467, 0.5914],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.4004, 1.1785, 1.0981, 1.0982, 1.1708, 1.1486, 0.9920, 0.9164, 1.0775,\n",
      "        1.1403, 1.1086, 1.1056, 1.0283, 1.1343, 1.0237, 1.0303],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9543, 0.8045, 0.9793, 1.1957, 0.9744, 1.1700, 1.1979, 1.0092, 1.1208,\n",
      "        0.9911, 1.0473, 0.9925, 0.8977, 0.9452, 0.9506, 1.1697],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0321, 1.0580, 0.9267, 1.0393, 1.0312, 1.0862, 1.0399, 1.1246, 0.9848,\n",
      "        1.0210, 1.0587, 1.0199, 0.9487, 0.9848, 0.9862, 1.0277],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1776, 0.9880, 0.9729, 1.0199, 0.8513, 1.0741, 0.8686, 1.0317, 1.0536,\n",
      "        1.0726, 0.9715, 1.1009, 1.1011, 1.2615, 0.9245, 0.9941],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.8796, 1.0985, 0.8206, 0.9215, 0.8561, 1.0778, 1.1035, 1.1126, 1.0836,\n",
      "        1.0919, 1.0222, 0.9204, 1.0540, 1.1541, 0.9797, 0.9711],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0286, 1.0457, 1.1452, 1.0791, 0.9077, 1.0588, 1.0554, 1.0565, 1.0685,\n",
      "        1.0988, 1.1453, 0.9791, 1.0319, 0.9165, 1.1020, 0.9528],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9701, 0.8797, 0.9346, 0.8809, 1.1354, 0.9501, 1.0664, 1.1470, 0.6802,\n",
      "        1.3089, 1.1612, 1.2953, 1.1366, 0.8932, 0.9130, 1.0230],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.1450, 1.1880, 1.0407, 1.1160, 0.9781, 1.1504, 1.1329, 0.9732, 0.9741,\n",
      "        0.9667, 0.9822, 0.9806, 0.9550, 0.9985, 1.0659, 1.1130],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9714, 0.9399, 1.2151, 0.9481, 0.9378, 0.9327, 0.8263, 1.0178, 0.8916,\n",
      "        1.1786, 0.9247, 0.9527, 1.1170, 0.8711, 0.9764, 1.0584],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0652, 1.0928, 1.1011, 1.0012, 0.9715, 1.0157, 1.0108, 0.9135, 1.1243,\n",
      "        0.9597, 0.9884, 0.9696, 0.4460, 1.3044, 1.2302, 1.0176],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0711, 1.1873, 0.9955, 0.8645, 1.0336, 1.1831, 0.8045, 1.1062, 1.1904,\n",
      "        1.0573, 1.1388, 0.8153, 1.2542, 1.3246, 1.2705, 0.8851],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0316, 0.9737, 1.3301, 0.8283, 0.9012, 0.9032, 0.9710, 1.0297, 0.9781,\n",
      "        0.9368, 1.1668, 1.1038, 1.1114, 1.0062, 1.0007, 1.1410],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9448, 0.9179, 1.1492, 0.9955, 0.9749, 0.7893, 1.0864, 1.1640, 1.1324,\n",
      "        1.0732, 1.0246, 0.9933, 0.9505, 0.9637, 1.0549, 1.0088],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0292, 0.9223, 1.0692, 0.9928, 0.9036, 1.0801, 1.1425, 1.1376, 1.1655,\n",
      "        1.0345, 0.9965, 0.7956, 1.0738, 1.1471, 1.1897, 1.0709],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([1.0396, 0.9896, 0.9585, 0.7823, 0.9158, 1.1187, 1.1722, 0.8409, 0.8604,\n",
      "        1.1058, 0.9966, 0.9809, 1.1334, 1.1019, 0.9282, 0.7988],\n",
      "       dtype=torch.float64)\n",
      "tensor([1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0915, 1.0915, 1.0914, 1.0914,\n",
      "        1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914, 1.0914],\n",
      "       dtype=torch.float64, grad_fn=<SqueezeBackward0>) tensor([0.9767, 0.9866, 1.0618, 1.0580, 0.9765, 0.9311, 1.0537, 0.9956, 0.9362,\n",
      "        0.9102, 1.0894, 0.9613, 1.0026, 1.2807, 1.0610, 0.9961],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "combined_model.load_state_dict(torch.load(\"../other_pickle/Combined_Model.pth\"))\n",
    "combined_model.eval()\n",
    "for i, batch in list(enumerate(combined_train_dataloader))[:100]:\n",
    "    (input, worthless_input), label = batch\n",
    "    output = combined_model(input).squeeze()\n",
    "    # loss = loss_function(output, label)\n",
    "    # print(F.softmax(output, dim=1), label)\n",
    "    print(output, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
