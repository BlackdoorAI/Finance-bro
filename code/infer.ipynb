{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, dataset, sequence_length):\n",
    "        self.dataset = dataset\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = [], []\n",
    "        for i in range(idx, idx + self.sequence_length):\n",
    "            data, label = self.dataset[i]\n",
    "            x.append(data)\n",
    "            y.append(label)\n",
    "        _, y = self.dataset[idx + self.sequence_length]\n",
    "        return torch.stack(x), y\n",
    "\n",
    "\n",
    "class SlidingWindowDatasetTEST(Dataset):\n",
    "    def __init__(self, dataset, sequence_length):\n",
    "        self.dataset = dataset\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx:idx+self.sequence_length]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 400\n",
    "HIDDEN_SIZE = 200\n",
    "EMBED_SIZE = 30\n",
    "LAYERS = 8\n",
    "SEQUENCE_LENGTH = 20\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# train_tensor = train_tensor.to(device)\n",
    "# train_label_tensor = train_label_tensor.to(device)\n",
    "# test_tensor = test_tensor.to(device)\n",
    "# validate_tensor = validate_tensor.to(device)\n",
    "# validate_label_tensor = validate_label_tensor.to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_tensor, train_label_tensor)\n",
    "train_dataset = SlidingWindowDataset(train_dataset,SEQUENCE_LENGTH)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_tensor)\n",
    "###problem here###\n",
    "test_dataset = SlidingWindowDatasetTEST(test_dataset,SEQUENCE_LENGTH)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "validate_dataset = torch.utils.data.TensorDataset(validate_tensor,validate_label_tensor)\n",
    "validate_dataset = SlidingWindowDataset(validate_dataset,SEQUENCE_LENGTH)\n",
    "validate_dataloader = torch.utils.data.DataLoader(validate_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "class LSTMSales(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, batch_size, layers):\n",
    "        super(LSTMSales, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.layers_num = layers\n",
    "\n",
    "        #Embedding layers\n",
    "        self.store_number = nn.Embedding(54,embedding_dim)\n",
    "        self.family = nn.Embedding(33,embedding_dim)\n",
    "        self.store_type = nn.Embedding(5,embedding_dim)\n",
    "        self.cluster = nn.Embedding(17,embedding_dim)\n",
    "        self.holiday = nn.Embedding(5,embedding_dim)\n",
    "        \n",
    "        #input is all the embedding vectors plus all the other variables\n",
    "        self.lstm = nn.LSTM(120, hidden_dim, num_layers=layers, batch_first=True) \n",
    "        self.hidden = (torch.zeros(layers,batch_size,hidden_dim),torch.zeros(layers,batch_size,hidden_dim))\n",
    "        \n",
    "        #normalize outputs\n",
    "        #self.bn1 = nn.BatchNorm1d(out_features)\n",
    "\n",
    "        self.hidden2sales = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, batch_tensor):\n",
    "        #Trying to predict the log of (the sales + 1) \n",
    "        # store_number =self.store_number(batch_tensor[:,:,0].long())\n",
    "        # family = self.family(batch_tensor[:,:,1].long())\n",
    "        # store_type = self.store_type(batch_tensor[:,:,3].long())\n",
    "        # cluster = self.cluster(batch_tensor[:,:,4].long())\n",
    "        # holiday = self.holiday(batch_tensor[:,:,7].long())\n",
    "        # batch_tensor = batch_tensor[:,:,[2,5,6,8,9,10]]\n",
    "        # input = torch.cat([batch_tensor,store_number,family,store_type,cluster,holiday],dim=2)\n",
    "        lstm_out, self.hidden = self.lstm(batch_tensor)\n",
    "        last_timestep_output = lstm_out[:, -1, :]\n",
    "        sales = self.hidden2sales(last_timestep_output)\n",
    "        sales =sales\n",
    "        return sales\n",
    "    \n",
    "    def hidden_reset(self):\n",
    "        #reset the hidden and cell state after each epoch\n",
    "        self.hidden = (torch.zeros(self.layers_num,self.batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,self.batch_size,self.hidden_dim))\n",
    "    def batch_reset(self,batch_size):\n",
    "        self.hidden = (torch.zeros(self.layers_num,batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,batch_size,self.hidden_dim))\n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
