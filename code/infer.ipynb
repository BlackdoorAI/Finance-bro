{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from infer_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_reload = [\"infer_functions\"]\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "    __import__(module_name)\n",
    "    module = sys.modules[module_name]\n",
    "    globals().update({name: getattr(module, name) for name in dir(module) if not name.startswith('_')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catting AAPL.csv\n",
      "Catting ABBV.csv\n",
      "Catting ABT.csv\n",
      "Catting ACN.csv\n",
      "Catting ADBE.csv\n",
      "Catting AMAT.csv\n",
      "Catting AMD.csv\n",
      "Catting AMGN.csv\n",
      "Catting AMZN.csv\n",
      "Catting AVGO.csv\n",
      "Catting BA.csv\n",
      "Catting BKNG.csv\n",
      "Catting CAT.csv\n",
      "Catting CMCSA.csv\n",
      "Catting COP.csv\n",
      "Catting COST.csv\n",
      "Catting CRM.csv\n",
      "Catting CSCO.csv\n",
      "Catting CVX.csv\n",
      "Catting DHR.csv\n",
      "Catting DIS.csv\n",
      "Catting HD.csv\n",
      "Catting HON.csv\n",
      "Catting IBM.csv\n",
      "Catting INTC.csv\n",
      "Catting INTU.csv\n",
      "Catting JNJ.csv\n",
      "Catting KO.csv\n",
      "Catting LIN.csv\n",
      "Catting LLY.csv\n",
      "Catting LOW.csv\n",
      "Catting MA.csv\n",
      "Catting MCD.csv\n",
      "Catting MRK.csv\n",
      "Catting MSFT.csv\n",
      "Catting NKE.csv\n",
      "Catting NOW.csv\n",
      "Catting NVDA.csv\n",
      "Catting ORCL.csv\n",
      "Catting PEP.csv\n",
      "Catting PFE.csv\n",
      "Catting PG.csv\n",
      "Catting PM.csv\n",
      "Catting QCOM.csv\n",
      "Catting RTX.csv\n",
      "Catting SPGI.csv\n",
      "Catting TMO.csv\n",
      "Catting TMUS.csv\n",
      "Catting TSLA.csv\n",
      "Catting TXN.csv\n",
      "Catting UBER.csv\n",
      "Catting UNP.csv\n",
      "Catting UPS.csv\n",
      "Catting V.csv\n",
      "Catting VZ.csv\n",
      "Catting WMT.csv\n",
      "Catting XOM.csv\n"
     ]
    }
   ],
   "source": [
    "static_tensor_dataset = create_tensor_dataset(\"static\", 4, limit=100, categories= 0, averages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catting AAPL.csv\n",
      "Catting ABBV.csv\n",
      "Catting ABT.csv\n",
      "Catting ACN.csv\n",
      "Catting ADBE.csv\n",
      "Catting AMAT.csv\n",
      "Catting AMD.csv\n",
      "Catting AMGN.csv\n",
      "Catting AMZN.csv\n",
      "Catting AVGO.csv\n",
      "Catting BA.csv\n",
      "Catting BKNG.csv\n",
      "Catting BLK.csv\n",
      "Catting BX.csv\n",
      "Catting CAT.csv\n",
      "Catting COP.csv\n",
      "Catting CRM.csv\n",
      "Catting CSCO.csv\n",
      "Catting CVX.csv\n",
      "Catting DHR.csv\n",
      "Catting DIS.csv\n",
      "Catting GE.csv\n",
      "Catting HD.csv\n",
      "Catting HON.csv\n",
      "Catting IBM.csv\n",
      "Catting INTC.csv\n",
      "Catting INTU.csv\n",
      "Catting JNJ.csv\n",
      "Catting KO.csv\n",
      "Catting LIN.csv\n",
      "Catting LLY.csv\n",
      "Catting LOW.csv\n",
      "Catting MA.csv\n",
      "Catting MCD.csv\n",
      "Catting META.csv\n",
      "Catting MRK.csv\n",
      "Catting MSFT.csv\n",
      "Catting NFLX.csv\n",
      "Catting NOW.csv\n",
      "Catting NVDA.csv\n",
      "Catting ORCL.csv\n",
      "Catting PEP.csv\n",
      "Catting PFE.csv\n",
      "Catting PG.csv\n",
      "Catting PLD.csv\n",
      "Catting PM.csv\n",
      "Catting QCOM.csv\n",
      "Catting RTX.csv\n",
      "Catting SPGI.csv\n",
      "Catting TMO.csv\n",
      "Catting TMUS.csv\n",
      "Catting TSLA.csv\n",
      "Catting TXN.csv\n",
      "Catting UBER.csv\n",
      "Catting UNH.csv\n",
      "Catting UNP.csv\n",
      "Catting VZ.csv\n",
      "Catting WMT.csv\n",
      "tensor([[[1.5255e-05, 6.9777e-06, 1.1259e-05,  ..., 1.7972e-05,\n",
      "          1.6365e-05, 2.3616e-05],\n",
      "         [1.5761e-05, 7.0899e-06, 1.3775e-05,  ..., 2.5506e-05,\n",
      "          1.8180e-05, 8.8955e-06],\n",
      "         [2.0827e-05, 7.2160e-06, 1.7574e-05,  ..., 3.4662e-05,\n",
      "          2.4180e-05, 4.4263e-05],\n",
      "         [1.5593e-05, 4.6963e-06, 1.0889e-05,  ..., 1.6415e-05,\n",
      "          1.6350e-05, 4.9416e-05]],\n",
      "\n",
      "        [[1.7572e-05, 6.9777e-06, 1.9013e-05,  ..., 2.3573e-05,\n",
      "          2.2302e-05, 3.0932e-05],\n",
      "         [1.5537e-05, 7.0899e-06, 1.1481e-05,  ..., 1.8358e-05,\n",
      "          1.6685e-05, 2.4297e-05],\n",
      "         [1.6040e-05, 7.2160e-06, 1.4142e-05,  ..., 2.5966e-05,\n",
      "          1.8489e-05, 9.1133e-06],\n",
      "         [2.1213e-05, 7.3539e-06, 1.7919e-05,  ..., 3.5299e-05,\n",
      "          2.4603e-05, 4.5696e-05]],\n",
      "\n",
      "        [[3.3433e-05, 9.2020e-06, 2.7435e-05,  ..., 5.7413e-05,\n",
      "          3.9157e-05, 5.6327e-05],\n",
      "         [2.6209e-05, 9.3499e-06, 2.2851e-05,  ..., 4.5585e-05,\n",
      "          3.0810e-05, 4.9511e-05],\n",
      "         [2.2146e-05, 9.5161e-06, 2.1507e-05,  ..., 4.3612e-05,\n",
      "          2.6942e-05, 2.4795e-05],\n",
      "         [2.5964e-05, 9.6980e-06, 2.4993e-05,  ..., 5.2741e-05,\n",
      "          3.1848e-05, 6.7294e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[8.7505e-04, 3.6902e-04, 3.7768e-04,  ..., 1.8325e-04,\n",
      "          7.8020e-04, 3.6320e-05],\n",
      "         [9.0283e-04, 3.7482e-04, 3.9280e-04,  ..., 1.9629e-04,\n",
      "          8.1335e-04, 3.5852e-04],\n",
      "         [9.1438e-04, 3.8036e-04, 3.7500e-04,  ..., 1.7229e-04,\n",
      "          8.0844e-04, 1.9105e-04],\n",
      "         [9.8052e-04, 3.9005e-04, 3.9793e-04,  ..., 1.7874e-04,\n",
      "          8.6566e-04, 2.9130e-04]],\n",
      "\n",
      "        [[1.0428e-03, 3.6960e-04, 4.0523e-04,  ..., 1.7429e-04,\n",
      "          8.8220e-04, 3.2302e-04],\n",
      "         [8.9259e-04, 3.7541e-04, 3.8574e-04,  ..., 1.8748e-04,\n",
      "          7.9669e-04, 3.7427e-05],\n",
      "         [9.2027e-04, 3.8096e-04, 4.0391e-04,  ..., 2.0014e-04,\n",
      "          8.2849e-04, 3.6788e-04],\n",
      "         [9.3281e-04, 3.9067e-04, 3.8296e-04,  ..., 1.7573e-04,\n",
      "          8.2389e-04, 1.9755e-04]],\n",
      "\n",
      "        [[9.2104e-04, 3.7120e-04, 3.8731e-04,  ..., 2.2042e-04,\n",
      "          8.0580e-04, 2.2302e-05],\n",
      "         [1.0666e-03, 3.7703e-04, 4.1502e-04,  ..., 1.7881e-04,\n",
      "          9.0333e-04, 3.3378e-04],\n",
      "         [9.1234e-04, 3.8261e-04, 3.9774e-04,  ..., 1.9168e-04,\n",
      "          8.1375e-04, 3.8509e-05],\n",
      "         [9.4140e-04, 3.9236e-04, 4.1362e-04,  ..., 2.0470e-04,\n",
      "          8.4664e-04, 3.8144e-04]]], dtype=torch.float64) tensor([ 0.2713,  0.1489,  0.2096,  ...,  0.0109, -0.0551,  0.0239],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dynamic_tensor_dataset = create_tensor_dataset(\"dynamic\", 4, limit=100, categories= 0, averages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977\n",
      "((tensor([[1.5255e-05, 6.9777e-06, 1.1259e-05, 3.5437e-05, 1.7395e-05, 1.7972e-05,\n",
      "         1.6365e-05, 2.3616e-05],\n",
      "        [1.5761e-05, 7.0899e-06, 1.3775e-05, 6.9498e-05, 2.2771e-05, 2.5506e-05,\n",
      "         1.8180e-05, 8.8955e-06],\n",
      "        [2.0827e-05, 7.2160e-06, 1.7574e-05, 3.0669e-05, 3.3413e-05, 3.4662e-05,\n",
      "         2.4180e-05, 4.4263e-05],\n",
      "        [1.5593e-05, 4.6963e-06, 1.0889e-05, 1.3764e-05, 1.7267e-05, 1.6415e-05,\n",
      "         1.6350e-05, 4.9416e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 1.2730e+11], dtype=torch.float64)), tensor(0.2713, dtype=torch.float64))\n",
      "((tensor([[1.7572e-05, 6.9777e-06, 1.9013e-05, 2.7140e-05, 3.5838e-05, 2.3573e-05,\n",
      "         2.2302e-05, 3.0932e-05],\n",
      "        [1.5537e-05, 7.0899e-06, 1.1481e-05, 3.6000e-05, 1.7275e-05, 1.8358e-05,\n",
      "         1.6685e-05, 2.4297e-05],\n",
      "        [1.6040e-05, 7.2160e-06, 1.4142e-05, 7.1264e-05, 2.4004e-05, 2.5966e-05,\n",
      "         1.8489e-05, 9.1133e-06],\n",
      "        [2.1213e-05, 7.3539e-06, 1.7919e-05, 3.0898e-05, 3.4276e-05, 3.5299e-05,\n",
      "         2.4603e-05, 4.5696e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 1.6337e+11], dtype=torch.float64)), tensor(0.1489, dtype=torch.float64))\n",
      "((tensor([[3.3433e-05, 9.2020e-06, 2.7435e-05, 2.0996e-06, 5.9791e-05, 5.7413e-05,\n",
      "         3.9157e-05, 5.6327e-05],\n",
      "        [2.6209e-05, 9.3499e-06, 2.2851e-05, 2.7355e-05, 4.4836e-05, 4.5585e-05,\n",
      "         3.0810e-05, 4.9511e-05],\n",
      "        [2.2146e-05, 9.5161e-06, 2.1507e-05, 6.3646e-05, 4.4664e-05, 4.3612e-05,\n",
      "         2.6942e-05, 2.4795e-05],\n",
      "        [2.5964e-05, 9.6980e-06, 2.4993e-05, 5.3985e-05, 5.0349e-05, 5.2741e-05,\n",
      "         3.1848e-05, 6.7294e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.6705e+11], dtype=torch.float64)), tensor(0.2096, dtype=torch.float64))\n",
      "((tensor([[3.7375e-05, 1.7914e-05, 3.7005e-05, 5.6580e-05, 8.2397e-05, 8.2299e-05,\n",
      "         4.7083e-05, 6.3479e-05],\n",
      "        [4.2872e-05, 1.8202e-05, 3.8030e-05, 4.3677e-05, 8.2060e-05, 8.3564e-05,\n",
      "         5.2038e-05, 9.9908e-05],\n",
      "        [3.4362e-05, 9.4364e-06, 2.8481e-05, 2.1688e-06, 6.2069e-05, 5.9202e-05,\n",
      "         4.0261e-05, 5.8873e-05],\n",
      "        [2.6940e-05, 9.6168e-06, 2.3721e-05, 2.8023e-05, 4.8080e-05, 4.6865e-05,\n",
      "         3.1616e-05, 5.1927e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 3.2387e+11], dtype=torch.float64)), tensor(-0.0097, dtype=torch.float64))\n",
      "((tensor([[4.2554e-05, 1.7847e-05, 4.3014e-05, 3.3706e-05, 1.0020e-04, 9.7660e-05,\n",
      "         5.4330e-05, 1.1677e-04],\n",
      "        [3.7921e-05, 1.8134e-05, 3.7593e-05, 5.7262e-05, 8.1520e-05, 8.3750e-05,\n",
      "         4.7822e-05, 6.5064e-05],\n",
      "        [4.3467e-05, 1.8456e-05, 3.8898e-05, 4.4618e-05, 8.6179e-05, 8.4750e-05,\n",
      "         5.2724e-05, 1.0197e-04],\n",
      "        [3.4868e-05, 9.5806e-06, 2.8931e-05, 2.1768e-06, 6.3433e-05, 6.0064e-05,\n",
      "         4.0811e-05, 6.0551e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 3.0179e+11], dtype=torch.float64)), tensor(0.1655, dtype=torch.float64))\n",
      "((tensor([[4.3261e-05, 1.7802e-05, 4.0955e-05, 4.0087e-05, 9.0579e-05, 9.0466e-05,\n",
      "         5.3622e-05, 9.9036e-05],\n",
      "        [4.3229e-05, 1.8088e-05, 4.3752e-05, 3.4155e-05, 9.9256e-05, 9.9506e-05,\n",
      "         5.5251e-05, 1.1984e-04],\n",
      "        [3.8495e-05, 1.8409e-05, 3.8498e-05, 5.8569e-05, 8.5718e-05, 8.5044e-05,\n",
      "         4.8512e-05, 6.6489e-05],\n",
      "        [4.4162e-05, 1.8761e-05, 3.9561e-05, 4.4838e-05, 8.8183e-05, 8.6091e-05,\n",
      "         5.3512e-05, 1.0501e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 3.7482e+11], dtype=torch.float64)), tensor(0.0210, dtype=torch.float64))\n",
      "((tensor([[5.1422e-05, 2.8138e-05, 5.3501e-05, 5.4669e-05, 1.1965e-04, 1.1918e-04,\n",
      "         6.5864e-05, 9.0914e-05],\n",
      "        [5.3156e-05, 2.8591e-05, 6.7546e-05, 1.7510e-04, 1.5650e-04, 1.6182e-04,\n",
      "         7.5132e-05, 1.4399e-04],\n",
      "        [6.5896e-05, 2.9099e-05, 7.7338e-05, 7.8744e-05, 1.8545e-04, 1.8569e-04,\n",
      "         9.0346e-05, 1.9126e-04],\n",
      "        [4.5281e-05, 1.8601e-05, 4.3345e-05, 4.1711e-05, 9.6446e-05, 9.4987e-05,\n",
      "         5.6089e-05, 1.0685e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 5.4430e+11], dtype=torch.float64)), tensor(0.1331, dtype=torch.float64))\n",
      "((tensor([[5.4732e-05, 2.8068e-05, 5.1256e-05, 9.1109e-05, 1.1122e-04, 1.1242e-04,\n",
      "         6.7469e-05, 6.3279e-05],\n",
      "        [5.2239e-05, 2.8519e-05, 5.4420e-05, 5.5397e-05, 1.1853e-04, 1.2143e-04,\n",
      "         6.6983e-05, 9.3302e-05],\n",
      "        [5.3962e-05, 2.9026e-05, 6.9174e-05, 1.7910e-04, 1.6457e-04, 1.6433e-04,\n",
      "         7.6219e-05, 1.4715e-04],\n",
      "        [6.6950e-05, 2.9581e-05, 7.8657e-05, 7.9133e-05, 1.8977e-04, 1.8863e-04,\n",
      "         9.1697e-05, 1.9696e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 6.5627e+11], dtype=torch.float64)), tensor(-0.1985, dtype=torch.float64))\n",
      "((tensor([[6.7787e-05, 6.3708e-05, 5.8087e-05, 1.2092e-04, 1.2891e-04, 1.2877e-04,\n",
      "         8.1651e-05, 1.1683e-04],\n",
      "        [8.2951e-05, 6.4733e-05, 7.6301e-05, 9.8046e-05, 1.7536e-04, 1.8026e-04,\n",
      "         1.0407e-04, 2.4174e-04],\n",
      "        [5.6628e-05, 2.8975e-05, 5.3567e-05, 9.4739e-05, 1.1623e-04, 1.1670e-04,\n",
      "         6.9833e-05, 6.6581e-05],\n",
      "        [5.4055e-05, 2.9529e-05, 5.6867e-05, 5.7128e-05, 1.2795e-04, 1.2567e-04,\n",
      "         6.9192e-05, 9.8509e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 4.1568e+11], dtype=torch.float64)), tensor(-0.0201, dtype=torch.float64))\n",
      "((tensor([[5.7062e-05, 6.3736e-05, 4.6294e-05, 1.4969e-04, 9.3205e-05, 9.4389e-05,\n",
      "         6.6175e-05, 6.6180e-05],\n",
      "        [6.9067e-05, 6.4761e-05, 5.9259e-05, 1.2290e-04, 1.2807e-04, 1.3159e-04,\n",
      "         8.3282e-05, 1.2025e-04],\n",
      "        [8.4456e-05, 6.5912e-05, 7.8371e-05, 1.0058e-04, 1.8494e-04, 1.8359e-04,\n",
      "         1.0589e-04, 2.4776e-04],\n",
      "        [5.7703e-05, 2.9542e-05, 5.4642e-05, 9.5488e-05, 1.1929e-04, 1.1889e-04,\n",
      "         7.1086e-05, 6.8767e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 3.7220e+11], dtype=torch.float64)), tensor(0.1393, dtype=torch.float64))\n",
      "((tensor([[6.1935e-05, 6.5852e-05, 5.0941e-05, 1.0240e-04, 1.0484e-04, 1.0631e-04,\n",
      "         7.2530e-05, 9.1502e-05],\n",
      "        [6.0043e-05, 6.6910e-05, 4.8774e-05, 1.5711e-04, 9.5633e-05, 9.9615e-05,\n",
      "         6.9706e-05, 7.0348e-05],\n",
      "        [7.2623e-05, 6.8100e-05, 6.2859e-05, 1.3020e-04, 1.3949e-04, 1.3841e-04,\n",
      "         8.7509e-05, 1.2728e-04],\n",
      "        [8.8877e-05, 6.9401e-05, 8.2560e-05, 1.0469e-04, 1.9601e-04, 1.9317e-04,\n",
      "         1.1132e-04, 2.6428e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 4.3858e+11], dtype=torch.float64)), tensor(0.1282, dtype=torch.float64))\n",
      "((tensor([[7.3681e-05, 7.9791e-05, 6.7130e-05, 1.0655e-04, 1.4532e-04, 1.4674e-04,\n",
      "         8.9987e-05, 1.4245e-04],\n",
      "        [9.3951e-05, 8.1073e-05, 8.3326e-05, 1.8498e-04, 1.8453e-04, 1.9256e-04,\n",
      "         1.1576e-04, 2.4938e-04],\n",
      "        [6.5382e-05, 6.9360e-05, 5.4318e-05, 1.0864e-04, 1.1179e-04, 1.1259e-04,\n",
      "         7.6596e-05, 9.8231e-05],\n",
      "        [6.3391e-05, 7.0686e-05, 5.2002e-05, 1.6531e-04, 1.0533e-04, 1.0519e-04,\n",
      "         7.3467e-05, 7.5781e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 4.7887e+11], dtype=torch.float64)), tensor(0.1938, dtype=torch.float64))\n",
      "((tensor([[6.4628e-05, 8.2626e-05, 5.7074e-05, 1.4719e-04, 1.1405e-04, 1.1494e-04,\n",
      "         7.6416e-05, 9.5584e-05],\n",
      "        [7.7706e-05, 8.3954e-05, 7.0887e-05, 1.1209e-04, 1.4944e-04, 1.5522e-04,\n",
      "         9.5005e-05, 1.5176e-04],\n",
      "        [9.9012e-05, 8.5447e-05, 8.8588e-05, 1.9642e-04, 2.0143e-04, 2.0300e-04,\n",
      "         1.2191e-04, 2.6457e-04],\n",
      "        [6.8961e-05, 7.3197e-05, 5.7352e-05, 1.1334e-04, 1.1875e-04, 1.1874e-04,\n",
      "         8.0706e-05, 1.0502e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 5.5461e+11], dtype=torch.float64)), tensor(0.0883, dtype=torch.float64))\n",
      "((tensor([[7.4207e-05, 8.3203e-05, 6.2441e-05, 1.1285e-04, 1.2550e-04, 1.2568e-04,\n",
      "         8.6593e-05, 1.1515e-04],\n",
      "        [6.6279e-05, 8.4540e-05, 5.8606e-05, 1.5057e-04, 1.1405e-04, 1.1823e-04,\n",
      "         7.8452e-05, 9.9027e-05],\n",
      "        [7.9634e-05, 8.6043e-05, 7.3285e-05, 1.1574e-04, 1.5863e-04, 1.5912e-04,\n",
      "         9.7294e-05, 1.5656e-04],\n",
      "        [1.0155e-04, 8.7687e-05, 9.0956e-05, 1.9926e-04, 2.0808e-04, 2.0818e-04,\n",
      "         1.2491e-04, 2.7504e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 6.0328e+11], dtype=torch.float64)), tensor(0.1082, dtype=torch.float64))\n",
      "((tensor([[1.2323e-04, 1.1326e-04, 1.1844e-04, 2.2144e-04, 2.7276e-04, 2.7866e-04,\n",
      "         1.5657e-04, 3.8057e-04],\n",
      "        [7.7160e-05, 8.6314e-05, 6.5009e-05, 1.1704e-04, 1.2725e-04, 1.3107e-04,\n",
      "         9.0136e-05, 1.2096e-04],\n",
      "        [6.8868e-05, 8.7848e-05, 6.1431e-05, 1.5764e-04, 1.2275e-04, 1.2288e-04,\n",
      "         8.1460e-05, 1.0358e-04],\n",
      "        [8.2812e-05, 8.9527e-05, 7.6290e-05, 1.1905e-04, 1.6615e-04, 1.6544e-04,\n",
      "         1.0107e-04, 1.6502e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 6.6853e+11], dtype=torch.float64)), tensor(0.1084, dtype=torch.float64))\n",
      "((tensor([[9.7905e-05, 1.1404e-04, 9.4852e-05, 1.8378e-04, 2.0676e-04, 2.1151e-04,\n",
      "         1.2259e-04, 2.0993e-04],\n",
      "        [1.2636e-04, 1.1588e-04, 1.2160e-04, 2.2651e-04, 2.7274e-04, 2.8660e-04,\n",
      "         1.6073e-04, 3.9424e-04],\n",
      "        [7.9067e-05, 8.8453e-05, 6.7202e-05, 1.2084e-04, 1.3506e-04, 1.3435e-04,\n",
      "         9.2299e-05, 1.2478e-04],\n",
      "        [7.0627e-05, 9.0143e-05, 6.3067e-05, 1.5991e-04, 1.2679e-04, 1.2600e-04,\n",
      "         8.3456e-05, 1.0767e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 7.1790e+11], dtype=torch.float64)), tensor(0.0135, dtype=torch.float64))\n",
      "((tensor([[8.8499e-05, 1.1530e-04, 7.9786e-05, 2.0661e-04, 1.6449e-04, 1.6477e-04,\n",
      "         1.0599e-04, 1.6441e-04],\n",
      "        [1.0081e-04, 1.1716e-04, 9.7793e-05, 1.8876e-04, 2.0760e-04, 2.1844e-04,\n",
      "         1.2637e-04, 2.1837e-04],\n",
      "        [1.3002e-04, 1.1924e-04, 1.2623e-04, 2.3483e-04, 2.9069e-04, 2.9499e-04,\n",
      "         1.6527e-04, 4.0836e-04],\n",
      "        [8.1424e-05, 9.1140e-05, 6.9278e-05, 1.2309e-04, 1.4009e-04, 1.3834e-04,\n",
      "         9.4954e-05, 1.3024e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 7.3021e+11], dtype=torch.float64)), tensor(-0.1150, dtype=torch.float64))\n",
      "((tensor([[9.2817e-05, 1.1648e-04, 8.4153e-05, 1.5587e-04, 1.7313e-04, 1.7284e-04,\n",
      "         1.1117e-04, 1.2647e-04],\n",
      "        [9.1053e-05, 1.1836e-04, 8.2192e-05, 2.1204e-04, 1.6502e-04, 1.7003e-04,\n",
      "         1.0916e-04, 1.7088e-04],\n",
      "        [1.0365e-04, 1.2046e-04, 1.0143e-04, 1.9554e-04, 2.2108e-04, 2.2465e-04,\n",
      "         1.2983e-04, 2.2601e-04],\n",
      "        [1.3379e-04, 1.2276e-04, 1.3002e-04, 2.3900e-04, 3.0126e-04, 3.0349e-04,\n",
      "         1.6988e-04, 4.2590e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 6.5416e+11], dtype=torch.float64)), tensor(-0.0176, dtype=torch.float64))\n",
      "((tensor([[1.3310e-04, 1.0749e-04, 1.2744e-04, 2.0459e-04, 2.9229e-04, 2.9222e-04,\n",
      "         1.6751e-04, 3.1301e-04],\n",
      "        [9.6688e-05, 1.2106e-04, 8.7774e-05, 1.6196e-04, 1.7586e-04, 1.8058e-04,\n",
      "         1.1593e-04, 1.3309e-04],\n",
      "        [9.4782e-05, 1.2321e-04, 8.6312e-05, 2.2239e-04, 1.7794e-04, 1.7705e-04,\n",
      "         1.1356e-04, 1.7906e-04],\n",
      "        [1.0798e-04, 1.2557e-04, 1.0578e-04, 2.0150e-04, 2.3198e-04, 2.3401e-04,\n",
      "         1.3512e-04, 2.3866e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 6.0230e+11], dtype=torch.float64)), tensor(-0.0967, dtype=torch.float64))\n",
      "((tensor([[9.4667e-05, 1.0809e-04, 8.3912e-05, 1.9567e-04, 1.6834e-04, 1.7004e-04,\n",
      "         1.1224e-04, 1.2226e-04],\n",
      "        [1.3630e-04, 1.0982e-04, 1.3068e-04, 2.0898e-04, 2.9188e-04, 3.0015e-04,\n",
      "         1.7173e-04, 3.2382e-04],\n",
      "        [9.8946e-05, 1.2390e-04, 9.0614e-05, 1.6700e-04, 1.8641e-04, 1.8486e-04,\n",
      "         1.1855e-04, 1.3710e-04],\n",
      "        [9.7075e-05, 1.2626e-04, 8.8493e-05, 2.2530e-04, 1.8355e-04, 1.8130e-04,\n",
      "         1.1618e-04, 1.8589e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 5.8590e+11], dtype=torch.float64)), tensor(-0.0629, dtype=torch.float64))\n",
      "((tensor([[8.4516e-05, 1.0941e-04, 6.8674e-05, 1.4463e-04, 1.2632e-04, 1.2435e-04,\n",
      "         9.5191e-05, 1.0453e-04],\n",
      "        [9.7595e-05, 1.1117e-04, 8.6616e-05, 2.0121e-04, 1.6922e-04, 1.7582e-04,\n",
      "         1.1584e-04, 1.2733e-04],\n",
      "        [1.4042e-04, 1.1315e-04, 1.3581e-04, 2.1692e-04, 3.1146e-04, 3.0931e-04,\n",
      "         1.7679e-04, 3.3582e-04],\n",
      "        [1.0202e-04, 1.2781e-04, 9.3524e-05, 1.7030e-04, 1.9358e-04, 1.9056e-04,\n",
      "         1.2210e-04, 1.4328e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 5.1159e+11], dtype=torch.float64)), tensor(0.1300, dtype=torch.float64))\n",
      "((tensor([[9.3471e-05, 1.1122e-04, 7.7207e-05, 9.0578e-05, 1.4847e-04, 1.4712e-04,\n",
      "         1.0703e-04, 1.6497e-04],\n",
      "        [8.7495e-05, 1.1301e-04, 7.1185e-05, 1.4935e-04, 1.2752e-04, 1.2912e-04,\n",
      "         9.8652e-05, 1.0932e-04],\n",
      "        [1.0096e-04, 1.1501e-04, 9.0395e-05, 2.0973e-04, 1.8133e-04, 1.8194e-04,\n",
      "         1.1975e-04, 1.3260e-04],\n",
      "        [1.4538e-04, 1.1721e-04, 1.4076e-04, 2.2215e-04, 3.2479e-04, 3.2019e-04,\n",
      "         1.8286e-04, 3.5242e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 6.0733e+11], dtype=torch.float64)), tensor(0.0443, dtype=torch.float64))\n",
      "((tensor([[1.4802e-04, 1.0893e-04, 1.3217e-04, 2.2096e-04, 2.9779e-04, 2.9527e-04,\n",
      "         1.8087e-04, 3.2795e-04],\n",
      "        [9.6196e-05, 1.1420e-04, 7.9558e-05, 9.2984e-05, 1.4900e-04, 1.5186e-04,\n",
      "         1.1027e-04, 1.7151e-04],\n",
      "        [8.9982e-05, 1.1623e-04, 7.3853e-05, 1.5476e-04, 1.3584e-04, 1.3283e-04,\n",
      "         1.0139e-04, 1.1317e-04],\n",
      "        [1.0392e-04, 1.1845e-04, 9.3138e-05, 2.1352e-04, 1.8798e-04, 1.8724e-04,\n",
      "         1.2313e-04, 1.3834e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 6.2132e+11], dtype=torch.float64)), tensor(0.2106, dtype=torch.float64))\n",
      "((tensor([[1.0614e-04, 1.1071e-04, 9.1661e-05, 2.1549e-04, 1.8658e-04, 1.8111e-04,\n",
      "         1.2410e-04, 1.3067e-04],\n",
      "        [1.5322e-04, 1.1249e-04, 1.3698e-04, 2.2814e-04, 3.0057e-04, 3.0654e-04,\n",
      "         1.8742e-04, 3.4292e-04],\n",
      "        [9.9500e-05, 1.1813e-04, 8.3016e-05, 9.6905e-05, 1.5964e-04, 1.5712e-04,\n",
      "         1.1398e-04, 1.7858e-04],\n",
      "        [9.3149e-05, 1.2038e-04, 7.6533e-05, 1.5846e-04, 1.4163e-04, 1.3748e-04,\n",
      "         1.0485e-04, 1.1875e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 7.3787e+11], dtype=torch.float64)), tensor(0.0685, dtype=torch.float64))\n",
      "((tensor([[9.5359e-05, 1.1141e-04, 7.8336e-05, 1.8503e-04, 1.4839e-04, 1.3921e-04,\n",
      "         1.0720e-04, 8.5407e-05],\n",
      "        [1.0878e-04, 1.1320e-04, 9.4056e-05, 2.2028e-04, 1.8645e-04, 1.8616e-04,\n",
      "         1.2732e-04, 1.3528e-04],\n",
      "        [1.5691e-04, 1.1521e-04, 1.4151e-04, 2.3540e-04, 3.1883e-04, 3.1403e-04,\n",
      "         1.9180e-04, 3.5352e-04],\n",
      "        [1.0198e-04, 1.2114e-04, 8.5175e-05, 9.8241e-05, 1.6479e-04, 1.6102e-04,\n",
      "         1.1670e-04, 1.8552e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 7.6268e+11], dtype=torch.float64)), tensor(0.0525, dtype=torch.float64))\n",
      "((tensor([[1.0965e-04, 1.1246e-04, 9.0120e-05, 1.1951e-04, 1.8410e-04, 1.7121e-04,\n",
      "         1.2530e-04, 1.6702e-04],\n",
      "        [9.8032e-05, 1.1427e-04, 8.0634e-05, 1.8974e-04, 1.4875e-04, 1.4353e-04,\n",
      "         1.1033e-04, 8.8697e-05],\n",
      "        [1.1175e-04, 1.1630e-04, 9.7473e-05, 2.2800e-04, 1.9840e-04, 1.9130e-04,\n",
      "         1.3070e-04, 1.3990e-04],\n",
      "        [1.6132e-04, 1.1852e-04, 1.4565e-04, 2.3939e-04, 3.3015e-04, 3.2281e-04,\n",
      "         1.9699e-04, 3.6840e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 7.8455e+11], dtype=torch.float64)), tensor(0.0793, dtype=torch.float64))\n",
      "((tensor([[1.7337e-04, 1.5399e-04, 1.5426e-04, 2.3216e-04, 3.4686e-04, 3.4493e-04,\n",
      "         2.1168e-04, 3.6315e-04],\n",
      "        [1.1234e-04, 1.1495e-04, 9.2451e-05, 1.2214e-04, 1.8393e-04, 1.7594e-04,\n",
      "         1.2852e-04, 1.7288e-04],\n",
      "        [1.0037e-04, 1.1700e-04, 8.3282e-05, 1.9573e-04, 1.5775e-04, 1.4700e-04,\n",
      "         1.1288e-04, 9.1416e-05],\n",
      "        [1.1450e-04, 1.1923e-04, 9.9983e-05, 2.3109e-04, 2.0475e-04, 1.9599e-04,\n",
      "         1.3379e-04, 1.4530e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 8.6888e+11], dtype=torch.float64)), tensor(-0.0098, dtype=torch.float64))\n",
      "((tensor([[1.2798e-04, 1.5548e-04, 1.0781e-04, 1.8451e-04, 2.4178e-04, 2.1114e-04,\n",
      "         1.4832e-04, 1.5768e-04],\n",
      "        [1.7867e-04, 1.5832e-04, 1.5917e-04, 2.3865e-04, 3.4855e-04, 3.5652e-04,\n",
      "         2.1838e-04, 3.7806e-04],\n",
      "        [1.1569e-04, 1.1839e-04, 9.6045e-05, 1.2673e-04, 1.9619e-04, 1.8124e-04,\n",
      "         1.3226e-04, 1.7921e-04],\n",
      "        [1.0344e-04, 1.2065e-04, 8.5925e-05, 1.9954e-04, 1.6375e-04, 1.5148e-04,\n",
      "         1.1622e-04, 9.5498e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 8.5132e+11], dtype=torch.float64)), tensor(0.0805, dtype=torch.float64))\n",
      "((tensor([[1.1871e-04, 1.5617e-04, 9.7034e-05, 1.6930e-04, 2.0800e-04, 1.7296e-04,\n",
      "         1.3340e-04, 1.6704e-04],\n",
      "        [1.3455e-04, 1.6308e-04, 1.1349e-04, 1.9350e-04, 2.4787e-04, 2.2264e-04,\n",
      "         1.5610e-04, 1.6748e-04],\n",
      "        [1.8771e-04, 1.6635e-04, 1.6870e-04, 2.5262e-04, 3.7931e-04, 3.7468e-04,\n",
      "         2.2927e-04, 3.9984e-04],\n",
      "        [1.2164e-04, 1.2455e-04, 1.0109e-04, 1.3180e-04, 2.0777e-04, 1.9054e-04,\n",
      "         1.3892e-04, 1.9100e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 9.0984e+11], dtype=torch.float64)), tensor(0.1592, dtype=torch.float64))\n",
      "((tensor([[0.0001, 0.0002, 0.0001, 0.0001, 0.0003, 0.0002, 0.0002, 0.0002],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0001, 0.0002],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0003, 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0003, 0.0004, 0.0004, 0.0002, 0.0004]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 1.0903e+12], dtype=torch.float64)), tensor(-0.2315, dtype=torch.float64))\n",
      "((tensor([[0.0002, 0.0002, 0.0002, 0.0003, 0.0004, 0.0003, 0.0002, 0.0004],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0001, 0.0003, 0.0002, 0.0002, 0.0003],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0001, 0.0002],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0003, 0.0002, 0.0002, 0.0002]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 7.4137e+11], dtype=torch.float64)), tensor(0.1167, dtype=torch.float64))\n",
      "((tensor([[0.0001, 0.0002, 0.0001, 0.0003, 0.0002, 0.0002, 0.0002, 0.0001],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0004, 0.0004, 0.0003, 0.0002, 0.0004],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0001, 0.0003, 0.0002, 0.0002, 0.0003],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0001, 0.0002]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 8.9567e+11], dtype=torch.float64)), tensor(0.0708, dtype=torch.float64))\n",
      "((tensor([[0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0001, 0.0002],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0003, 0.0002, 0.0002, 0.0002, 0.0001],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0004, 0.0004, 0.0004, 0.0002, 0.0004],\n",
      "        [0.0002, 0.0002, 0.0001, 0.0001, 0.0003, 0.0003, 0.0002, 0.0003]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 9.1064e+11], dtype=torch.float64)), tensor(0.1372, dtype=torch.float64))\n",
      "((tensor([[0.0002, 0.0002, 0.0001, 0.0003, 0.0003, 0.0002, 0.0002, 0.0003],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0001, 0.0002],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0004, 0.0004, 0.0004, 0.0002, 0.0004]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 9.8889e+11], dtype=torch.float64)), tensor(0.2978, dtype=torch.float64))\n",
      "((tensor([[0.0002, 0.0002, 0.0002, 0.0003, 0.0004, 0.0004, 0.0003, 0.0005],\n",
      "        [0.0002, 0.0002, 0.0001, 0.0003, 0.0003, 0.0002, 0.0002, 0.0003],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0001, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 1.2877e+12], dtype=torch.float64)), tensor(0.0286, dtype=torch.float64))\n",
      "((tensor([[0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0003, 0.0004, 0.0004, 0.0003, 0.0005],\n",
      "        [0.0002, 0.0002, 0.0001, 0.0003, 0.0003, 0.0003, 0.0002, 0.0003],\n",
      "        [0.0001, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 1.0840e+12], dtype=torch.float64)), tensor(0.2896, dtype=torch.float64))\n",
      "((tensor([[1.5429e-04, 1.8287e-04, 1.2221e-04, 7.0089e-05, 2.3043e-04, 2.0358e-04,\n",
      "         1.6950e-04, 2.4825e-04],\n",
      "        [1.5332e-04, 1.8811e-04, 1.2292e-04, 2.4484e-04, 2.2876e-04, 2.0417e-04,\n",
      "         1.6884e-04, 1.9900e-04],\n",
      "        [2.2739e-04, 1.9351e-04, 1.9867e-04, 3.5440e-04, 4.7667e-04, 4.1349e-04,\n",
      "         2.7038e-04, 5.0548e-04],\n",
      "        [1.6925e-04, 2.2264e-04, 1.3985e-04, 2.8187e-04, 3.0097e-04, 2.5732e-04,\n",
      "         1.9188e-04, 3.1472e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 1.5328e+12], dtype=torch.float64)), tensor(0.3533, dtype=torch.float64))\n",
      "((tensor([[1.6759e-04, 1.8202e-04, 1.3486e-04, 8.5654e-05, 2.6307e-04, 2.3292e-04,\n",
      "         1.8626e-04, 3.2158e-04],\n",
      "        [1.5930e-04, 1.8836e-04, 1.2633e-04, 7.2178e-05, 2.3198e-04, 2.1081e-04,\n",
      "         1.7519e-04, 2.5892e-04],\n",
      "        [1.5817e-04, 1.9408e-04, 1.2793e-04, 2.5450e-04, 2.4446e-04, 2.1070e-04,\n",
      "         1.7407e-04, 2.0667e-04],\n",
      "        [2.3478e-04, 1.9992e-04, 2.0534e-04, 3.6195e-04, 4.9570e-04, 4.2687e-04,\n",
      "         2.7888e-04, 5.2902e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 1.9203e+12], dtype=torch.float64)), tensor(0.0659, dtype=torch.float64))\n",
      "((tensor([[2.6307e-04, 1.8066e-04, 2.4357e-04, 1.4113e-04, 6.0044e-04, 5.3179e-04,\n",
      "         3.2273e-04, 6.0702e-04],\n",
      "        [1.7169e-04, 1.8604e-04, 1.3834e-04, 8.7528e-05, 2.6280e-04, 2.3933e-04,\n",
      "         1.9103e-04, 3.3282e-04],\n",
      "        [1.6308e-04, 1.9285e-04, 1.3047e-04, 7.4451e-05, 2.4599e-04, 2.1588e-04,\n",
      "         1.7922e-04, 2.6683e-04],\n",
      "        [1.6206e-04, 1.9896e-04, 1.3121e-04, 2.5792e-04, 2.5226e-04, 2.1585e-04,\n",
      "         1.7816e-04, 2.1463e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.2437e+12], dtype=torch.float64)), tensor(0.0293, dtype=torch.float64))\n",
      "((tensor([[2.1231e-04, 1.9194e-04, 2.1190e-04, 6.7895e-04, 4.9971e-04, 4.4170e-04,\n",
      "         2.6274e-04, 3.7851e-04],\n",
      "        [2.7133e-04, 1.8590e-04, 2.5154e-04, 1.4519e-04, 6.0388e-04, 5.5012e-04,\n",
      "         3.3322e-04, 6.3248e-04],\n",
      "        [1.7695e-04, 1.9176e-04, 1.4383e-04, 9.0895e-05, 2.8056e-04, 2.4675e-04,\n",
      "         1.9675e-04, 3.4531e-04],\n",
      "        [1.6822e-04, 1.9904e-04, 1.3472e-04, 7.5961e-05, 2.5556e-04, 2.2265e-04,\n",
      "         1.8468e-04, 2.7898e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.0349e+12], dtype=torch.float64)), tensor(0.0942, dtype=torch.float64))\n",
      "((tensor([[1.9716e-04, 1.9552e-04, 1.9736e-04, 6.6461e-04, 4.6259e-04, 3.8980e-04,\n",
      "         2.4027e-04, 3.3324e-04],\n",
      "        [2.1752e-04, 1.9620e-04, 2.1738e-04, 6.9387e-04, 4.9924e-04, 4.5390e-04,\n",
      "         2.6948e-04, 3.9177e-04],\n",
      "        [2.7780e-04, 1.9034e-04, 2.5980e-04, 1.4978e-04, 6.4042e-04, 5.6340e-04,\n",
      "         3.4093e-04, 6.5187e-04],\n",
      "        [1.8132e-04, 1.9660e-04, 1.4754e-04, 9.2125e-05, 2.8954e-04, 2.5280e-04,\n",
      "         2.0139e-04, 3.5864e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.2213e+12], dtype=torch.float64)), tensor(0.1468, dtype=torch.float64))\n",
      "((tensor([[0.0002, 0.0002, 0.0002, 0.0006, 0.0004, 0.0004, 0.0002, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0007, 0.0005, 0.0004, 0.0002, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0007, 0.0005, 0.0005, 0.0003, 0.0004],\n",
      "        [0.0003, 0.0002, 0.0003, 0.0002, 0.0007, 0.0006, 0.0004, 0.0007]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.4286e+12], dtype=torch.float64)), tensor(0.1028, dtype=torch.float64))\n",
      "((tensor([[0.0003, 0.0002, 0.0003, 0.0004, 0.0007, 0.0007, 0.0004, 0.0008],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0006, 0.0004, 0.0004, 0.0003, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0007, 0.0005, 0.0004, 0.0003, 0.0004],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0007, 0.0005, 0.0005, 0.0003, 0.0004]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.8921e+12], dtype=torch.float64)), tensor(-0.0146, dtype=torch.float64))\n",
      "((tensor([[0.0002, 0.0002, 0.0002, 0.0003, 0.0005, 0.0005, 0.0003, 0.0005],\n",
      "        [0.0003, 0.0002, 0.0003, 0.0004, 0.0007, 0.0007, 0.0004, 0.0008],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0006, 0.0005, 0.0004, 0.0003, 0.0003],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0007, 0.0005, 0.0004, 0.0003, 0.0004]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.8513e+12], dtype=torch.float64)), tensor(-0.1069, dtype=torch.float64))\n",
      "((tensor([[0.0002, 0.0002, 0.0002, 0.0002, 0.0004, 0.0004, 0.0003, 0.0004],\n",
      "        [0.0002, 0.0002, 0.0003, 0.0003, 0.0005, 0.0005, 0.0003, 0.0005],\n",
      "        [0.0003, 0.0002, 0.0003, 0.0005, 0.0008, 0.0007, 0.0004, 0.0008],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0006, 0.0005, 0.0004, 0.0003, 0.0003]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.2928e+12], dtype=torch.float64)), tensor(0.1036, dtype=torch.float64))\n",
      "((tensor([[0.0002, 0.0002, 0.0002, 0.0006, 0.0005, 0.0004, 0.0003, 0.0004],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0003, 0.0004, 0.0004, 0.0003, 0.0004],\n",
      "        [0.0002, 0.0002, 0.0003, 0.0004, 0.0006, 0.0005, 0.0003, 0.0005],\n",
      "        [0.0003, 0.0002, 0.0003, 0.0005, 0.0008, 0.0007, 0.0004, 0.0009]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.4175e+12], dtype=torch.float64)), tensor(-0.1003, dtype=torch.float64))\n",
      "((tensor([[2.9283e-04, 2.1118e-04, 2.9557e-04, 6.9886e-05, 6.6946e-04, 6.1041e-04,\n",
      "         3.6260e-04, 5.5594e-04],\n",
      "        [2.3984e-04, 2.1082e-04, 2.2813e-04, 6.2781e-04, 4.5923e-04, 4.3097e-04,\n",
      "         2.8446e-04, 3.9442e-04],\n",
      "        [2.2400e-04, 2.1008e-04, 2.2062e-04, 2.5937e-04, 4.5422e-04, 4.0670e-04,\n",
      "         2.6623e-04, 4.0315e-04],\n",
      "        [2.5641e-04, 2.0890e-04, 2.6679e-04, 3.6016e-04, 5.9941e-04, 5.3807e-04,\n",
      "         3.1765e-04, 5.1354e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.0669e+12], dtype=torch.float64)), tensor(0.1426, dtype=torch.float64))\n",
      "((tensor([[2.4137e-04, 2.1102e-04, 2.4785e-04, 3.4506e-04, 5.4211e-04, 4.8256e-04,\n",
      "         2.9513e-04, 4.7436e-04],\n",
      "        [2.9985e-04, 2.1574e-04, 3.0305e-04, 7.1382e-05, 6.6846e-04, 6.2691e-04,\n",
      "         3.7170e-04, 5.7509e-04],\n",
      "        [2.4541e-04, 2.1574e-04, 2.3549e-04, 6.4727e-04, 4.8674e-04, 4.4113e-04,\n",
      "         2.9087e-04, 4.0628e-04],\n",
      "        [2.2940e-04, 2.1526e-04, 2.2618e-04, 2.6273e-04, 4.6850e-04, 4.1643e-04,\n",
      "         2.7237e-04, 4.1847e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 2.6090e+12], dtype=torch.float64)), tensor(0.1776, dtype=torch.float64))\n",
      "((tensor([[2.1463e-04, 2.2355e-04, 2.1627e-04, 1.8149e-04, 4.4874e-04, 3.9422e-04,\n",
      "         2.5606e-04, 4.5192e-04],\n",
      "        [2.4728e-04, 2.1568e-04, 2.5423e-04, 3.5261e-04, 5.4156e-04, 4.9584e-04,\n",
      "         3.0267e-04, 4.9093e-04],\n",
      "        [3.0697e-04, 2.2088e-04, 3.1297e-04, 7.3630e-05, 7.0883e-04, 6.4200e-04,\n",
      "         3.8026e-04, 5.9266e-04],\n",
      "        [2.5144e-04, 2.2117e-04, 2.4153e-04, 6.5597e-04, 5.0228e-04, 4.5190e-04,\n",
      "         2.9772e-04, 4.2193e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 4.0000e+00, 3.0509e+12], dtype=torch.float64)), tensor(-0.0369, dtype=torch.float64))\n",
      "((tensor([[1.5056e-04, 8.5275e-05, 2.8145e-04, 2.2752e-04, 3.2945e-04, 3.4849e-04,\n",
      "         1.9276e-04, 3.2548e-04],\n",
      "        [1.4518e-04, 7.3040e-05, 2.7837e-04, 2.3113e-04, 2.6722e-04, 3.1757e-04,\n",
      "         1.8253e-04, 3.7355e-04],\n",
      "        [1.3188e-04, 7.5796e-05, 2.7276e-04, 2.3700e-04, 3.1056e-04, 3.1763e-04,\n",
      "         1.7098e-04, 3.2401e-04],\n",
      "        [1.2432e-04, 6.6846e-05, 2.4998e-04, 2.3877e-04, 2.3836e-04, 2.9465e-04,\n",
      "         1.6015e-04, 2.8053e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 9.6842e+10], dtype=torch.float64)), tensor(-0.0035, dtype=torch.float64))\n",
      "((tensor([[1.3063e-04, 7.3370e-05, 2.6507e-04, 7.3746e-04, 2.9721e-04, 3.7975e-04,\n",
      "         1.8138e-04, 3.6318e-04],\n",
      "        [1.5498e-04, 8.7577e-05, 2.9008e-04, 2.3361e-04, 3.3069e-04, 3.5980e-04,\n",
      "         1.9864e-04, 3.3847e-04],\n",
      "        [1.4934e-04, 7.5138e-05, 2.8887e-04, 2.3955e-04, 2.8472e-04, 3.2676e-04,\n",
      "         1.8762e-04, 3.8681e-04],\n",
      "        [1.3577e-04, 7.8075e-05, 2.8110e-04, 2.4133e-04, 3.2201e-04, 3.2695e-04,\n",
      "         1.7584e-04, 3.3810e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 9.2384e+10], dtype=torch.float64)), tensor(0.1028, dtype=torch.float64))\n",
      "((tensor([[1.4331e-04, 7.6403e-05, 2.8952e-04, 7.3240e-04, 3.5098e-04, 3.9518e-04,\n",
      "         1.9507e-04, 3.2115e-04],\n",
      "        [1.3213e-04, 7.4037e-05, 2.6844e-04, 7.4402e-04, 2.9313e-04, 3.8524e-04,\n",
      "         1.8365e-04, 3.7109e-04],\n",
      "        [1.5664e-04, 8.8522e-05, 2.9578e-04, 2.3790e-04, 3.4620e-04, 3.6377e-04,\n",
      "         2.0063e-04, 3.4437e-04],\n",
      "        [1.5106e-04, 7.6048e-05, 2.9251e-04, 2.3968e-04, 2.9007e-04, 3.3049e-04,\n",
      "         1.8960e-04, 3.9659e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.0082e+11], dtype=torch.float64)), tensor(0.0444, dtype=torch.float64))\n",
      "((tensor([[2.1380e-04, 7.2888e-05, 3.1945e-04, 3.5661e-04, 1.1564e-05, 3.0298e-04,\n",
      "         2.3869e-04, 4.4035e-04],\n",
      "        [1.5713e-04, 8.1393e-05, 3.2098e-04, 3.6227e-04, 3.6020e-04, 4.6665e-04,\n",
      "         2.1995e-04, 5.9320e-04],\n",
      "        [1.5916e-04, 8.2093e-05, 3.3181e-04, 3.7148e-04, 4.4583e-04, 4.6961e-04,\n",
      "         2.2206e-04, 3.6270e-04],\n",
      "        [1.5638e-04, 7.8338e-05, 3.0746e-04, 3.7425e-04, 4.0863e-04, 4.3264e-04,\n",
      "         2.1274e-04, 4.0038e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.5439e+11], dtype=torch.float64)), tensor(0.0920, dtype=torch.float64))\n",
      "((tensor([[1.8433e-04, 9.1929e-05, 4.2313e-04, 3.2845e-04, 6.7244e-04, 7.2125e-04,\n",
      "         2.8980e-04, 6.1589e-04],\n",
      "        [2.3178e-04, 9.0240e-05, 4.2252e-04, 3.3367e-04, 4.4916e-04, 4.8737e-04,\n",
      "         2.8782e-04, 8.9611e-04],\n",
      "        [1.9536e-04, 9.1845e-05, 4.2565e-04, 3.4214e-04, 1.8623e-04, 6.4460e-04,\n",
      "         2.8498e-04, 4.9000e-04],\n",
      "        [1.9747e-04, 9.6884e-05, 4.1364e-04, 3.4470e-04, 6.3320e-04, 5.8116e-04,\n",
      "         2.7497e-04, 6.2669e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.3093e+11], dtype=torch.float64)), tensor(-0.0589, dtype=torch.float64))\n",
      "((tensor([[1.9469e-04, 8.9571e-05, 4.2170e-04, 3.7885e-04, 7.2245e-04, 6.5674e-04,\n",
      "         2.8690e-04, 7.3012e-04],\n",
      "        [1.8769e-04, 9.3386e-05, 4.3138e-04, 3.3359e-04, 6.6763e-04, 7.3657e-04,\n",
      "         2.9539e-04, 6.3351e-04],\n",
      "        [2.3583e-04, 9.1824e-05, 4.3369e-04, 3.4207e-04, 4.7338e-04, 4.9604e-04,\n",
      "         2.9265e-04, 9.1785e-04],\n",
      "        [1.9894e-04, 9.3579e-05, 4.3390e-04, 3.4462e-04, 1.9100e-04, 6.5631e-04,\n",
      "         2.8990e-04, 5.0576e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.1270e+11], dtype=torch.float64)), tensor(0.1955, dtype=torch.float64))\n",
      "((tensor([[ 3.7606e-04,  1.1624e-04,  4.2473e-04,  3.7947e-04, -1.7742e-04,\n",
      "          1.3730e-04,  3.4759e-04,  5.7712e-04],\n",
      "        [ 1.9861e-04,  9.1160e-05,  4.3073e-04,  3.8549e-04,  7.1862e-04,\n",
      "          6.7194e-04,  2.9299e-04,  7.5240e-04],\n",
      "        [ 1.9132e-04,  9.5201e-05,  4.4360e-04,  3.4263e-04,  7.0494e-04,\n",
      "          7.5107e-04,  3.0091e-04,  6.5008e-04],\n",
      "        [ 2.4059e-04,  9.3732e-05,  4.4292e-04,  3.4518e-04,  4.8641e-04,\n",
      "          5.0599e-04,  2.9826e-04,  9.4912e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.4499e+11], dtype=torch.float64)), tensor(-0.0499, dtype=torch.float64))\n",
      "((tensor([[ 3.1383e-04,  1.1424e-04,  4.1564e-04,  3.1753e-04,  4.6429e-04,\n",
      "          4.9727e-04,  3.5996e-04,  9.3083e-04],\n",
      "        [ 3.2048e-04,  9.8831e-05,  3.6241e-04,  3.2257e-04, -1.4743e-04,\n",
      "          1.1735e-04,  2.9653e-04,  4.9684e-04],\n",
      "        [ 1.6913e-04,  7.7635e-05,  3.7003e-04,  3.3076e-04,  6.3388e-04,\n",
      "          5.7239e-04,  2.4933e-04,  6.4499e-04],\n",
      "        [ 1.6306e-04,  8.1183e-05,  3.7847e-04,  2.8884e-04,  6.0511e-04,\n",
      "          6.4002e-04,  2.5619e-04,  5.6158e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.5458e+11], dtype=torch.float64)), tensor(0.1577, dtype=torch.float64))\n",
      "((tensor([[ 3.2861e-04,  1.4813e-04,  4.8544e-04,  3.1741e-04,  7.2393e-06,\n",
      "          5.7314e-04,  3.8649e-04,  7.5842e-04],\n",
      "        [ 3.1950e-04,  1.1603e-04,  4.2369e-04,  3.2245e-04,  4.6091e-04,\n",
      "          5.0776e-04,  3.6685e-04,  9.5733e-04],\n",
      "        [ 3.2603e-04,  1.0055e-04,  3.7194e-04,  3.3064e-04, -1.5536e-04,\n",
      "          1.1942e-04,  3.0146e-04,  5.0882e-04],\n",
      "        [ 1.7220e-04,  7.9090e-05,  3.7715e-04,  3.3311e-04,  6.5003e-04,\n",
      "          5.8270e-04,  2.5360e-04,  6.6564e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.8585e+11], dtype=torch.float64)), tensor(0.0183, dtype=torch.float64))\n",
      "((tensor([[ 2.8958e-04,  1.3440e-04,  4.6539e-04,  6.9345e-04,  7.1431e-04,\n",
      "          6.2645e-04,  3.6275e-04,  7.7714e-04],\n",
      "        [ 3.3459e-04,  1.5048e-04,  4.9491e-04,  3.2237e-04,  7.1876e-06,\n",
      "          5.8531e-04,  3.9394e-04,  7.8011e-04],\n",
      "        [ 3.2508e-04,  1.1807e-04,  4.3488e-04,  3.3057e-04,  4.8576e-04,\n",
      "          5.1680e-04,  3.7300e-04,  9.8054e-04],\n",
      "        [ 3.3200e-04,  1.0245e-04,  3.7915e-04,  3.3303e-04, -1.5934e-04,\n",
      "          1.2159e-04,  3.0667e-04,  5.2518e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.9110e+11], dtype=torch.float64)), tensor(0.0831, dtype=torch.float64))\n",
      "((tensor([[3.0939e-04, 1.3111e-04, 4.9910e-04, 6.9332e-04, 1.5397e-04, 6.7792e-04,\n",
      "         3.8914e-04, 7.7798e-04],\n",
      "        [2.9487e-04, 1.3653e-04, 4.7448e-04, 7.0432e-04, 7.0923e-04, 6.3978e-04,\n",
      "         3.6977e-04, 7.9940e-04],\n",
      "        [3.4045e-04, 1.5312e-04, 5.0801e-04, 3.3050e-04, 7.5753e-06, 5.9575e-04,\n",
      "         4.0056e-04, 7.9906e-04],\n",
      "        [3.3105e-04, 1.2030e-04, 4.4333e-04, 3.3297e-04, 4.9821e-04, 5.2620e-04,\n",
      "         3.7946e-04, 1.0121e-03]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.9895e+11], dtype=torch.float64)), tensor(-0.0164, dtype=torch.float64))\n",
      "((tensor([[3.2605e-04, 1.4538e-04, 5.2610e-04, 6.9294e-04, 6.3865e-04, 6.5696e-04,\n",
      "         3.9960e-04, 1.2782e-03],\n",
      "        [3.1492e-04, 1.3315e-04, 5.0867e-04, 7.0394e-04, 1.5282e-04, 6.9211e-04,\n",
      "         3.9652e-04, 7.9999e-04],\n",
      "        [2.9993e-04, 1.3888e-04, 4.8687e-04, 7.2182e-04, 7.4724e-04, 6.5096e-04,\n",
      "         3.7585e-04, 8.1853e-04],\n",
      "        [3.4658e-04, 1.5597e-04, 5.1769e-04, 3.3279e-04, 7.7669e-06, 6.0637e-04,\n",
      "         4.0735e-04, 8.2449e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.9063e+11], dtype=torch.float64)), tensor(0.1645, dtype=torch.float64))\n",
      "((tensor([[0.0003, 0.0001, 0.0006, 0.0007, 0.0008, 0.0008, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0007, 0.0006, 0.0007, 0.0004, 0.0013],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0007, 0.0002, 0.0007, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0007, 0.0008, 0.0007, 0.0004, 0.0008]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 2.3937e+11], dtype=torch.float64)), tensor(0.1983, dtype=torch.float64))\n",
      "((tensor([[0.0003, 0.0001, 0.0005, 0.0006, 0.0009, 0.0007, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0006, 0.0007, 0.0008, 0.0008, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0002, 0.0006, 0.0007, 0.0007, 0.0007, 0.0004, 0.0013],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0007, 0.0002, 0.0007, 0.0004, 0.0008]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 2.8673e+11], dtype=torch.float64)), tensor(-0.0392, dtype=torch.float64))\n",
      "((tensor([[0.0004, 0.0001, 0.0006, 0.0006, 0.0002, 0.0005, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0006, 0.0009, 0.0007, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0006, 0.0007, 0.0009, 0.0008, 0.0004, 0.0009],\n",
      "        [0.0003, 0.0002, 0.0006, 0.0007, 0.0007, 0.0007, 0.0004, 0.0014]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 2.7065e+11], dtype=torch.float64)), tensor(-0.0313, dtype=torch.float64))\n",
      "((tensor([[0.0003, 0.0001, 0.0005, 0.0006, 0.0008, 0.0007, 0.0004, 0.0012],\n",
      "        [0.0004, 0.0001, 0.0006, 0.0006, 0.0002, 0.0005, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0006, 0.0009, 0.0007, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0006, 0.0007, 0.0009, 0.0008, 0.0004, 0.0009]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 2.3730e+11], dtype=torch.float64)), tensor(0.1151, dtype=torch.float64))\n",
      "((tensor([[0.0003, 0.0001, 0.0006, 0.0006, 0.0005, 0.0008, 0.0004, 0.0012],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0006, 0.0008, 0.0007, 0.0004, 0.0013],\n",
      "        [0.0004, 0.0001, 0.0006, 0.0006, 0.0002, 0.0005, 0.0004, 0.0008],\n",
      "        [0.0003, 0.0001, 0.0005, 0.0007, 0.0010, 0.0008, 0.0004, 0.0009]],\n",
      "       dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 2.8580e+11], dtype=torch.float64)), tensor(-0.0492, dtype=torch.float64))\n",
      "((tensor([[3.0685e-04, 1.1655e-04, 4.3500e-04, 5.6686e-04, 4.7954e-05, 4.2178e-04,\n",
      "         3.4019e-04, 6.6460e-04],\n",
      "        [3.1786e-04, 1.2967e-04, 5.8959e-04, 5.7585e-04, 4.9276e-04, 8.5638e-04,\n",
      "         4.2899e-04, 1.2278e-03],\n",
      "        [3.4334e-04, 1.2188e-04, 5.4114e-04, 5.9049e-04, 8.2948e-04, 7.2936e-04,\n",
      "         4.2737e-04, 1.2945e-03],\n",
      "        [3.8666e-04, 1.3930e-04, 5.8687e-04, 7.2630e-04, 1.9910e-04, 5.3171e-04,\n",
      "         4.2813e-04, 8.7511e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 2.8199e+11], dtype=torch.float64)), tensor(-0.0950, dtype=torch.float64))\n",
      "((tensor([[1.6861e-04, 1.4962e-04, 1.6851e-04, 1.8465e-04, 3.3229e-05, 4.9511e-05,\n",
      "         1.4921e-04, 2.3512e-04],\n",
      "        [1.3850e-04, 1.3709e-04, 1.6897e-04, 1.8758e-04, 2.1144e-04, 1.5077e-04,\n",
      "         1.4902e-04, 1.9801e-04],\n",
      "        [1.5021e-04, 1.3024e-04, 1.5645e-04, 1.9235e-04, 9.9106e-05, 1.1261e-04,\n",
      "         1.4248e-04, 1.5421e-04],\n",
      "        [1.5954e-04, 1.1366e-04, 1.8233e-04, 8.8053e-05, 1.6957e-04, 1.6129e-04,\n",
      "         1.5984e-04, 1.9910e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 7.9486e+10], dtype=torch.float64)), tensor(0.0664, dtype=torch.float64))\n",
      "((tensor([[1.5523e-04, 8.5772e-05, 1.8859e-04, 1.8465e-04, 1.7740e-04, 1.7332e-04,\n",
      "         1.5773e-04, 1.0179e-04],\n",
      "        [1.7171e-04, 1.5203e-04, 1.7184e-04, 1.8758e-04, 3.2999e-05, 5.0574e-05,\n",
      "         1.5212e-04, 2.4190e-04],\n",
      "        [1.4096e-04, 1.3953e-04, 1.7347e-04, 1.9235e-04, 2.2289e-04, 1.5349e-04,\n",
      "         1.5155e-04, 2.0285e-04],\n",
      "        [1.5299e-04, 1.3273e-04, 1.5952e-04, 1.9379e-04, 1.0167e-04, 1.1468e-04,\n",
      "         1.4497e-04, 1.5920e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 8.7397e+10], dtype=torch.float64)), tensor(0.0625, dtype=torch.float64))\n",
      "((tensor([[6.3595e-05, 1.1412e-04, 7.9248e-05, 1.4126e-04, 1.8905e-04, 1.7515e-04,\n",
      "         8.0759e-05, 1.4832e-04],\n",
      "        [7.2951e-05, 1.2800e-04, 7.9870e-05, 1.4350e-04, 1.3517e-04, 1.3396e-04,\n",
      "         8.1877e-05, 1.6467e-04],\n",
      "        [1.6089e-04, 8.8700e-05, 1.9744e-04, 1.9235e-04, 1.8571e-04, 1.8023e-04,\n",
      "         1.6354e-04, 1.0728e-04],\n",
      "        [1.7800e-04, 1.5769e-04, 1.7988e-04, 1.9379e-04, 3.5685e-05, 5.2432e-05,\n",
      "         1.5741e-04, 2.5585e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.0020e+11], dtype=torch.float64)), tensor(0.0874, dtype=torch.float64))\n",
      "((tensor([[5.8872e-05, 1.5305e-04, 7.4432e-05, 1.4126e-04, 2.1294e-04, 1.6555e-04,\n",
      "         8.0021e-05, 2.7002e-04],\n",
      "        [6.4767e-05, 1.1596e-04, 8.0811e-05, 1.4350e-04, 1.8774e-04, 1.7891e-04,\n",
      "         8.2336e-05, 1.5260e-04],\n",
      "        [7.4243e-05, 1.3027e-04, 8.2000e-05, 1.4715e-04, 1.4249e-04, 1.3638e-04,\n",
      "         8.3269e-05, 1.6871e-04],\n",
      "        [1.6387e-04, 9.0395e-05, 2.0131e-04, 1.9379e-04, 1.9051e-04, 1.8355e-04,\n",
      "         1.6641e-04, 1.1076e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.0656e+11], dtype=torch.float64)), tensor(-0.0299, dtype=torch.float64))\n",
      "((tensor([[8.1153e-05, 9.1839e-05, 8.1815e-05, 1.4126e-04, 1.1540e-04, 2.0103e-04,\n",
      "         8.5603e-05, 1.0088e-04],\n",
      "        [5.9957e-05, 1.5551e-04, 7.5900e-05, 1.4350e-04, 2.1147e-04, 1.6910e-04,\n",
      "         8.1584e-05, 2.7781e-04],\n",
      "        [6.5914e-05, 1.1802e-04, 8.2966e-05, 1.4715e-04, 1.9791e-04, 1.8213e-04,\n",
      "         8.3736e-05, 1.5634e-04],\n",
      "        [7.5619e-05, 1.3276e-04, 8.3609e-05, 1.4825e-04, 1.4618e-04, 1.3888e-04,\n",
      "         8.4726e-05, 1.7417e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.0013e+11], dtype=torch.float64)), tensor(0.1205, dtype=torch.float64))\n",
      "((tensor([[1.8360e-04, 1.7713e-04, 1.4601e-04, 2.2441e-04, 1.0874e-04, 1.0886e-04,\n",
      "         1.7254e-04, 8.0250e-05],\n",
      "        [1.8183e-04, 1.6679e-04, 1.5196e-04, 2.2798e-04, 1.2364e-04, 1.0895e-04,\n",
      "         1.7371e-04, 3.5997e-05],\n",
      "        [1.7533e-04, 1.9796e-04, 1.7854e-04, 3.0672e-04, 2.5182e-04, 4.3573e-04,\n",
      "         1.8501e-04, 2.2165e-04],\n",
      "        [1.2955e-04, 3.3621e-04, 1.6561e-04, 3.0901e-04, 4.7666e-04, 3.6543e-04,\n",
      "         1.7597e-04, 6.1246e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 5.4373e+10], dtype=torch.float64)), tensor(-0.0384, dtype=torch.float64))\n",
      "((tensor([[1.4329e-04, 1.7878e-04, 1.4603e-04, 2.2557e-04, 2.2180e-04, 1.0992e-04,\n",
      "         1.5365e-04, 4.6501e-05],\n",
      "        [1.8795e-04, 1.8090e-04, 1.4965e-04, 2.2915e-04, 1.0854e-04, 1.1177e-04,\n",
      "         1.7681e-04, 8.2988e-05],\n",
      "        [1.8600e-04, 1.7062e-04, 1.5681e-04, 2.3497e-04, 1.3100e-04, 1.1148e-04,\n",
      "         1.7757e-04, 3.7068e-05],\n",
      "        [1.7949e-04, 2.0278e-04, 1.8297e-04, 3.1060e-04, 2.5965e-04, 4.4602e-04,\n",
      "         1.8921e-04, 2.3000e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 5.1318e+10], dtype=torch.float64)), tensor(0.1110, dtype=torch.float64))\n",
      "((tensor([[1.6646e-04, 1.6966e-04, 1.5413e-04, 2.2557e-04, 1.3524e-04, 1.3190e-04,\n",
      "         1.6151e-04, 2.5012e-04],\n",
      "        [1.4593e-04, 1.8166e-04, 1.4892e-04, 2.2915e-04, 2.2027e-04, 1.1228e-04,\n",
      "         1.5665e-04, 4.7843e-05],\n",
      "        [1.9127e-04, 1.8411e-04, 1.5365e-04, 2.3497e-04, 1.1442e-04, 1.1378e-04,\n",
      "         1.7982e-04, 8.5021e-05],\n",
      "        [1.8945e-04, 1.7389e-04, 1.5988e-04, 2.3672e-04, 1.3439e-04, 1.1353e-04,\n",
      "         1.8068e-04, 3.8268e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 5.9265e+10], dtype=torch.float64)), tensor(0.0247, dtype=torch.float64))\n",
      "((tensor([[1.7529e-04, 1.8311e-04, 1.6377e-04, 1.0001e-04, 1.1002e-04, 1.3645e-04,\n",
      "         1.6559e-04, 1.2495e-04],\n",
      "        [1.7031e-04, 1.7438e-04, 1.4913e-04, 1.0160e-04, 8.7925e-05, 8.2601e-05,\n",
      "         1.5874e-04, 1.6220e-05],\n",
      "        [1.7741e-04, 1.8041e-04, 1.6592e-04, 2.4161e-04, 1.4558e-04, 1.4103e-04,\n",
      "         1.7220e-04, 2.7109e-04],\n",
      "        [1.5554e-04, 1.9374e-04, 1.6029e-04, 2.4341e-04, 2.4493e-04, 1.1969e-04,\n",
      "         1.6668e-04, 5.2031e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 6.1501e+10], dtype=torch.float64)), tensor(0.0465, dtype=torch.float64))\n",
      "((tensor([[1.7314e-04, 1.7291e-04, 1.6304e-04, 9.9870e-05, 1.2684e-04, 1.3089e-04,\n",
      "         1.6608e-04, 1.7959e-04],\n",
      "        [1.7827e-04, 1.8580e-04, 1.6677e-04, 1.0145e-04, 1.0911e-04, 1.3918e-04,\n",
      "         1.6859e-04, 1.2838e-04],\n",
      "        [1.7309e-04, 1.7723e-04, 1.5290e-04, 1.0403e-04, 9.2558e-05, 8.3973e-05,\n",
      "         1.6121e-04, 1.6594e-05],\n",
      "        [1.8045e-04, 1.8360e-04, 1.6894e-04, 2.4307e-04, 1.4913e-04, 1.4343e-04,\n",
      "         1.7497e-04, 2.7948e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 6.2626e+10], dtype=torch.float64)), tensor(0.0426, dtype=torch.float64))\n",
      "((tensor([[1.6971e-04, 1.7521e-04, 1.7719e-04, 9.9870e-05, 2.1337e-04, 1.4808e-04,\n",
      "         1.7513e-04, 1.8484e-04],\n",
      "        [1.7633e-04, 1.7569e-04, 1.6626e-04, 1.0145e-04, 1.2597e-04, 1.3370e-04,\n",
      "         1.6932e-04, 1.8477e-04],\n",
      "        [1.8143e-04, 1.8910e-04, 1.7121e-04, 1.0403e-04, 1.1502e-04, 1.4169e-04,\n",
      "         1.7145e-04, 1.3152e-04],\n",
      "        [1.7630e-04, 1.8062e-04, 1.5590e-04, 1.0481e-04, 9.4950e-05, 8.5517e-05,\n",
      "         1.6404e-04, 1.7131e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 6.7791e+10], dtype=torch.float64)), tensor(0.0331, dtype=torch.float64))\n",
      "((tensor([[ 1.0046e-04,  1.6638e-04,  1.6692e-04,  1.4227e-04,  5.4657e-04,\n",
      "          1.1047e-04,  1.6196e-04, -4.5805e-05],\n",
      "        [ 1.7481e-04,  1.8006e-04,  1.8275e-04,  1.0262e-04,  2.1432e-04,\n",
      "          1.5299e-04,  1.8060e-04,  1.9235e-04],\n",
      "        [ 1.8151e-04,  1.8086e-04,  1.7265e-04,  1.0522e-04,  1.3431e-04,\n",
      "          1.3766e-04,  1.7417e-04,  1.9146e-04],\n",
      "        [ 1.8691e-04,  1.9492e-04,  1.7657e-04,  1.0601e-04,  1.1934e-04,\n",
      "          1.4595e-04,  1.7645e-04,  1.3734e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 6.8974e+10], dtype=torch.float64)), tensor(0.0447, dtype=torch.float64))\n",
      "((tensor([[ 1.6895e-04,  1.5537e-04,  1.7557e-04,  1.4211e-04,  1.8675e-04,\n",
      "          1.3187e-04,  1.7079e-04,  1.4236e-04],\n",
      "        [ 1.0220e-04,  1.6886e-04,  1.7002e-04,  1.4437e-04,  5.4218e-04,\n",
      "          1.1272e-04,  1.6493e-04, -4.7073e-05],\n",
      "        [ 1.7771e-04,  1.8306e-04,  1.8741e-04,  1.0510e-04,  2.2567e-04,\n",
      "          1.5557e-04,  1.8346e-04,  1.9683e-04],\n",
      "        [ 1.8466e-04,  1.8411e-04,  1.7583e-04,  1.0589e-04,  1.3762e-04,\n",
      "          1.4004e-04,  1.7702e-04,  1.9744e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 7.3151e+10], dtype=torch.float64)), tensor(-0.0910, dtype=torch.float64))\n",
      "((tensor([[ 1.7589e-04,  1.7918e-04,  1.7266e-04,  1.4199e-04,  1.3804e-04,\n",
      "          1.2887e-04,  1.6999e-04,  1.5382e-04],\n",
      "        [ 1.7192e-04,  1.5773e-04,  1.7888e-04,  1.4424e-04,  1.8530e-04,\n",
      "          1.3459e-04,  1.7398e-04,  1.4634e-04],\n",
      "        [ 1.0392e-04,  1.7172e-04,  1.7440e-04,  1.4791e-04,  5.7105e-04,\n",
      "          1.1465e-04,  1.6759e-04, -4.8184e-05],\n",
      "        [ 1.8085e-04,  1.8639e-04,  1.9092e-04,  1.0580e-04,  2.3131e-04,\n",
      "          1.5829e-04,  1.8651e-04,  2.0303e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 5.9997e+10], dtype=torch.float64)), tensor(0.0262, dtype=torch.float64))\n",
      "((tensor([[ 1.7015e-04,  1.7223e-04,  1.7779e-04,  1.4199e-04,  1.8254e-04,\n",
      "          1.4730e-04,  1.7124e-04,  1.1379e-04],\n",
      "        [ 1.7913e-04,  1.8206e-04,  1.7607e-04,  1.4424e-04,  1.3708e-04,\n",
      "          1.3164e-04,  1.7331e-04,  1.5825e-04],\n",
      "        [ 1.7496e-04,  1.6054e-04,  1.8365e-04,  1.4791e-04,  1.9533e-04,\n",
      "          1.3702e-04,  1.7694e-04,  1.4993e-04],\n",
      "        [ 1.0584e-04,  1.7500e-04,  1.7782e-04,  1.4901e-04,  5.8581e-04,\n",
      "          1.1676e-04,  1.7053e-04, -4.9744e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 6.6993e+10], dtype=torch.float64)), tensor(-0.1008, dtype=torch.float64))\n",
      "((tensor([[ 1.7855e-04,  1.5919e-04,  1.6539e-04,  1.4127e-04,  7.6361e-05,\n",
      "          9.6164e-05,  1.6372e-04, -6.6935e-05],\n",
      "        [ 1.7595e-04,  1.7768e-04,  1.8409e-04,  1.4646e-04,  1.8406e-04,\n",
      "          1.5278e-04,  1.7727e-04,  1.1887e-04],\n",
      "        [ 1.8510e-04,  1.8814e-04,  1.8354e-04,  1.5018e-04,  1.4673e-04,\n",
      "          1.3607e-04,  1.7896e-04,  1.6462e-04],\n",
      "        [ 1.8094e-04,  1.6612e-04,  1.9012e-04,  1.5130e-04,  2.0346e-04,\n",
      "          1.4168e-04,  1.8280e-04,  1.5716e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 6.1455e+10], dtype=torch.float64)), tensor(-0.0191, dtype=torch.float64))\n",
      "((tensor([[ 1.8427e-04,  1.5831e-04,  1.8436e-04,  1.4119e-04,  1.4853e-04,\n",
      "          1.4967e-04,  1.7863e-04,  1.3180e-04],\n",
      "        [ 1.8174e-04,  1.6166e-04,  1.6856e-04,  1.4343e-04,  7.5790e-05,\n",
      "          9.8172e-05,  1.6682e-04, -6.8826e-05],\n",
      "        [ 1.7896e-04,  1.8074e-04,  1.8889e-04,  1.5010e-04,  1.9392e-04,\n",
      "          1.5544e-04,  1.8018e-04,  1.2172e-04],\n",
      "        [ 1.8843e-04,  1.9163e-04,  1.8703e-04,  1.5122e-04,  1.5043e-04,\n",
      "          1.3849e-04,  1.8199e-04,  1.6985e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 5.7786e+10], dtype=torch.float64)), tensor(0.1097, dtype=torch.float64))\n",
      "((tensor([[ 2.1958e-04,  1.5650e-04,  1.8255e-04,  1.4097e-04, -7.9332e-05,\n",
      "          1.6426e-04,  1.7731e-04,  1.7990e-04],\n",
      "        [ 1.8737e-04,  1.6061e-04,  1.8770e-04,  1.4321e-04,  1.4727e-04,\n",
      "          1.5264e-04,  1.8183e-04,  1.3539e-04],\n",
      "        [ 1.8466e-04,  1.6427e-04,  1.7278e-04,  1.4684e-04,  7.9769e-05,\n",
      "          9.9784e-05,  1.6939e-04, -7.0400e-05],\n",
      "        [ 1.8200e-04,  1.8390e-04,  1.9229e-04,  1.5098e-04,  1.9862e-04,\n",
      "          1.5805e-04,  1.8304e-04,  1.2546e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 6.2264e+10], dtype=torch.float64)), tensor(-0.0569, dtype=torch.float64))\n",
      "((tensor([[ 1.7684e-04,  1.5494e-04,  1.8401e-04,  1.4097e-04,  1.9242e-04,\n",
      "          1.7360e-04,  1.7835e-04,  1.6916e-04],\n",
      "        [ 2.2363e-04,  1.5902e-04,  1.8615e-04,  1.4321e-04, -7.8784e-05,\n",
      "          1.6779e-04,  1.8077e-04,  1.8509e-04],\n",
      "        [ 1.9069e-04,  1.6346e-04,  1.9271e-04,  1.4684e-04,  1.5525e-04,\n",
      "          1.5539e-04,  1.8492e-04,  1.3870e-04],\n",
      "        [ 1.8809e-04,  1.6741e-04,  1.7617e-04,  1.4794e-04,  8.1830e-05,\n",
      "          1.0162e-04,  1.7235e-04, -7.2680e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 5.6551e+10], dtype=torch.float64)), tensor(0.1483, dtype=torch.float64))\n",
      "((tensor([[ 1.9573e-04,  1.6731e-04,  1.4810e-04,  1.1026e-04,  8.5723e-05,\n",
      "         -3.1386e-05,  1.7975e-04,  5.0935e-05],\n",
      "        [ 1.5281e-04,  1.3357e-04,  1.5920e-04,  1.2150e-04,  1.6213e-04,\n",
      "          1.5046e-04,  1.5428e-04,  1.4767e-04],\n",
      "        [ 1.9310e-04,  1.3732e-04,  1.6215e-04,  1.2459e-04, -7.0465e-05,\n",
      "          1.4493e-04,  1.5599e-04,  1.6088e-04],\n",
      "        [ 1.6479e-04,  1.4134e-04,  1.6671e-04,  1.2552e-04,  1.3512e-04,\n",
      "          1.3427e-04,  1.5965e-04,  1.2150e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 7.7063e+10], dtype=torch.float64)), tensor(0.0424, dtype=torch.float64))\n",
      "((tensor([[ 2.0996e-04,  1.6975e-04,  1.8539e-04,  1.1012e-04,  5.7827e-05,\n",
      "          6.6262e-05,  1.7698e-04,  1.8462e-04],\n",
      "        [ 1.9909e-04,  1.6979e-04,  1.7946e-04,  1.1187e-04,  8.5024e-05,\n",
      "         -3.2019e-05,  1.6795e-04,  5.2339e-05],\n",
      "        [ 1.5532e-04,  1.3577e-04,  1.6325e-04,  1.2444e-04,  1.7070e-04,\n",
      "          1.5298e-04,  1.5670e-04,  1.5110e-04],\n",
      "        [ 1.9643e-04,  1.3977e-04,  1.6513e-04,  1.2536e-04, -7.2196e-05,\n",
      "          1.4741e-04,  1.5852e-04,  1.6589e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 8.4457e+10], dtype=torch.float64)), tensor(0.0867, dtype=torch.float64))\n",
      "((tensor([[ 2.0536e-04,  1.6878e-04,  2.1216e-04,  1.0993e-04,  1.2299e-04,\n",
      "          1.2547e-04,  1.7900e-04,  2.9291e-04],\n",
      "        [ 2.1345e-04,  1.7217e-04,  1.8871e-04,  1.1167e-04,  5.7323e-05,\n",
      "          6.7562e-05,  1.8011e-04,  1.8960e-04],\n",
      "        [ 2.0225e-04,  1.7249e-04,  1.8391e-04,  1.1451e-04,  8.9466e-05,\n",
      "         -3.2537e-05,  1.7050e-04,  5.3523e-05],\n",
      "        [ 1.5791e-04,  1.3812e-04,  1.6615e-04,  1.2514e-04,  1.7480e-04,\n",
      "          1.5551e-04,  1.5916e-04,  1.5571e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 9.2710e+10], dtype=torch.float64)), tensor(0.0943, dtype=torch.float64))\n",
      "((tensor([[ 2.7763e-04,  1.8731e-04,  2.3116e-04,  1.0993e-04, -1.6888e-04,\n",
      "          1.0703e-04,  1.9883e-04,  2.1775e-04],\n",
      "        [ 2.0915e-04,  1.7150e-04,  2.1635e-04,  1.1167e-04,  1.2214e-04,\n",
      "          1.2816e-04,  1.8250e-04,  3.0135e-04],\n",
      "        [ 2.1722e-04,  1.7523e-04,  1.9374e-04,  1.1451e-04,  6.0427e-05,\n",
      "          6.8779e-05,  1.8317e-04,  1.9424e-04],\n",
      "        [ 2.0600e-04,  1.7579e-04,  1.8752e-04,  1.1536e-04,  9.1779e-05,\n",
      "         -3.3136e-05,  1.7348e-04,  5.5256e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 9.9336e+10], dtype=torch.float64)), tensor(0.0703, dtype=torch.float64))\n",
      "((tensor([[ 2.2831e-04,  1.7611e-04,  2.3036e-04,  1.4169e-04,  8.4645e-05,\n",
      "          9.3502e-05,  1.9114e-04,  1.3906e-04],\n",
      "        [ 2.8072e-04,  1.8896e-04,  2.3403e-04,  1.1087e-04, -1.6651e-04,\n",
      "          1.0855e-04,  2.0126e-04,  2.2242e-04],\n",
      "        [ 2.1132e-04,  1.7329e-04,  2.2052e-04,  1.1368e-04,  1.2783e-04,\n",
      "          1.2953e-04,  1.8427e-04,  3.0652e-04],\n",
      "        [ 2.1966e-04,  1.7730e-04,  1.9612e-04,  1.1453e-04,  6.1544e-05,\n",
      "          6.9541e-05,  1.8504e-04,  1.9909e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.0464e+11], dtype=torch.float64)), tensor(0.0101, dtype=torch.float64))\n",
      "((tensor([[ 2.3020e-04,  1.8913e-04,  2.3883e-04,  1.4159e-04,  1.4834e-04,\n",
      "          1.3555e-04,  2.0222e-04,  1.5782e-04],\n",
      "        [ 2.3237e-04,  1.7883e-04,  2.3475e-04,  1.4384e-04,  8.4006e-05,\n",
      "          9.5448e-05,  1.9475e-04,  1.4298e-04],\n",
      "        [ 2.8550e-04,  1.9219e-04,  2.4012e-04,  1.1361e-04, -1.7542e-04,\n",
      "          1.1043e-04,  2.0455e-04,  2.2772e-04],\n",
      "        [ 2.1510e-04,  1.7649e-04,  2.2470e-04,  1.1446e-04,  1.3105e-04,\n",
      "          1.3183e-04,  1.8737e-04,  3.1624e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.0693e+11], dtype=torch.float64)), tensor(0.0862, dtype=torch.float64))\n",
      "((tensor([[ 2.3186e-04,  1.7645e-04,  2.3883e-04,  1.4143e-04,  1.1380e-04,\n",
      "          1.5274e-04,  1.9938e-04,  3.0478e-04],\n",
      "        [ 2.3417e-04,  1.9195e-04,  2.4327e-04,  1.4368e-04,  1.4714e-04,\n",
      "          1.3830e-04,  2.0593e-04,  1.6219e-04],\n",
      "        [ 2.3622e-04,  1.8180e-04,  2.4073e-04,  1.4733e-04,  8.8453e-05,\n",
      "          9.7057e-05,  1.9783e-04,  1.4631e-04],\n",
      "        [ 2.9046e-04,  1.9564e-04,  2.4455e-04,  1.1433e-04, -1.7974e-04,\n",
      "          1.1233e-04,  2.0789e-04,  2.3482e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.2870e+11], dtype=torch.float64)), tensor(0.0231, dtype=torch.float64))\n",
      "((tensor([[2.3245e-04, 1.8039e-04, 2.4329e-04, 1.4143e-04, 1.3220e-04, 1.7884e-04,\n",
      "         2.0400e-04, 2.1630e-04],\n",
      "        [2.3614e-04, 1.7929e-04, 2.4354e-04, 1.4368e-04, 1.1302e-04, 1.5602e-04,\n",
      "         2.0327e-04, 3.1357e-04],\n",
      "        [2.3832e-04, 1.9537e-04, 2.4975e-04, 1.4733e-04, 1.5511e-04, 1.4080e-04,\n",
      "         2.0943e-04, 1.6616e-04],\n",
      "        [2.4060e-04, 1.8527e-04, 2.4545e-04, 1.4843e-04, 9.0739e-05, 9.8841e-05,\n",
      "         2.0130e-04, 1.5105e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.2704e+11], dtype=torch.float64)), tensor(0.0948, dtype=torch.float64))\n",
      "((tensor([[2.2334e-04, 1.7436e-04, 2.3167e-04, 1.7695e-04, 1.3523e-04, 1.1294e-04,\n",
      "         1.9673e-04, 6.2543e-05],\n",
      "        [2.3568e-04, 1.8247e-04, 2.4699e-04, 1.4304e-04, 1.3070e-04, 1.8187e-04,\n",
      "         2.0706e-04, 2.2154e-04],\n",
      "        [2.3925e-04, 1.8167e-04, 2.4892e-04, 1.4667e-04, 1.1861e-04, 1.5813e-04,\n",
      "         2.0581e-04, 3.1982e-04],\n",
      "        [2.4166e-04, 1.9821e-04, 2.5352e-04, 1.4777e-04, 1.5841e-04, 1.4275e-04,\n",
      "         2.1215e-04, 1.7077e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.4041e+11], dtype=torch.float64)), tensor(0.0363, dtype=torch.float64))\n",
      "((tensor([[2.2651e-04, 1.7470e-04, 2.4843e-04, 1.7663e-04, 2.0208e-04, 1.8398e-04,\n",
      "         2.0883e-04, 9.8032e-05],\n",
      "        [2.2705e-04, 1.7684e-04, 2.3581e-04, 1.7943e-04, 1.3405e-04, 1.1515e-04,\n",
      "         2.0021e-04, 6.4229e-05],\n",
      "        [2.3942e-04, 1.8538e-04, 2.5311e-04, 1.4640e-04, 1.3753e-04, 1.8481e-04,\n",
      "         2.1020e-04, 2.2655e-04],\n",
      "        [2.4324e-04, 1.8480e-04, 2.5334e-04, 1.4750e-04, 1.2145e-04, 1.6074e-04,\n",
      "         2.0903e-04, 3.2958e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.4837e+11], dtype=torch.float64)), tensor(0.0180, dtype=torch.float64))\n",
      "((tensor([[2.3102e-04, 1.7590e-04, 2.4923e-04, 1.7653e-04, 1.9272e-04, 1.8265e-04,\n",
      "         2.1138e-04, 2.5602e-04],\n",
      "        [2.3055e-04, 1.7740e-04, 2.5318e-04, 1.7933e-04, 2.0056e-04, 1.8781e-04,\n",
      "         2.1278e-04, 1.0080e-04],\n",
      "        [2.3093e-04, 1.7988e-04, 2.4196e-04, 1.8388e-04, 1.4123e-04, 1.1716e-04,\n",
      "         2.0349e-04, 6.5763e-05],\n",
      "        [2.4371e-04, 1.8881e-04, 2.5793e-04, 1.4741e-04, 1.4100e-04, 1.8809e-04,\n",
      "         2.1375e-04, 2.3375e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.4797e+11], dtype=torch.float64)), tensor(0.0242, dtype=torch.float64))\n",
      "((tensor([[2.3585e-04, 1.7785e-04, 2.5779e-04, 1.7653e-04, 2.1059e-04, 2.1177e-04,\n",
      "         2.1803e-04, 3.2801e-04],\n",
      "        [2.3528e-04, 1.7872e-04, 2.5415e-04, 1.7933e-04, 1.9139e-04, 1.8657e-04,\n",
      "         2.1550e-04, 2.6340e-04],\n",
      "        [2.3463e-04, 1.8055e-04, 2.5993e-04, 1.8388e-04, 2.1142e-04, 1.9120e-04,\n",
      "         2.1640e-04, 1.0327e-04],\n",
      "        [2.3521e-04, 1.8332e-04, 2.4670e-04, 1.8526e-04, 1.4488e-04, 1.1931e-04,\n",
      "         2.0705e-04, 6.7893e-05]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.5361e+11], dtype=torch.float64)), tensor(-0.0265, dtype=torch.float64))\n",
      "((tensor([[2.3246e-04, 1.7390e-04, 2.3476e-04, 1.8357e-04, 1.1320e-04, 1.1554e-04,\n",
      "         2.1506e-04, 5.8738e-05],\n",
      "        [2.4015e-04, 1.8067e-04, 2.6282e-04, 1.7929e-04, 2.0909e-04, 2.1626e-04,\n",
      "         2.3595e-04, 3.3740e-04],\n",
      "        [2.3939e-04, 1.8186e-04, 2.6087e-04, 1.8384e-04, 2.0171e-04, 1.8989e-04,\n",
      "         2.3309e-04, 2.6979e-04],\n",
      "        [2.3893e-04, 1.8396e-04, 2.6497e-04, 1.8522e-04, 2.1684e-04, 1.9467e-04,\n",
      "         2.3432e-04, 1.0659e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.3958e+11], dtype=torch.float64)), tensor(0.2104, dtype=torch.float64))\n",
      "((tensor([[2.2021e-04, 1.7699e-04, 2.1449e-04, 1.8340e-04, 1.0768e-04, 1.0233e-04,\n",
      "         2.0379e-04, 1.1240e-04],\n",
      "        [2.3652e-04, 1.7653e-04, 2.3916e-04, 1.8631e-04, 1.1231e-04, 1.1791e-04,\n",
      "         2.1905e-04, 6.0374e-05],\n",
      "        [2.4417e-04, 1.8371e-04, 2.6957e-04, 1.8367e-04, 2.2020e-04, 2.1995e-04,\n",
      "         2.3973e-04, 3.4533e-04],\n",
      "        [2.4360e-04, 1.8516e-04, 2.6573e-04, 1.8504e-04, 2.0673e-04, 1.9319e-04,\n",
      "         2.3694e-04, 2.7827e-04]], dtype=torch.float64), tensor([0.0000e+00, 1.0000e+00, 3.0000e+00, 1.6188e+11], dtype=torch.float64)), tensor(0.1677, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "print(len(dynamic_tensor_dataset))\n",
    "for i, thing in list(enumerate(dynamic_tensor_dataset))[:100]:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "with open(r\"..\\other_pickle\\measures.json\", \"r\") as file:\n",
    "    measures = json.load(file)\n",
    "\n",
    "static_size = len(measures[\"static\"])\n",
    "dynamic_size = len(measures[\"dynamic\"])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "STATIC_BATCH_SIZE = 20\n",
    "DYNAMIC_BATCH_SIZE = 5\n",
    "\n",
    "static_train_dataloader = torch.utils.data.DataLoader(static_tensor_dataset, batch_size=STATIC_BATCH_SIZE, shuffle=True)\n",
    "dynamic_train_dataloader = torch.utils.data.DataLoader(dynamic_tensor_dataset, batch_size=DYNAMIC_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "LAYERS = 8\n",
    "\n",
    "class StaticLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, batch_size, layers, input, categories=0):\n",
    "        super(StaticLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.layers_num = layers\n",
    "        \n",
    "        #input is all the embedding vectors plus all the other variables\n",
    "        self.lstm = nn.LSTM(input, hidden_dim, num_layers=layers, batch_first=True) \n",
    "        self.hidden = (torch.zeros(layers,batch_size,hidden_dim),torch.zeros(layers,batch_size,hidden_dim))\n",
    "        \n",
    "        #Squeeeze them into 1 dimension\n",
    "        if categories > 0:\n",
    "            self.hidden2label = nn.Linear(hidden_dim, categories)\n",
    "        else:\n",
    "            self.hidden2label = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, batch_tensor):\n",
    "        lstm_out, self.hidden = self.lstm(batch_tensor)\n",
    "        last_timestep_output = lstm_out[:, -1, :]\n",
    "        sales = self.hidden2label(last_timestep_output)\n",
    "        return sales\n",
    "    \n",
    "    def hidden_reset(self):\n",
    "        #reset the hidden and cell state after each epoch\n",
    "        self.hidden = (torch.zeros(self.layers_num,self.batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,self.batch_size,self.hidden_dim))\n",
    "    def batch_reset(self,batch_size):\n",
    "        self.hidden = (torch.zeros(self.layers_num,batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,batch_size,self.hidden_dim))\n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "static_model = StaticLSTM(HIDDEN_SIZE, STATIC_BATCH_SIZE, LAYERS, static_size, categories=6)\n",
    "static_model = static_model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.L1Loss()\n",
    "loss_scores = [float('inf')]\n",
    "learning_rate = 0.01\n",
    "epochs = 2\n",
    "static_model = static_model.to(device)\n",
    "optimizer = optim.Adam(static_model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    static_model.hidden_reset()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(static_train_dataloader):\n",
    "        (input, worthless_input), label = batch\n",
    "        if input.shape[0] != STATIC_BATCH_SIZE:\n",
    "            static_model.batch_reset(input.shape[0])\n",
    "            print(\"Reset triggered due to batch size mismatch\")\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = static_model(input).squeeze()\n",
    "        \n",
    "        # Ensure output and label shapes are compatible for the loss function\n",
    "        if output.shape != label.shape:\n",
    "            print(f\"Output shape: {output.shape}, Label shape: {label.shape}\")\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 49:\n",
    "            print(f\"Batch {i+1}, Loss: {epoch_loss / (i+1)}\")\n",
    "    \n",
    "    average_epoch_loss = epoch_loss / len(static_train_dataloader)\n",
    "    print(f\"Average loss for epoch {epoch+1}: {average_epoch_loss}\")\n",
    "    \n",
    "    if average_epoch_loss < loss_scores[-1]:\n",
    "        torch.save(static_model.state_dict(), \"../other_pickle/Static_Model.pth\")\n",
    "        print(\"Model saved\")\n",
    "    loss_scores.append(average_epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = split_tensor_dataset(static_tensor_dataset)\n",
    "parameters = {\n",
    "    'lr': [0.1, 0.01],  # Learning rate,  \n",
    "    'max_epochs': [1, 2],\n",
    "    \"hidden_dim\": [100, 200,300],\n",
    "    \"layers\": [2,4,8]\n",
    "}\n",
    "Model, params = grid_search(static_model, parameters, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_model.load_state_dict(torch.load(\"../other_pickle/Static_Model.pth\"))\n",
    "static_model.eval()\n",
    "for i, batch in list(enumerate(static_train_dataloader))[:10]:\n",
    "    (input, worthless_input), label = batch\n",
    "    output = static_model(input).squeeze()\n",
    "    # loss = loss_function(output, label)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "LAYERS = 8\n",
    "\n",
    "class DynamicLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, batch_size, layers, input, categories=0):\n",
    "        super(DynamicLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.layers_num = layers\n",
    "        \n",
    "        #input is all the embedding vectors plus all the other variables\n",
    "        self.lstm = nn.LSTM(input, hidden_dim, num_layers=layers, batch_first=True) \n",
    "        self.hidden = (torch.zeros(layers,batch_size,hidden_dim),torch.zeros(layers,batch_size,hidden_dim))\n",
    "        \n",
    "        #Squeeeze them into 1 dimension\n",
    "        if categories > 0:\n",
    "            self.hidden2label = nn.Linear(hidden_dim, categories)\n",
    "        else:\n",
    "            self.hidden2label = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, batch_tensor):\n",
    "        lstm_out, self.hidden = self.lstm(batch_tensor)\n",
    "        last_timestep_output = lstm_out[:, -1, :]\n",
    "        sales = self.hidden2label(last_timestep_output)\n",
    "        return sales\n",
    "    \n",
    "    def hidden_reset(self):\n",
    "        #reset the hidden and cell state after each epoch\n",
    "        self.hidden = (torch.zeros(self.layers_num,self.batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,self.batch_size,self.hidden_dim))\n",
    "    def batch_reset(self,batch_size):\n",
    "        self.hidden = (torch.zeros(self.layers_num,batch_size,self.hidden_dim),\n",
    "                       torch.zeros(self.layers_num,batch_size,self.hidden_dim))\n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "dynamic_model = DynamicLSTM(HIDDEN_SIZE, STATIC_BATCH_SIZE, LAYERS, dynamic_size, categories=0)\n",
    "dynamic_model = dynamic_model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.HuberLoss(delta=1.0)\n",
    "loss_scores = [float('inf')]\n",
    "learning_rate = 0.01\n",
    "epochs = 1\n",
    "dynamic_model = dynamic_model.to(device)\n",
    "optimizer = optim.Adam(dynamic_model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    dynamic_model.hidden_reset()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(dynamic_train_dataloader):\n",
    "        (input, worthless_input), label = batch\n",
    "        if input.shape[0] != DYNAMIC_BATCH_SIZE:\n",
    "            dynamic_model.batch_reset(input.shape[0])\n",
    "            print(\"Reset triggered due to batch size mismatch\")\n",
    "\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = dynamic_model(input).squeeze()\n",
    "        \n",
    "        # Ensure output and label shapes are compatible for the loss function\n",
    "        if output.shape != label.shape:\n",
    "            print(f\"Output shape: {output.shape}, Label shape: {label.shape}\")\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Batch {i+1}, Loss: {epoch_loss / (i+1)}\")\n",
    "    \n",
    "    average_epoch_loss = epoch_loss / len(dynamic_train_dataloader)\n",
    "    print(f\"Average loss for epoch {epoch+1}: {average_epoch_loss}\")\n",
    "    \n",
    "    if average_epoch_loss < loss_scores[-1]:\n",
    "        torch.save(dynamic_model.state_dict(), \"../other_pickle/Dynamic_Model.pth\")\n",
    "        print(\"Model saved\")\n",
    "    loss_scores.append(average_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment.  If you were attempting to deepcopy a module, this may be because of a torch.nn.utils.weight_norm usage, see https://github.com/pytorch/pytorch/pull/103001",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m split_tensor_dataset(dynamic_tensor_dataset)\n\u001b[0;32m      2\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer__lr\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m],  \u001b[38;5;66;03m# Learning rate,  \u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: [torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW]\n\u001b[0;32m      8\u001b[0m }\n\u001b[1;32m----> 9\u001b[0m Model, params \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Python\\Finance\\EDGAR\\code\\infer_functions.py:92\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(Model, parameters, x_train, y_train)\u001b[0m\n\u001b[0;32m     90\u001b[0m net \u001b[38;5;241m=\u001b[39m NeuralNetClassifier(Model)\n\u001b[0;32m     91\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(net, parameters, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming X_train and y_train are your data\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gs, gs\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:880\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    877\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[0;32m    878\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv_orig\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)\n\u001b[1;32m--> 880\u001b[0m base_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch)\n\u001b[0;32m    884\u001b[0m fit_and_score_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    885\u001b[0m     scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    886\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    893\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    894\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:91\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:123\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m    121\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 123\u001b[0m     new_object_params[name] \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m new_object \u001b[38;5;241m=\u001b[39m klass(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_object_params)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:91\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:104\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safe:\n\u001b[1;32m--> 104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:86\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__deepcopy__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, memo)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly Tensors created explicitly by the user \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(graph leaves) support the deepcopy protocol at the moment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you were attempting to deepcopy a module, this may be because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof a torch.nn.utils.weight_norm usage, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msee https://github.com/pytorch/pytorch/pull/103001\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m     )\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment.  If you were attempting to deepcopy a module, this may be because of a torch.nn.utils.weight_norm usage, see https://github.com/pytorch/pytorch/pull/103001"
     ]
    }
   ],
   "source": [
    "x_train, y_train = split_tensor_dataset(dynamic_tensor_dataset)\n",
    "parameters = {\n",
    "    'optimizer__lr': [0.1, 0.01],  # Learning rate,  \n",
    "    'epochs': [1, 2],\n",
    "    \"module__hidden_dim\": [100, 200,300],\n",
    "    \"module__layers\": [2,4,8],\n",
    "    'optimizer': [torch.optim.AdamW]\n",
    "}\n",
    "Model, params = grid_search(dynamic_model, parameters, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.2713,  0.1489,  0.2096, -0.0097,  0.1655], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0210,  0.1331, -0.1985, -0.0201,  0.1393], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.1282, 0.1938, 0.0883, 0.1082, 0.1084], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0135, -0.1150, -0.0176, -0.0967, -0.0629], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.1300, 0.0443, 0.2106, 0.0685, 0.0525], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0793, -0.0098,  0.0805,  0.1592, -0.2315], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.1167, 0.0708, 0.1372, 0.2978, 0.0286], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.2896, 0.3533, 0.0659, 0.0293, 0.0942], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1468,  0.1028, -0.0146, -0.1069,  0.1036], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1003,  0.1426,  0.1776, -0.0369, -0.0035], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1028,  0.0444,  0.0920, -0.0589,  0.1955], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0499,  0.1577,  0.0183,  0.0831, -0.0164], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1645,  0.1983, -0.0392, -0.0313,  0.1151], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0492, -0.0950,  0.0664,  0.0625,  0.0874], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0299,  0.1205, -0.0384,  0.1110,  0.0247], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0465,  0.0426,  0.0331,  0.0447, -0.0910], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0262, -0.1008, -0.0191,  0.1097, -0.0569], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.1483, 0.0424, 0.0867, 0.0943, 0.0703], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0101, 0.0862, 0.0231, 0.0948, 0.0363], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0180,  0.0242, -0.0265,  0.2104,  0.1677], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0461,  0.1261, -0.0256,  0.1150,  0.0388], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1114, -0.0737, -0.0490,  0.0412, -0.0356], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0860,  0.1238,  0.0494, -0.0056, -0.0069], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1702,  0.1582,  0.0663, -0.0145,  0.0642], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0290, 0.0392, 0.0375, 0.1190, 0.0909], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0776, -0.0887,  0.0361,  0.0748, -0.0156], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0095, 0.0421, 0.0634, 0.0769, 0.0335], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0496, -0.0372,  0.1725, -0.0238,  0.0450], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0040, 0.0249, 0.0674, 0.1237, 0.0888], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0219,  0.0744, -0.0334, -0.0255,  0.1370], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0951,  0.0105, -0.0012, -0.0928,  0.2067], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0242, 0.0730, 0.1266, 0.1377, 0.1106], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0722, -0.0940, -0.0015, -0.1072, -0.0401], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0395,  0.1117,  0.1924,  0.0857, -0.0168], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0158, -0.1219,  0.0164,  0.1568, -0.0261], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.2373,  0.1290,  0.1532, -0.0088,  0.0058], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0504, 0.1849, 0.1451, 0.0765, 0.1922], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1440, -0.0116,  0.1459,  0.0010,  0.0471], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0387,  0.0390,  0.0888, -0.0406,  0.1777], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0325, 0.0488, 0.1195, 0.1611, 0.0797], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1555,  0.1155,  0.1862,  0.0777, -0.0578], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0579, 0.0801, 0.0527, 0.0185, 0.1664], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0026, 0.2581, 0.0464, 0.0058, 0.0828], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.2846, -0.0298, -0.2802, -0.1450, -0.0660], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.2298,  0.0901,  0.1330,  0.4115,  0.1037], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1014,  0.0020, -0.0273, -0.1338, -0.0285], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.2362,  0.0201, -0.1935, -0.1179,  0.0290], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0136, -0.0734,  0.0251,  0.1094,  0.1512], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1668, -0.0177,  0.1125,  0.1256, -0.0349], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1798, -0.0845, -0.1670, -0.1379,  0.1475], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.1681, 0.2064, 0.1743, 0.1486, 0.2067], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1323,  0.1657, -0.0186, -0.0069, -0.1039], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.2106,  0.0203,  0.1898,  0.0489,  0.1297], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1875, -0.1858,  0.2624,  0.0184,  0.5717], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.3208,  0.0031,  0.0220,  0.1157, -0.1939], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1374, -0.0486,  0.3216,  0.1034,  0.2359], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-3.1244e-02,  7.2593e-02,  5.5982e-01, -7.8315e-02,  9.0465e-05],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0302,  0.0561, -0.1074, -0.3319,  0.0767], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.2132, -0.2150,  0.2709, -0.0030,  0.7972], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.4580,  0.4040,  0.3166, -0.1021,  0.0404], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1221,  0.0722,  0.3238,  0.6263, -0.3396], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.3030, 0.2428, 0.0118, 0.4012, 0.1645], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.2250,  0.5214,  0.1058, -0.1009,  0.0413], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.3100,  0.3148, -0.2361, -0.2079, -0.1522], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1530,  0.2442,  0.2251, -0.1085,  0.0337], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0773,  0.0021,  0.0171, -0.0315,  0.0960], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0608,  0.1039,  0.1207,  0.0718,  0.1948], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0414, 0.0912, 0.0807, 0.1339, 0.0152], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0514,  0.1601,  0.1558, -0.0363, -0.0087], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0187,  0.0729, -0.0600,  0.0671,  0.1051], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1345,  0.1524, -0.0383,  0.0823, -0.0366], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0144,  0.0055,  0.0804, -0.0370, -0.0194], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0591,  0.1131,  0.1695, -0.0996,  0.1850], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0624, -0.0582,  0.0635,  0.0235, -0.0879], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0017,  0.0889,  0.0429,  0.0013,  0.1666], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1159, -0.0306,  0.4007,  0.1905,  0.0696], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.5140, -0.0354, -0.0687,  0.1786,  0.1996], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0045,  0.1921,  0.1319, -0.1405,  0.0307], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1684,  0.1249, -0.0178,  0.0462,  0.0480], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1147,  0.2664, -0.1179, -0.1087, -0.0064], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0656,  0.2400,  0.1817,  0.2318,  0.2376], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1427,  0.2539,  0.1063, -0.0137,  0.1331], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.2335,  0.2684,  0.1001,  0.1134, -0.1864], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1219,  0.1030, -0.0381,  0.0074,  0.1418], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.4301, 0.2302, 0.0079, 0.0095, 0.1140], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0020, -0.0206, -0.1040, -0.2616,  0.1148], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.2573,  0.1344,  0.2747,  0.0554, -0.0263], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0646,  0.1359,  0.1441, -0.1038,  0.0210], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0892, -0.1824,  0.2281,  0.1776,  0.2172], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0282,  0.0085,  0.0897,  0.1910, -0.0101], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1091, -0.0404,  0.2701,  0.1129,  0.3689], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0694,  0.2382, -0.0596,  0.0165,  0.0463], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1143,  0.0463, -0.1461,  0.1260,  0.0353], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0267,  0.0135,  0.0480,  0.0972,  0.2074], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.1145,  0.2082, -0.0639,  0.0435, -0.0608], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0176,  0.1782, -0.0575, -0.0378,  0.0620], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.1382,  0.0233,  0.0263,  0.1811,  0.1319], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([0.0955, 0.2726, 0.1827, 0.1720, 0.0400], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([ 0.0140, -0.0577,  0.2301, -0.0852,  0.0027], dtype=torch.float64)\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward0>) tensor([-0.0841, -0.3634, -0.0649, -0.1103,  0.2682], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dynamic_model.load_state_dict(torch.load(\"../other_pickle/Dynamic_Model.pth\"))\n",
    "dynamic_model.eval()\n",
    "for i, batch in list(enumerate(dynamic_train_dataloader))[:100]:\n",
    "    (input, worthless_input), label = batch\n",
    "    output = dynamic_model(input).squeeze()\n",
    "    # loss = loss_function(output, label)\n",
    "    # print(F.softmax(output, dim=1), label)\n",
    "    print(output, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
