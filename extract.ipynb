{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "import requests\n",
    "from fredapi import Fred\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import yahoo_fin.stock_info as si\n",
    "from datetime import datetime\n",
    "import tracemalloc\n",
    "\n",
    "fred = Fred(api_key='0c34c4dd2fd6943f6549f1c990a8a0f0') \n",
    "client =  httpx.AsyncClient()\n",
    "async def fetch(url, headers, semaphore, client, timeout, max_retries, start_retry_delay):\n",
    "    async with semaphore:\n",
    "        for attempt in range(1,max_retries):\n",
    "            try:\n",
    "                response = await client.get(url, timeout=timeout, headers= headers)\n",
    "                response.raise_for_status()\n",
    "                return response  # Successful request, exit the loop\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                headers = response.headers\n",
    "                #Sometimes a retry-after header is returned\n",
    "                retry_after = headers.get('Retry-After')\n",
    "                if retry_after != None:\n",
    "                    #Just for debugging\n",
    "                    print(retry_after)\n",
    "                    await asyncio.sleep(retry_after.astype(int))\n",
    "                    continue\n",
    "                print(f\"Error response {e.response.status_code}.\")\n",
    "            except httpx.TimeoutException as e:\n",
    "                print(f\"Timeout reached: {e}\")\n",
    "                if attempt < max_retries:\n",
    "                    print(f\"Retrying in {attempt*start_retry_delay} seconds...\")\n",
    "                    await asyncio.sleep(attempt*start_retry_delay)\n",
    "                else:\n",
    "                    print(\"Max retries reached. Exiting.\")\n",
    "                    return 0\n",
    "            except httpx.RequestError as e:\n",
    "                print(f\"An error occurred: {e}.\")\n",
    "\n",
    "def fred_info(ids:list, start:str, end:str):\n",
    "    #start and end are datatime objects\n",
    "    start = start.strftime('%Y-%m-%d')\n",
    "    end = end.strftime('%Y-%m-%d')\n",
    "    frame = pd.DataFrame()\n",
    "    for id in ids:\n",
    "        series = fred.get_series(id,observation_start=start, observation_end=end)\n",
    "        frame[id] = series\n",
    "    frame = frame.reset_index()\n",
    "    frame[\"index\"] = frame[\"index\"].astype(str)\n",
    "    return frame.ffill().bfill()\n",
    "\n",
    "async def fred_fetch(ids:list, start:str, end:str):\n",
    "    fred_data = await asyncio.to_thread(fred_info,ids,start,end)\n",
    "    return fred_data\n",
    "\n",
    "async def yahoo_fetch(ticker ,start_year, end_year):\n",
    "    yahoo_data = await asyncio.to_thread(si.get_data,ticker,start_year, end_year)\n",
    "    return yahoo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runlist(dict, nameslist):\n",
    "    idx = 0\n",
    "    while (idx<len(nameslist)):\n",
    "        try:\n",
    "            data = dict[nameslist[idx]]\n",
    "            return data\n",
    "        except KeyError:\n",
    "            idx +=1\n",
    "    raise KeyError(f\"None of the names in {nameslist} matched {dict}\")\n",
    "\n",
    "\n",
    "def getcik(ticker):\n",
    "    #Convert the ticker into the proper cik\n",
    "    for key,value in cikdata.items():\n",
    "        if value[\"ticker\"] == ticker:\n",
    "            cik = value[\"cik_str\"]\n",
    "            break\n",
    "    return str(cik).zfill(10)\n",
    "\n",
    "#Headers for EDGAR call\n",
    "headers = {\n",
    "    \"User-Agent\":\"ficakc@seznam.cz\",\n",
    "    \"Accept-Encoding\":\"gzip, deflate\",\n",
    "}\n",
    "\n",
    "TIMEOUT = 8\n",
    "RETRIES = 2\n",
    "START_RETRY_DELAY = 0.4\n",
    "# cik_url =  \"https://www.sec.gov/files/company_tickers.json\"\n",
    "# cikdata = requests.get(cik_url, headers=headers).json()\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\cik.json\",\"r\") as file:\n",
    "    cikdata = json.load(file)\n",
    "    file.close()\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\apple.json\",\"r\") as file:\n",
    "    Apple = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "def companyfacts(ticker:str, client, semaphore):\n",
    "    #Get all the financial data for a ticker\n",
    "    cik = getcik(ticker)\n",
    "    data_url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    facts = fetch(data_url, headers, semaphore, client, TIMEOUT,RETRIES,START_RETRY_DELAY)\n",
    "    return facts\n",
    "\n",
    "def endtodatetime(dataframe):\n",
    "    dataframe.loc[:,\"end\"] = pd.datetime(dataframe[\"end\"])\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, ticker:str):\n",
    "        self.ticker = ticker.upper()\n",
    "        self.cik = getcik(self.ticker)\n",
    "        \n",
    "    async def async_init(self,client, semaphore, measures):\n",
    "        #Get all of the data for the company, ALL of it \n",
    "        # snapshot3 = tracemalloc.take_snapshot()\n",
    "        data = await companyfacts(self.ticker, client, semaphore)\n",
    "        # snapshot4 = tracemalloc.take_snapshot()\n",
    "        # top_stats = snapshot3.compare_to(snapshot4, 'lineno')\n",
    "        # for stat in top_stats[:10]:\n",
    "        #     print(stat)\n",
    "        #If the response wasn't recieved, skips the rest of the code \n",
    "        if type(data) != int:\n",
    "            self.data = data.json()\n",
    "        else:\n",
    "            return\n",
    "        #Get the share amount \n",
    "        self.share_name_list = [\"EntityCommonStockSharesOutstanding\",\"CommonStockSharesOutstanding\", \"EntityPublicFloat\"]\n",
    "        share_info = runlist(self.data[\"facts\"][\"dei\"], self.share_name_list)\n",
    "        share_date= datetime.strptime(share_info[\"units\"][\"shares\"][0][\"end\"], r\"%Y-%m-%d\")\n",
    "        self.start_year = max([share_date] + [datetime.strptime(self.data[\"facts\"][\"us-gaap\"][measure][\"units\"][\"USD\"][0][\"end\"], r\"%Y-%m-%d\") if measure in self.data[\"facts\"][\"us-gaap\"] else datetime.strptime('1920-01-01', r\"%Y-%m-%d\") for measure in measures])\n",
    "        self.end_year = datetime.now().date()\n",
    "        #Get the price and set the self.price\n",
    "        self.fullprice = await yahoo_fetch(self.ticker,self.start_year, self.end_year)\n",
    "        self.fullprice = self.fullprice.reset_index()\n",
    "        Price = self.fullprice[[self.fullprice.columns[0],\"close\", \"adjclose\"]].copy()\n",
    "        Price[\"end\"] = Price[\"index\"].astype(str)\n",
    "        Price.drop(columns=[\"index\"],inplace=True)\n",
    "        date_range = pd.date_range(start=self.start_year, end=self.end_year).astype(str)\n",
    "        self.date_range = pd.DataFrame(date_range, columns=['end'])\n",
    "        Price = pd.merge(self.date_range, Price, on = [\"end\"],how=\"left\" )\n",
    "        self.price = Price.bfill()\n",
    "\n",
    "    def fact(self,measure,simple=True):\n",
    "        #Propagate the 0 \n",
    "        if self.data == 0:\n",
    "            return 0\n",
    "        try:\n",
    "            point_list = self.data[\"facts\"][\"us-gaap\"][measure][\"units\"][\"USD\"]\n",
    "            frame = pd.DataFrame(point_list)\n",
    "            frame = frame.drop_duplicates(subset='end', keep='last')\n",
    "            frame[measure] = frame[\"val\"]\n",
    "            if simple:\n",
    "                frame = frame[[\"end\", measure]]\n",
    "            frame = pd.merge(self.date_range,frame,on=\"end\",how=\"left\")\n",
    "            return frame.ffill()\n",
    "        except KeyError:\n",
    "            print(f\"Measure {measure} not available for company.\")\n",
    "    def shares(self,simple=True):\n",
    "        #Propagate the 0 \n",
    "        if self.data == 0:\n",
    "            return 0\n",
    "        if simple:\n",
    "            share_count = pd.DataFrame(runlist(self.data[\"facts\"][\"dei\"],self.share_name_list)[\"units\"][\"shares\"])[[\"end\",\"val\"]]\n",
    "        share_count[\"shares\"] = share_count[\"val\"]\n",
    "        share_count.drop(columns=[\"val\"], inplace = True)\n",
    "        share_count = share_count.drop_duplicates(subset=\"end\", keep=\"last\")\n",
    "        share_count = pd.merge(self.date_range, share_count, on=[\"end\"], how=\"left\")\n",
    "        return share_count.ffill()\n",
    "    \n",
    "async def async_task(ticker, client, semaphore, measures, indicators):\n",
    "    stock = Stock(ticker)\n",
    "    print(f\"Currently pinging {ticker}\")\n",
    "    await stock.async_init(client,semaphore,measures)\n",
    "    try:\n",
    "        #Price and shares oustanding \n",
    "        shares = stock.shares().copy()\n",
    "        stock_price = stock.price.copy()\n",
    "        df = pd.merge(shares, stock_price, left_on=[\"end\"], right_on=[\"end\"], how = \"left\")\n",
    "        frames_list = [stock.fact(measure) for measure in measures]\n",
    "        for frame in frames_list:\n",
    "            df = pd.merge(df,frame, on=[\"end\"], how=\"left\")\n",
    "    #HANDLE RETURNING NONES IN THE GATHER BECAUSE SOME FRAMES WILL BE NONE///////////////////////////\n",
    "    except AttributeError:\n",
    "        return\n",
    "    #Economic indicators \n",
    "    indicator_frame = await fred_fetch(indicators, stock.start_year, stock.end_year)\n",
    "    df = pd.merge(df, indicator_frame, left_on =[\"end\"], right_on=[\"index\"], how=\"left\")\n",
    "    return (ticker,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently pinging AAPL\n",
      "Currently pinging MSFT\n",
      "Currently pinging GOOGL\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'shares'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m company_frames_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[async_task(ticker, client, sem, measures, indicators) \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m ticker_list])\n\u001b[0;32m     19\u001b[0m company_frames_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker, df \u001b[38;5;129;01min\u001b[39;00m company_frames_tuples:\n",
      "Cell \u001b[1;32mIn[57], line 119\u001b[0m, in \u001b[0;36masync_task\u001b[1;34m(ticker, client, semaphore, measures, indicators)\u001b[0m\n\u001b[0;32m    117\u001b[0m stock \u001b[38;5;241m=\u001b[39m Stock(ticker)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently pinging \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m stock\u001b[38;5;241m.\u001b[39masync_init(client,semaphore,measures)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#Price and shares oustanding \u001b[39;00m\n\u001b[0;32m    122\u001b[0m     shares \u001b[38;5;241m=\u001b[39m stock\u001b[38;5;241m.\u001b[39mshares()\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[57], line 75\u001b[0m, in \u001b[0;36mStock.async_init\u001b[1;34m(self, client, semaphore, measures)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_name_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntityCommonStockSharesOutstanding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommonStockSharesOutstanding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntityPublicFloat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     74\u001b[0m share_info \u001b[38;5;241m=\u001b[39m runlist(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdei\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_name_list)\n\u001b[1;32m---> 75\u001b[0m share_date\u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[43mshare_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshares\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([share_date] \u001b[38;5;241m+\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-gaap\u001b[39m\u001b[38;5;124m\"\u001b[39m][measure][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m measure \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-gaap\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1920-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m measure \u001b[38;5;129;01min\u001b[39;00m measures])\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_year \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'shares'"
     ]
    }
   ],
   "source": [
    "#write out measures based on importance in descending order\n",
    "# tracemalloc.start()\n",
    "measures = [\"Assets\", \"Liabilities\", \"AssetsCurrent\", \"LiabilitiesCurrent\"]\n",
    "#write out the indicators \n",
    "indicators = [\"TB3MS\", \"DCOILWTICO\"]\n",
    "#Get the first n companies sorted by market cap \n",
    "companies_num = 3\n",
    "comp = 0\n",
    "sem = asyncio.Semaphore(9)\n",
    "#GATHER THE FIRST companies_num companies ciks and pass them to the gather with the tasks\n",
    "ticker_list = []\n",
    "for company, values in cikdata.items():\n",
    "    if comp<companies_num:\n",
    "        ticker_list.append(values[\"ticker\"])\n",
    "        comp+=1\n",
    "    else:\n",
    "        break\n",
    "company_frames_tuples = await asyncio.gather(*[async_task(ticker, client, sem, measures, indicators) for ticker in ticker_list])\n",
    "company_frames_dict = {}\n",
    "for ticker, df in company_frames_tuples:\n",
    "    company_frames_dict[ticker] = df\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple.data[\"facts\"][\"dei\"][\"EntityCommonStockSharesOutstanding\"][\"units\"][\"shares\"]\n",
    "frame  = fred_info([\"TB3MS\", \"DCOILWTICO\"], '2015-02-24', '2017-02-24')\n",
    "frame.head(40)\n",
    "# print(frame)\n",
    "\n",
    "frame[\"index\"] = frame[\"index\"].astype(str)\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\FRED.json\", \"w\") as file:\n",
    "    json.dump(frame.to_dict(orient=\"records\"), file, indent=1)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT = companyfacts('MSFT').json()\n",
    "print(MSFT[\"facts\"][\"dei\"][\"EntityCommonStockSharesOutstanding\"][\"units\"][\"shares\"][0][\"end\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = [\"Assets\", \"Liabilities\", \"AssetsCurrent\", \"LiabilitiesCurrent\"]\n",
    "Apple = Stock(\"aapl\", measures)\n",
    "stock = Apple\n",
    "shares = stock.shares()\n",
    "stock_num = stock.price\n",
    "if isinstance(shares, int) or isinstance(stock_num, int): \n",
    "    pass\n",
    "    # break\n",
    "df = pd.merge(shares.copy(), stock_num.copy(), on=[\"end\"], how = \"left\")\n",
    "frames_list = [stock.fact(measure) for measure in measures]\n",
    "for frame in frames_list:\n",
    "    df = pd.merge(df,frame, on=[\"end\"], how=\"left\")\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to info: Stock[\"facts\"][\"us-gaap\"][some_measure][\"units\"][\"USD\"]\n",
    "\n",
    "Path to meta info: Stock[\"facts\"][\"dei\"]\n",
    "\n",
    "List of all possible names for shares outstanding:\n",
    "    CommonStockSharesOutstanding\n",
    "    EntityCommonStockSharesOutstanding\n",
    "\n",
    "Three things:\n",
    "    First:\n",
    "        Graph and correlate measures and ratios\n",
    "            Currently forward filling fundamentals data, could be fucked in the future\n",
    "            Include the rate of change of the variables and compare those \n",
    "    Second:\n",
    "        Make a test to validate trading strategies\n",
    "            Add a function that picks eligible stocks at some timeframe and test their performance xdz\n",
    "    Third:\n",
    "        Train a model to predict the long term price\n",
    "            forward filling fundamentals can be really fucked \n",
    "            Consider using averages or linear change from previous value to next for training \n",
    "            Include all the past fundamentals for each datapoint - this could figure out how people value growth.\n",
    "\n",
    "Data to add for regression and AI:\n",
    "    oil price\n",
    "    interest rates \n",
    "        FRED HAS SO MUCH DATA HOLY SHIT \n",
    "        pick yer fucking poison mate\n",
    "    \n",
    "\n",
    "Measures:\n",
    "    Price/BookValuepershare = MarketCap/BookValue = EntityCommonStockSharesOutstanding*SPrice(Assets-Liabilities)\n",
    "    Price/Earnings - all the possible earnings metrics\n",
    "    Current ratio = AssetsCurrent/LiabilitiesCurrent\n",
    "    ///////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    Revenue\n",
    "    Operating Income \n",
    "    Free cash flow \n",
    "    EBITDA \n",
    "    Dividends - \"PaymentsOfDividendsCommonStock\"\n",
    "\n",
    "How does market cap influence these correlations?\n",
    "\n",
    "Where do you find price data?\n",
    "    Yahoo-fin.\n",
    "\n",
    "\n",
    "Methods to figure out relationships:\n",
    "    Kendall's Tau\n",
    "    Spearman's Rank Correlation\n",
    "\n",
    "    cross variable correlation loop through all variables \n",
    "    Polynomial regression\n",
    "    LSTM\n",
    "\n",
    "\n",
    "Todo:\n",
    "    You are using the calls one after another in the same task, you can run them concurrently\n",
    "    Investigate why not forward filling\n",
    "    Implement a list check for all the possible names for common shares\n",
    "    Implement ConnectionError safeguard\n",
    "    Remove memory snapshots if not useful\n",
    "    Make run list implementation for shares aswell -ITS FUCKEDDDDDDDDDDDDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get all the measure names*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\stock.json\", \"w\") as file:\n",
    "#     json.dump(df.to_dict(orient='records'), file, indent=1)\n",
    "#     file.close()\n",
    "\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\shares.json\", \"w\") as file:\n",
    "    json.dump(stock.shares().copy().to_dict(orient='records'), file, indent=1)\n",
    "    file.close()\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\assets.json\", \"w\") as file:\n",
    "    json.dump(Apple[\"facts\"][\"us-gaap\"][\"Assets\"][\"units\"][\"USD\"], file, indent=1)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = {}\n",
    "for key,value in Apple[\"facts\"][\"us-gaap\"].items() :\n",
    "    measures[key.ljust(100)] = value[\"label\"]\n",
    "\n",
    "measures[\"METADATA\".ljust(200,\"/\")] = \"\"\n",
    "\n",
    "for key,value in Apple[\"facts\"][\"dei\"].items():\n",
    "    measures[key.ljust(100)] = value[\"label\"]\n",
    "\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\measures.json\",\"w\") as file:\n",
    "    json.dump(measures, file, indent=1)\n",
    "\n",
    "\n",
    "#create price reference list:\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\price.json\", \"w\") as file:\n",
    "    json.dump(Apple.price.to_dict(orient='records'), file, indent=1)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Apple[\"facts\"][\"us-gaap\"][\"AssetsCurrent\"][\"units\"][\"USD\"] :\n",
    "    try:\n",
    "        del key[\"frame\"]\n",
    "        print(key)\n",
    "    except KeyError:\n",
    "        print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Apple[\"facts\"][\"us-gaap\"][\"Assets\"][\"units\"][\"USD\"][0][\"end\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
