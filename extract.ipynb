{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to info: Stock[\"facts\"][\"us-gaap\"][some_measure][\"units\"][\"USD\"]\n",
    "\n",
    "Path to meta info: Stock[\"facts\"][\"dei\"][some_meausere]\n",
    "\n",
    "List of all possible names for shares outstanding:\n",
    "    CommonStockSharesOutstanding\n",
    "    EntityCommonStockSharesOutstanding\n",
    "\n",
    "Decide if to ping individual concepts instead of getting all the data\n",
    "Alternative is storing all the files in harddisk instead of memory\n",
    "    The Current strategy is to store the data using pickle and reload it for analysis\n",
    "\n",
    "Three things:\n",
    "    First:\n",
    "        Graph and correlate measures and ratios\n",
    "            Currently forward filling fundamentals data, could be fucked in the future\n",
    "            Include the rate of change of the variables and compare those \n",
    "    Second:\n",
    "        Make a test to validate trading strategies\n",
    "            Add a function that picks eligible stocks at some timeframe and test their performance xdz\n",
    "    Third:\n",
    "        Train a model to predict the long term price\n",
    "            forward filling fundamentals can be really fucked \n",
    "            Consider using averages or linear change from previous value to next for training \n",
    "            Include all the past fundamentals for each datapoint - this could figure out how people value growth.\n",
    "\n",
    "Data to add for regression and AI:\n",
    "    oil price\n",
    "    interest rates \n",
    "        FRED HAS SO MUCH DATA HOLY SHIT \n",
    "        pick yer fucking poison mate\n",
    "    \n",
    "\n",
    "Measures:\n",
    "    Price/BookValuepershare = MarketCap/BookValue = EntityCommonStockSharesOutstanding*SPrice(Assets-Liabilities)\n",
    "    Price/Earnings - all the possible earnings metrics\n",
    "    Current ratio = AssetsCurrent/LiabilitiesCurrent\n",
    "    ///////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    Revenue\n",
    "    Operating Income \n",
    "    Free cash flow \n",
    "    EBITDA \n",
    "    Dividends - \"PaymentsOfDividendsCommonStock\"\n",
    "\n",
    "How does market cap influence these correlations?\n",
    "\n",
    "Where do you find price data?\n",
    "    Yahoo-fin.\n",
    "\n",
    "\n",
    "Methods to figure out relationships:\n",
    "    Kendall's Tau\n",
    "    Spearman's Rank Correlation\n",
    "\n",
    "    cross variable correlation loop through all variables \n",
    "    Polynomial regression\n",
    "    LSTM\n",
    "\n",
    "\n",
    "Todo:\n",
    "    You are using the calls one after another in the same task, you can run them concurrently\n",
    "    Investigate why not forward filling\n",
    "    Figure out the start time\n",
    "        Deprecate conversion is now okay, use pd.append to get the full measures.\n",
    "    Implement additive logic for unavailable measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "from fredapi import Fred\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yahoo_fin.stock_info as si\n",
    "from datetime import datetime\n",
    "import tracemalloc\n",
    "import copy\n",
    "\n",
    "fred = Fred(api_key='0c34c4dd2fd6943f6549f1c990a8a0f0') \n",
    "client =  httpx.AsyncClient()\n",
    "async def fetch(url, headers, semaphore, client, timeout, max_retries, start_retry_delay):\n",
    "    async with semaphore:\n",
    "        for attempt in range(1,max_retries):\n",
    "            try:\n",
    "                response = await client.get(url, timeout=timeout, headers= headers)\n",
    "                response.raise_for_status()\n",
    "                return response  # Successful request, exit the loop\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                    headers = response.headers\n",
    "                    #Sometimes a retry-after header is returned\n",
    "                    retry_after = headers.get('Retry-After')\n",
    "                    if retry_after != None:\n",
    "                        #Just for debugging\n",
    "                        print(retry_after)\n",
    "                        await asyncio.sleep(retry_after.astype(int))\n",
    "                        continue\n",
    "                    print(f\"Error response {e.response.status_code}.\")\n",
    "            except httpx.TimeoutException as e:\n",
    "                print(f\"Timeout reached: {e}\")\n",
    "                print(f\"Retrying in {attempt*start_retry_delay} seconds...\")\n",
    "                await asyncio.sleep(attempt*start_retry_delay)\n",
    "            except httpx.RequestError as e:\n",
    "                print(f\"An error occurred: {e}.\")\n",
    "                await asyncio.sleep(attempt*start_retry_delay)\n",
    "        return 0\n",
    "                \n",
    "\n",
    "def fred_info(ids:list, start:str, end:str):\n",
    "    #start and end are datatime objects\n",
    "    start = start.strftime('%Y-%m-%d')\n",
    "    end = end.strftime('%Y-%m-%d')\n",
    "    frame = pd.DataFrame()\n",
    "    for id in ids:\n",
    "        series = fred.get_series(id,observation_start=start, observation_end=end)\n",
    "        frame[id] = series\n",
    "    frame = frame.reset_index()\n",
    "    frame[\"index\"] = frame[\"index\"].astype(str)\n",
    "    frame = frame.ffill()\n",
    "    return frame.bfill()\n",
    "\n",
    "async def fred_fetch(ids:list, start:str, end:str):\n",
    "    fred_data = await asyncio.to_thread(fred_info,ids,start,end)\n",
    "    return fred_data\n",
    "\n",
    "async def yahoo_fetch(ticker ,start_year, end_year):\n",
    "    yahoo_data = await asyncio.to_thread(si.get_data,ticker,start_year, end_year)\n",
    "    return yahoo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decompose the measure into its constituents\n",
    "measure_conversion = {\"Assets\":[[\"AssetsNoncurrent\", \"AssetsCurrent\"]],\n",
    "                    \"Liabilities\":[[\"LiabilitiesCurrent\", \"LiabilitiesNoncurrent\"]],\n",
    "                    \"AssetsCurrent\":[[\"AssetsCurrent\"]],\n",
    "                    \"LiabilitiesCurrent\":[[\"LiabilitiesCurrent\"]],\n",
    "                    \"revenues\": [[\"revenues\"]]\n",
    "}\n",
    "\n",
    "#Lookup table for the undeprecated version of a measure\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\deprecated_to_current.json\", \"r\") as file:\n",
    "    deprecate_conversion = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "def runlist(dict, nameslist):\n",
    "    idx = 0\n",
    "    while (idx<len(nameslist)):\n",
    "        try:\n",
    "            data = dict[nameslist[idx]]\n",
    "            return data\n",
    "        except KeyError:\n",
    "            idx +=1\n",
    "    return False\n",
    "\n",
    "def searchdict(dict, nameslist):\n",
    "    for key in [\"dei\", \"us-gaap\"]:\n",
    "        data = runlist(dict[key], nameslist) \n",
    "        if  data != False:\n",
    "            return data\n",
    "    raise KeyError(f\"Company doesnt have any of {nameslist}\")\n",
    "\n",
    "\n",
    "def getcik(ticker):\n",
    "    #Convert the ticker into the proper cik\n",
    "    for key,value in cikdata.items():\n",
    "        if value[\"ticker\"] == ticker:\n",
    "            cik = value[\"cik_str\"]\n",
    "            break\n",
    "    return str(cik).zfill(10)\n",
    "\n",
    "#Headers for EDGAR call\n",
    "headers = {\n",
    "    \"User-Agent\":\"ficakc@seznam.cz\",\n",
    "    \"Accept-Encoding\":\"gzip, deflate\",\n",
    "}\n",
    "\n",
    "TIMEOUT = 8\n",
    "RETRIES = 2\n",
    "START_RETRY_DELAY = 1\n",
    "# cik_url =  \"https://www.sec.gov/files/company_tickers.json\"\n",
    "# cikdata = requests.get(cik_url, headers=headers).json()\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\cik.json\",\"r\") as file:\n",
    "    cikdata = json.load(file)\n",
    "    file.close()\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\apple.json\",\"r\") as file:\n",
    "    Apple = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def sync_companyfacts(ticker:str):\n",
    "    cik = getcik(ticker)\n",
    "    data_url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    data  = httpx.get(data_url, headers= headers)\n",
    "    return data\n",
    "    \n",
    "async def companyfacts(ticker:str, client, semaphore):\n",
    "    #Get all the financial data for a ticker\n",
    "    cik = getcik(ticker)\n",
    "    data_url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    facts = await fetch(data_url, headers, semaphore, client, TIMEOUT,RETRIES,START_RETRY_DELAY)\n",
    "    return facts\n",
    "\n",
    "def endtodatetime(dataframe):\n",
    "    dataframe.loc[:,\"end\"] = pd.datetime(dataframe[\"end\"])\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, ticker:str):\n",
    "        self.ticker = ticker.upper()\n",
    "        self.cik = getcik(self.ticker)\n",
    "        \n",
    "    async def async_init(self,client, semaphore, measures):\n",
    "        #Get all of the data for the company, ALL of it \n",
    "        data = await companyfacts(self.ticker, client, semaphore)\n",
    "        #If the response wasn't recieved, skips the rest of the code \n",
    "        if type(data) != int:\n",
    "            self.data = data.json()\n",
    "        else:\n",
    "            return 0\n",
    "        #Get the share amount \n",
    "        self.share_name_list = [\"EntityCommonStockSharesOutstanding\", \"CommonStockSharesOutstanding\"]\n",
    "        meta = copy.deepcopy(self.data[\"facts\"])\n",
    "        #searches the company dict for the first occurence of something in the names list\n",
    "        share_info = searchdict(meta, self.share_name_list)\n",
    "        share_date= datetime.strptime(share_info[\"units\"][\"shares\"][0][\"end\"], r\"%Y-%m-%d\")\n",
    "        #Get the earliest date with all the infor about the company\n",
    "        self.start_year = max([share_date] + [datetime.strptime(self.data[\"facts\"][\"us-gaap\"][measure][\"units\"][\"USD\"][0][\"end\"], r\"%Y-%m-%d\") if measure in self.data[\"facts\"][\"us-gaap\"] else datetime.strptime('1920-01-01', r\"%Y-%m-%d\") for measure in measures])\n",
    "        self.end_year = datetime.now().date()\n",
    "        #Get the price and set the self.price\n",
    "        self.fullprice = await yahoo_fetch(self.ticker,self.start_year, self.end_year)\n",
    "        self.fullprice = self.fullprice.reset_index()\n",
    "        Price = self.fullprice[[self.fullprice.columns[0],\"close\", \"adjclose\"]].copy()\n",
    "        Price[\"end\"] = Price[\"index\"].astype(str)\n",
    "        Price.drop(columns=[\"index\"],inplace=True)\n",
    "        date_range = pd.date_range(start=self.start_year, end=self.end_year).astype(str)\n",
    "        self.date_range = pd.DataFrame(date_range, columns=['end'])\n",
    "        Price = pd.merge(self.date_range, Price, on = [\"end\"],how=\"left\" )\n",
    "        self.price = Price.bfill()\n",
    "        return 1\n",
    "\n",
    "    def fact(self,measure,simple=True):\n",
    "        #Propagate the 0 \n",
    "        if self.data == 0:\n",
    "            return \n",
    "        if measure in deprecate_conversion:\n",
    "            undep = deprecate_conversion[measure]\n",
    "            \n",
    "        try:\n",
    "            point_list = self.data[\"facts\"][\"us-gaap\"][measure][\"units\"][\"USD\"]\n",
    "            frame = pd.DataFrame(point_list)\n",
    "            frame = frame.drop_duplicates(subset='end', keep='last')\n",
    "            frame[measure] = frame[\"val\"]\n",
    "            if simple:\n",
    "                frame = frame[[\"end\", measure]]\n",
    "            frame = pd.merge(self.date_range,frame,on=\"end\",how=\"left\")\n",
    "            return frame.ffill()\n",
    "        except KeyError:\n",
    "            print(f\"Measure {measure} not available for {self.ticker}.\")\n",
    "    def shares(self,simple=True):\n",
    "        #Propagate the 0 \n",
    "        if self.data == 0:\n",
    "            return 0\n",
    "        if simple:\n",
    "            meta = copy.deepcopy(self.data[\"facts\"])\n",
    "            share_count = pd.DataFrame(searchdict(meta,self.share_name_list)[\"units\"][\"shares\"][0], index=[0])[[\"end\",\"val\"]]\n",
    "        share_count[\"shares\"] = share_count[\"val\"]\n",
    "        share_count.drop(columns=[\"val\"], inplace = True)\n",
    "        share_count = share_count.drop_duplicates(subset=\"end\", keep=\"last\")\n",
    "        share_count = pd.merge(self.date_range, share_count, on=[\"end\"], how=\"left\")\n",
    "        return share_count.ffill()\n",
    "    \n",
    "\n",
    "#Initializes and appends the stock object\n",
    "async def async_task(ticker, client, semaphore, measures):\n",
    "    # Measures are used to get the date when all the financial info is available\n",
    "    stock = Stock(ticker)\n",
    "    print(f\"Currently pinging {ticker}\")\n",
    "    succesful = await stock.async_init(client,semaphore,measures)\n",
    "    if not succesful:\n",
    "        return (ticker, False)\n",
    "    with open(f'C:\\Programming\\Python\\Finance\\EDGAR\\companies\\{ticker}.pkl', 'wb') as file:\n",
    "        pickle.dump(stock,file)\n",
    "        file.close()\n",
    "    #Returns availability of data for a specific company\n",
    "    return (ticker,True)\n",
    "\n",
    "\n",
    "def acquire_frame(ticker, measures, indicator_frame):\n",
    "    with open(f'C:\\Programming\\Python\\Finance\\EDGAR\\companies\\{ticker}.pkl', 'rb') as file:\n",
    "        stock = pickle.load(file)\n",
    "        file.close()\n",
    "    try:\n",
    "        #Price and shares oustanding \n",
    "        shares = stock.shares().copy()\n",
    "        stock_price = stock.price.copy()\n",
    "        df = pd.merge(shares, stock_price, left_on=[\"end\"], right_on=[\"end\"], how = \"left\")\n",
    "        frames_list = [stock.fact(measure) for measure in measures]\n",
    "        for frame in frames_list:\n",
    "            df = pd.merge(df,frame, on=[\"end\"], how=\"left\")\n",
    "    except AttributeError:\n",
    "        return\n",
    "    #Economic indicators \n",
    "    df = pd.merge(df, indicator_frame, left_on =[\"end\"], right_on=[\"index\"], how=\"left\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently pinging AAPL\n",
      "Currently pinging MSFT\n",
      "Currently pinging GOOGL\n",
      "Currently pinging AMZN\n",
      "Currently pinging NVDA\n",
      "Measure Liabilities not available for AMZN.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m company_frames_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[async_task(ticker, client, sem, measures, indicators) \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m ticker_list])\n\u001b[0;32m     19\u001b[0m company_frames_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(company_frames_tuples)):\n",
      "Cell \u001b[1;32mIn[19], line 148\u001b[0m, in \u001b[0;36masync_task\u001b[1;34m(ticker, client, semaphore, measures, indicators)\u001b[0m\n\u001b[0;32m    146\u001b[0m     frames_list \u001b[38;5;241m=\u001b[39m [stock\u001b[38;5;241m.\u001b[39mfact(measure) \u001b[38;5;28;01mfor\u001b[39;00m measure \u001b[38;5;129;01min\u001b[39;00m measures]\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frames_list:\n\u001b[1;32m--> 148\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m#HANDLE RETURNING NONES IN THE GATHER BECAUSE SOME FRAMES WILL BE NONE///////////////////////////\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:152\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    150\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    151\u001b[0m     left_df \u001b[38;5;241m=\u001b[39m _validate_operand(left)\n\u001b[1;32m--> 152\u001b[0m     right_df \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_operand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    155\u001b[0m             left_df,\n\u001b[0;32m    156\u001b[0m             right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    167\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ficak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2632\u001b[0m, in \u001b[0;36m_validate_operand\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   2631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2633\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only merge Series or DataFrame objects, a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2634\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed"
     ]
    }
   ],
   "source": [
    "#write out measures based on importance in descending order\n",
    "# tracemalloc.start()\n",
    "measures = [\"Assets\", \"Liabilities\", \"AssetsCurrent\", \"LiabilitiesCurrent\"]\n",
    "#write out the indicators \n",
    "indicators = [\"TB3MS\", \"DCOILWTICO\"]\n",
    "indicator_frame = asyncio.run(fred_fetch(indicators, stock.start_year, stock.end_year))\n",
    "#Get the first n companies sorted by market cap \n",
    "companies_num = 5\n",
    "comp = 0\n",
    "sem = asyncio.Semaphore(9)\n",
    "#GATHER THE FIRST companies_num companies ciks and pass them to the gather with the tasks\n",
    "ticker_list = []\n",
    "for company, values in cikdata.items():\n",
    "    if comp<companies_num:\n",
    "        ticker_list.append(values[\"ticker\"])\n",
    "        comp+=1\n",
    "    else:\n",
    "        break\n",
    "company_frames_availablity = await asyncio.gather(*[async_task(ticker, client, sem, measures, indicators) for ticker in ticker_list])\n",
    "company_frames_tuples = [(ticker,acquire_frame(ticker)) for ticker,value in company_frames_availablity if value]\n",
    "company_frames_dict = {}\n",
    "for key,value in company_frames_tuples:\n",
    "    company_frames_dict[key] = value\n",
    "\n",
    "# for i in range(len(company_frames_tuples)):\n",
    "#     if company_frames_tuples[i] == None:\n",
    "#         del company_frames_tuples[i]\n",
    "# for ticker, df in company_frames_tuples:\n",
    "#     company_frames_dict[ticker] = df\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>shares</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>AssetsCurrent</th>\n",
       "      <th>LiabilitiesCurrent</th>\n",
       "      <th>index</th>\n",
       "      <th>TB3MS</th>\n",
       "      <th>DCOILWTICO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.010000</td>\n",
       "      <td>17.613337</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.160000</td>\n",
       "      <td>17.728153</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>72.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.270000</td>\n",
       "      <td>17.812353</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.820000</td>\n",
       "      <td>18.233356</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.820000</td>\n",
       "      <td>18.233356</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.820000</td>\n",
       "      <td>18.233356</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.820000</td>\n",
       "      <td>18.233356</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-07-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.299999</td>\n",
       "      <td>18.600779</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.410000</td>\n",
       "      <td>18.684978</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-07-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.270000</td>\n",
       "      <td>18.577818</td>\n",
       "      <td>8.611300e+10</td>\n",
       "      <td>3.993800e+10</td>\n",
       "      <td>5.567600e+10</td>\n",
       "      <td>2.614700e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          end  shares      close   adjclose        Assets   Liabilities  \\\n",
       "0  2010-06-30     NaN  23.010000  17.613337  8.611300e+10  3.993800e+10   \n",
       "1  2010-07-01     NaN  23.160000  17.728153  8.611300e+10  3.993800e+10   \n",
       "2  2010-07-02     NaN  23.270000  17.812353  8.611300e+10  3.993800e+10   \n",
       "3  2010-07-03     NaN  23.820000  18.233356  8.611300e+10  3.993800e+10   \n",
       "4  2010-07-04     NaN  23.820000  18.233356  8.611300e+10  3.993800e+10   \n",
       "5  2010-07-05     NaN  23.820000  18.233356  8.611300e+10  3.993800e+10   \n",
       "6  2010-07-06     NaN  23.820000  18.233356  8.611300e+10  3.993800e+10   \n",
       "7  2010-07-07     NaN  24.299999  18.600779  8.611300e+10  3.993800e+10   \n",
       "8  2010-07-08     NaN  24.410000  18.684978  8.611300e+10  3.993800e+10   \n",
       "9  2010-07-09     NaN  24.270000  18.577818  8.611300e+10  3.993800e+10   \n",
       "\n",
       "   AssetsCurrent  LiabilitiesCurrent       index  TB3MS  DCOILWTICO  \n",
       "0   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "1   5.567600e+10        2.614700e+10  2010-07-01   0.16       72.95  \n",
       "2   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "3   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "4   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "5   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "6   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "7   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "8   5.567600e+10        2.614700e+10         NaN    NaN         NaN  \n",
       "9   5.567600e+10        2.614700e+10         NaN    NaN         NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_frames_dict[\"MSFT\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple.data[\"facts\"][\"dei\"][\"EntityCommonStockSharesOutstanding\"][\"units\"][\"shares\"]\n",
    "frame  = fred_info([\"TB3MS\", \"DCOILWTICO\"], '2015-02-24', '2017-02-24')\n",
    "frame.head(40)\n",
    "# print(frame)\n",
    "\n",
    "frame[\"index\"] = frame[\"index\"].astype(str)\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\FRED.json\", \"w\") as file:\n",
    "    json.dump(frame.to_dict(orient=\"records\"), file, indent=1)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated fucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "tickers = [\"AAPL\", \"MSFT\"]\n",
    "for ticker in tickers:\n",
    "    data = sync_companyfacts(ticker).json()\n",
    "    data = data[\"facts\"][\"us-gaap\"]\n",
    "    for key,value in data.items():\n",
    "        del value[\"units\"]\n",
    "        if not key in dictionary:\n",
    "            dictionary[key] = value\n",
    "\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\deprecated.json\", \"w\")as file:\n",
    "    json.dump(dictionary, file, indent= 1)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual testing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkout(ticker, name):\n",
    "    data = sync_companyfacts(ticker).json()\n",
    "    dict1  = data[\"facts\"][\"us-gaap\"]\n",
    "    dict2  = data[\"facts\"][\"dei\"]\n",
    "    dict = {**dict1, **dict2}\n",
    "    complist = []\n",
    "    for key in dict:\n",
    "        complist.append(key)\n",
    "\n",
    "    with open(f\"C:\\Programming\\Python\\Finance\\EDGAR\\{name}.json\", \"w\") as file:\n",
    "        json.dump(complist, file, indent =1)\n",
    "        file.close()\n",
    "\n",
    "# amazon = sync_companyfacts(ticker).json()\n",
    "dictionary = amazon[\"facts\"][\"dei\"].keys()\n",
    "dictionary  = [i for i in dictionary]\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\amazontotal.json\", \"w\") as file:\n",
    "        json.dump(dictionary, file, indent =1)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "# print(amazon[\"facts\"].keys())\n",
    "# checkout(\"AMZN\",\"amazon_liabl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Stock.__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m measures \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssets\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssetsCurrent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiabilitiesCurrent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m Apple \u001b[38;5;241m=\u001b[39m \u001b[43mStock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maapl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m stock \u001b[38;5;241m=\u001b[39m Apple\n\u001b[0;32m      4\u001b[0m shares \u001b[38;5;241m=\u001b[39m stock\u001b[38;5;241m.\u001b[39mshares()\n",
      "\u001b[1;31mTypeError\u001b[0m: Stock.__init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "measures = [\"Assets\", \"Liabilities\", \"AssetsCurrent\", \"LiabilitiesCurrent\"]\n",
    "Apple = Stock(\"aapl\", measures)\n",
    "stock = Apple\n",
    "shares = stock.shares()\n",
    "stock_num = stock.price\n",
    "if isinstance(shares, int) or isinstance(stock_num, int): \n",
    "    pass\n",
    "    # break\n",
    "df = pd.merge(shares.copy(), stock_num.copy(), on=[\"end\"], how = \"left\")\n",
    "frames_list = [stock.fact(measure) for measure in measures]\n",
    "for frame in frames_list:\n",
    "    df = pd.merge(df,frame, on=[\"end\"], how=\"left\")\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get all the measure names*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\stock.json\", \"w\") as file:\n",
    "#     json.dump(df.to_dict(orient='records'), file, indent=1)\n",
    "#     file.close()\n",
    "\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\shares.json\", \"w\") as file:\n",
    "    json.dump(stock.shares().copy().to_dict(orient='records'), file, indent=1)\n",
    "    file.close()\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\assets.json\", \"w\") as file:\n",
    "    json.dump(Apple[\"facts\"][\"us-gaap\"][\"Assets\"][\"units\"][\"USD\"], file, indent=1)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = {}\n",
    "for key,value in Apple[\"facts\"][\"us-gaap\"].items() :\n",
    "    measures[key.ljust(100)] = value[\"label\"]\n",
    "\n",
    "measures[\"METADATA\".ljust(200,\"/\")] = \"\"\n",
    "\n",
    "for key,value in Apple[\"facts\"][\"dei\"].items():\n",
    "    measures[key.ljust(100)] = value[\"label\"]\n",
    "\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\measures.json\",\"w\") as file:\n",
    "    json.dump(measures, file, indent=1)\n",
    "\n",
    "\n",
    "#create price reference list:\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\price.json\", \"w\") as file:\n",
    "    json.dump(Apple.price.to_dict(orient='records'), file, indent=1)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Apple[\"facts\"][\"us-gaap\"][\"AssetsCurrent\"][\"units\"][\"USD\"] :\n",
    "    try:\n",
    "        del key[\"frame\"]\n",
    "        print(key)\n",
    "    except KeyError:\n",
    "        print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Apple[\"facts\"][\"us-gaap\"][\"Assets\"][\"units\"][\"USD\"][0][\"end\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
