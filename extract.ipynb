{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_GatheringFuture pending>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla\n",
      "bla\n",
      "bla\n",
      "bla\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "\n",
    "client =  httpx.AsyncClient()\n",
    "async def fetch(url, headers, semaphore, client, timeout, max_retries, start_retry_delay):\n",
    "    async with semaphore:\n",
    "        async with client:\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = client.get(url, timeout=timeout, headers= headers)\n",
    "                    response.raise_for_status()\n",
    "                    return response  # Successful request, exit the loop\n",
    "                except httpx.HTTPStatusError as e:\n",
    "                    headers = response.headers\n",
    "                    retry_after = headers.get('Retry-After')\n",
    "                    if retry_after != None:\n",
    "                        print(retry_after)\n",
    "                        asyncio.sleep(retry_after.astype(int))\n",
    "                        continue\n",
    "                    print(f\"Error response {e.response.status_code}.\")\n",
    "                except httpx.TimeoutException as e:\n",
    "                    print(f\"Timeout reached: {e}\")\n",
    "                    if attempt < max_retries:\n",
    "                        print(f\"Retrying in {attempt*start_retry_delay} seconds...\")\n",
    "                        asyncio.sleep(attempt*start_retry_delay)\n",
    "                    else:\n",
    "                        print(\"Max retries reached. Exiting.\")\n",
    "                        return 0\n",
    "                except httpx.RequestError as e:\n",
    "                    print(f\"An error occurred: {e}.\")\n",
    "\n",
    "\n",
    "\n",
    "asyncio.gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import yahoo_fin.stock_info as si\n",
    "from datetime import datetime\n",
    "from fredapi import Fred\n",
    "\n",
    "fred = Fred(api_key='0c34c4dd2fd6943f6549f1c990a8a0f0') \n",
    "\n",
    "\n",
    "def getcik(ticker):\n",
    "    #Convert the ticker into the proper cik\n",
    "    for key,value in cikdata.items():\n",
    "        if value[\"ticker\"] == ticker:\n",
    "            cik = value[\"cik_str\"]\n",
    "            break\n",
    "    return str(cik).zfill(10)\n",
    "\n",
    "#Headers for EDGAR call\n",
    "headers = {\n",
    "    \"User-Agent\":\"ficakc@seznam.cz\",\n",
    "    \"Accept-Encoding\":\"gzip, deflate\",\n",
    "}\n",
    "\n",
    "TIMEOUT = 8\n",
    "RETRIES = 2\n",
    "START_RETRY_DELAY = 0.4\n",
    "# cik_url =  \"https://www.sec.gov/files/company_tickers.json\"\n",
    "# cikdata = requests.get(cik_url, headers=headers).json()\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\cik.json\",\"r\") as file:\n",
    "    cikdata = json.load(file)\n",
    "    file.close()\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\apple.json\",\"r\") as file:\n",
    "    Apple = json.load(file)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "def companyfacts(ticker:str, client, semaphore):\n",
    "    #Get all the financial data for a ticker\n",
    "    cik = getcik(ticker)\n",
    "    data_url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    facts = fetch(data_url, headers, semaphore, client, TIMEOUT,RETRIES,START_RETRY_DELAY)\n",
    "    return facts\n",
    "\n",
    "def endtodatetime(dataframe):\n",
    "    dataframe.loc[:,\"end\"] = pd.datetime(dataframe[\"end\"])\n",
    "    return dataframe\n",
    "\n",
    "def fred_info(ids:list, start, end):\n",
    "    #start and end are datatime objects\n",
    "    start = start.strftime('%Y-%m-%d')\n",
    "    end = end.strftime('%Y-%m-%d')\n",
    "    frame = pd.DataFrame()\n",
    "    for id in ids:\n",
    "        series = fred.get_series(id,observation_start=start, observation_end=end)\n",
    "        frame[id] = series\n",
    "    frame = frame.reset_index()\n",
    "    frame[\"index\"] = frame[\"index\"].astype(str)\n",
    "    return frame.ffill().bfill()\n",
    "\n",
    "class Stock:\n",
    "    def __init__(self, ticker:str, measures:list):\n",
    "        self.ticker = ticker.upper()\n",
    "        self.cik = getcik(self.ticker)\n",
    "        \n",
    "    async def async_init(self,client,semaphore):\n",
    "        data = await companyfacts(self.ticker, client, semaphore)\n",
    "        #If the response wasn't recieved, skips the rest of the code \n",
    "        if type(data) != int:\n",
    "            self.data = data.json()\n",
    "        else:\n",
    "            return\n",
    "        share_amount = datetime.strptime(self.data[\"facts\"][\"dei\"][\"EntityCommonStockSharesOutstanding\"][\"units\"][\"shares\"][0][\"end\"], r\"%Y-%m-%d\") if \"EntityCommonStockSharesOutstanding\" in self.data[\"facts\"][\"dei\"] else datetime.strptime(self.data[\"facts\"][\"dei\"][\"EntityPublicFloat\"][\"units\"][\"shares\"][0][\"end\"], r\"%Y-%m-%d\")\n",
    "        self.start_year = max([share_amount] + [datetime.strptime(self.data[\"facts\"][\"us-gaap\"][measure][\"units\"][\"USD\"][0][\"end\"], r\"%Y-%m-%d\") if measure in self.data[\"facts\"][\"us-gaap\"] else datetime.strptime('1920-01-01', r\"%Y-%m-%d\") for measure in measures])\n",
    "        self.end_year = datetime.now().date()\n",
    "        #Get the price and set the self.price\n",
    "        self.fullprice = si.get_data(self.ticker,self.start_year, self.end_year).reset_index()\n",
    "        Price = self.fullprice[[self.fullprice.columns[0],\"close\", \"adjclose\"]].copy()\n",
    "        Price[\"end\"] = Price[\"index\"].astype(str)\n",
    "        Price.drop(columns=[\"index\"],inplace=True)\n",
    "        date_range = pd.date_range(start=self.start_year, end=self.end_year).astype(str)\n",
    "        self.date_range = pd.DataFrame(date_range, columns=['end'])\n",
    "        Price = pd.merge(self.date_range, Price, on = [\"end\"],how=\"left\" )\n",
    "        self.price = Price.bfill()\n",
    "\n",
    "    def fact(self,measure,simple=True):\n",
    "        #Propagate the 0 \n",
    "        if self.data == 0:\n",
    "            return 0\n",
    "        try:\n",
    "            point_list = self.data[\"facts\"][\"us-gaap\"][measure][\"units\"][\"USD\"]\n",
    "            frame = pd.DataFrame(point_list)\n",
    "            frame = frame.drop_duplicates(subset='end', keep='last')\n",
    "            frame[measure] = frame[\"val\"]\n",
    "            if simple:\n",
    "                frame = frame[[\"end\", measure]]\n",
    "            frame = pd.merge(self.date_range,frame,on=\"end\",how=\"left\")\n",
    "            return frame.ffill()\n",
    "        except KeyError:\n",
    "            print(f\"Measure {measure} not available for company.\")\n",
    "    def shares(self,simple=True):\n",
    "        #Propagate the 0 \n",
    "        if self.data == 0:\n",
    "            return 0\n",
    "        try:\n",
    "            if simple:\n",
    "                share_count = pd.DataFrame(self.data[\"facts\"][\"dei\"][\"EntityCommonStockSharesOutstanding\"][\"units\"][\"shares\"])[[\"end\",\"val\"]]\n",
    "        except KeyError:\n",
    "            if simple:\n",
    "                share_count = pd.DataFrame(self.data[\"facts\"][\"dei\"][\"EntityPublicFloat\"][\"units\"][\"shares\"])[[\"end\",\"val\"]]\n",
    "        share_count[\"shares\"] = share_count[\"val\"]\n",
    "        share_count.drop(columns=[\"val\"], inplace = True)\n",
    "        share_count = share_count.drop_duplicates(subset=\"end\", keep=\"last\")\n",
    "        share_count = pd.merge(self.date_range, price, on=[\"end\"], how=\"left\")\n",
    "        return share_count.ffill()\n",
    "    \n",
    "async def async_task(cik, client, semaphore, measures, indicators):\n",
    "    print(f\"Currently pinging {cik}\")\n",
    "    stock = Stock(cik, measures)\n",
    "    stock.async_init(stock,client,semaphore)\n",
    "    try:\n",
    "        #Price and shares oustanding \n",
    "        shares = stock.shares().copy()\n",
    "        stock_price = stock.price.copy()\n",
    "        df = pd.merge(shares, stock_price, left_on=[\"end\"], right_on=[\"end\"], how = \"left\")\n",
    "        frames_list = [stock.fact(measure) for measure in measures]\n",
    "        for frame in frames_list:\n",
    "            df = pd.merge(df,frame, on=[\"end\"], how=\"left\")\n",
    "    #HANDE RETURNING NONES IN THE GATHER///////////////////////////\n",
    "    except AttributeError:\n",
    "        return\n",
    "    #Economic indicators \n",
    "    indicator_frame = fred_info(indicators, stock.start_year, stock.end_year)\n",
    "    df = pd.merge(df, indicator_frame, left_on =[\"end\"], right_on=[\"index\"], how=\"left\")\n",
    "    return (cik,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently pinging AAPL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: HTTPSConnectionPool(host='data.sec.gov', port=443): Read timed out. (read timeout=10)\n",
      "Max retries reached. Exiting.\n",
      "Currently pinging MSFT\n",
      "             end        shares\n",
      "0     2010-06-30           NaN\n",
      "1     2010-07-01           NaN\n",
      "2     2010-07-02           NaN\n",
      "3     2010-07-03           NaN\n",
      "4     2010-07-04           NaN\n",
      "...          ...           ...\n",
      "4942  2024-01-10  7.432262e+09\n",
      "4943  2024-01-11  7.432262e+09\n",
      "4944  2024-01-12  7.432262e+09\n",
      "4945  2024-01-13  7.432262e+09\n",
      "4946  2024-01-14  7.432262e+09\n",
      "\n",
      "[4947 rows x 2 columns]\n",
      "Currently pinging GOOGL\n",
      "Request failed: HTTPSConnectionPool(host='data.sec.gov', port=443): Read timed out. (read timeout=10)\n",
      "Max retries reached. Exiting.\n",
      "Currently pinging AMZN\n",
      "Request failed: HTTPSConnectionPool(host='data.sec.gov', port=443): Read timed out. (read timeout=10)\n",
      "Max retries reached. Exiting.\n",
      "Currently pinging NVDA\n",
      "Currently pinging META\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'shares'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m company, values \u001b[38;5;129;01min\u001b[39;00m cikdata\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently pinging \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     stock \u001b[38;5;241m=\u001b[39m \u001b[43mStock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m#Price and shares oustanding \u001b[39;00m\n\u001b[0;32m     15\u001b[0m         shares \u001b[38;5;241m=\u001b[39m stock\u001b[38;5;241m.\u001b[39mshares()\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[1], line 89\u001b[0m, in \u001b[0;36mStock.__init__\u001b[1;34m(self, ticker, measures)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m share_amount \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdei\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntityCommonStockSharesOutstanding\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshares\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntityCommonStockSharesOutstanding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdei\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdei\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEntityPublicFloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshares\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([share_amount] \u001b[38;5;241m+\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-gaap\u001b[39m\u001b[38;5;124m\"\u001b[39m][measure][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m measure \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-gaap\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1920-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m measure \u001b[38;5;129;01min\u001b[39;00m measures])\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_year \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'shares'"
     ]
    }
   ],
   "source": [
    "#write out measures based on importance in descending order\n",
    "measures = [\"Assets\", \"Liabilities\", \"AssetsCurrent\", \"LiabilitiesCurrent\"]\n",
    "#write out the indicators \n",
    "indicators = [\"TB3MS\", \"DCOILWTICO\"]\n",
    "#Get the first n companies sorted by market cap \n",
    "companies_num = 3\n",
    "comp = 0\n",
    "#dict of all the companies' dataframes\n",
    "frame_dict = {}\n",
    "sem = asyncio.semaphore(9)\n",
    "#GATHER THE FIRST companies_num companies ciks and pass them to the gather with the tasks\n",
    "cik_list = []\n",
    "for company, values in cikdata.items():\n",
    "    if comp<companies_num:\n",
    "        cik_list.append(values[\"cik_str\"])\n",
    "        comp+=1\n",
    "    else:\n",
    "        break\n",
    "company_frames_tuples = asyncio.gather(*[async_task(cik) for cik in cik_list])\n",
    "company_frames_dict = {}\n",
    "for cik, df in company_frames_tuples:\n",
    "    company_frames_dict[cik] = df\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple.data[\"facts\"][\"dei\"][\"EntityCommonStockSharesOutstanding\"][\"units\"][\"shares\"]\n",
    "frame  = fred_info([\"TB3MS\", \"DCOILWTICO\"], '2015-02-24', '2017-02-24')\n",
    "frame.head(40)\n",
    "# print(frame)\n",
    "\n",
    "frame[\"index\"] = frame[\"index\"].astype(str)\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\FRED.json\", \"w\") as file:\n",
    "    json.dump(frame.to_dict(orient=\"records\"), file, indent=1)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT = companyfacts('MSFT').json()\n",
    "print(MSFT[\"facts\"][\"dei\"][\"EntityCommonStockSharesOutstanding\"][\"units\"][\"shares\"][0][\"end\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = [\"Assets\", \"Liabilities\", \"AssetsCurrent\", \"LiabilitiesCurrent\"]\n",
    "Apple = Stock(\"aapl\", measures)\n",
    "stock = Apple\n",
    "shares = stock.shares()\n",
    "stock_num = stock.price\n",
    "if isinstance(shares, int) or isinstance(stock_num, int): \n",
    "    pass\n",
    "    # break\n",
    "df = pd.merge(shares.copy(), stock_num.copy(), on=[\"end\"], how = \"left\")\n",
    "frames_list = [stock.fact(measure) for measure in measures]\n",
    "for frame in frames_list:\n",
    "    df = pd.merge(df,frame, on=[\"end\"], how=\"left\")\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to info: Stock[\"facts\"][\"us-gaap\"][some_measure][\"units\"][\"USD\"]\n",
    "\n",
    "Path to meta info: Stock[\"facts\"][\"dei\"]\n",
    "\n",
    "Three things:\n",
    "    First:\n",
    "        Graph and correlate measures and ratios\n",
    "            Currently forward filling fundamentals data, could be fucked in the future\n",
    "            Include the rate of change of the variables and compare those \n",
    "    Second:\n",
    "        Make a test to validate trading strategies\n",
    "            Add a function that picks eligible stocks at some timeframe and test their performance xdz\n",
    "    Third:\n",
    "        Train a model to predict the long term price\n",
    "            forward filling fundamentals can be really fucked \n",
    "            Consider using averages or linear change from previous value to next for training \n",
    "            Include all the past fundamentals for each datapoint - this could figure out how people value growth.\n",
    "\n",
    "Data to add for regression and AI:\n",
    "    oil price\n",
    "    interest rates \n",
    "        FRED HAS SO MUCH DATA HOLY SHIT \n",
    "        pick yer fucking poison mate\n",
    "    \n",
    "\n",
    "Measures:\n",
    "    Price/BookValuepershare = MarketCap/BookValue = EntityCommonStockSharesOutstanding*SPrice(Assets-Liabilities)\n",
    "    Price/Earnings - all the possible earnings metrics\n",
    "    Current ratio = AssetsCurrent/LiabilitiesCurrent\n",
    "    ///////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    Revenue\n",
    "    Operating Income \n",
    "    Free cash flow \n",
    "    EBITDA \n",
    "    Dividends - \"PaymentsOfDividendsCommonStock\"\n",
    "\n",
    "How does market cap influence these correlations?\n",
    "\n",
    "Where do you find price data?\n",
    "    Yahoo-fin.\n",
    "\n",
    "\n",
    "Methods to figure out relationships:\n",
    "    Kendall's Tau\n",
    "    Spearman's Rank Correlation\n",
    "\n",
    "    cross variable correlation loop through all variables \n",
    "    Polynomial regression\n",
    "    LSTM\n",
    "\n",
    "\n",
    "Todo:\n",
    "    Investigate why not forward filling\n",
    "    Fix Asynchronousness\n",
    "        Implement asynchrnousness for FRED and Yahoofin.\n",
    "    Implement ConnectionError safeguard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get all the measure names*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\stock.json\", \"w\") as file:\n",
    "#     json.dump(df.to_dict(orient='records'), file, indent=1)\n",
    "#     file.close()\n",
    "\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\shares.json\", \"w\") as file:\n",
    "    json.dump(stock.shares().copy().to_dict(orient='records'), file, indent=1)\n",
    "    file.close()\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\assets.json\", \"w\") as file:\n",
    "    json.dump(Apple[\"facts\"][\"us-gaap\"][\"Assets\"][\"units\"][\"USD\"], file, indent=1)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = {}\n",
    "for key,value in Apple[\"facts\"][\"us-gaap\"].items() :\n",
    "    measures[key.ljust(100)] = value[\"label\"]\n",
    "\n",
    "measures[\"METADATA\".ljust(200,\"/\")] = \"\"\n",
    "\n",
    "for key,value in Apple[\"facts\"][\"dei\"].items():\n",
    "    measures[key.ljust(100)] = value[\"label\"]\n",
    "\n",
    "\n",
    "with open(r\"C:\\Programming\\Python\\Finance\\EDGAR\\measures.json\",\"w\") as file:\n",
    "    json.dump(measures, file, indent=1)\n",
    "\n",
    "\n",
    "#create price reference list:\n",
    "with open(\"C:\\Programming\\Python\\Finance\\EDGAR\\price.json\", \"w\") as file:\n",
    "    json.dump(Apple.price.to_dict(orient='records'), file, indent=1)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Apple[\"facts\"][\"us-gaap\"][\"AssetsCurrent\"][\"units\"][\"USD\"] :\n",
    "    try:\n",
    "        del key[\"frame\"]\n",
    "        print(key)\n",
    "    except KeyError:\n",
    "        print(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Apple[\"facts\"][\"us-gaap\"][\"Assets\"][\"units\"][\"USD\"][0][\"end\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
